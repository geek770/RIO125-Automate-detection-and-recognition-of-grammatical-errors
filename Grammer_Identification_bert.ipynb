{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geek770/RIO125-Automate-detection-and-recognition-of-grammatical-errors/blob/main/Grammer_Identification_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOhaUtvjzstc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jqB0lrji3J8E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import AdamWeightDecay\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "# Function to load data from a CSV file\n",
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Function to preprocess data, extracting sentences and labels\n",
        "def preprocess_data(data):\n",
        "    sentences = data['input'].tolist()\n",
        "    labels = data['labels'].tolist()\n",
        "    return sentences, labels\n",
        "\n",
        "# Function to preprocess test data, tokenizing sentences\n",
        "def preprocess_test_data(data, tokenizer, max_length):\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        sentences = data['input'].tolist()\n",
        "    else:\n",
        "        sentences = data\n",
        "    tokenized_sentences = []\n",
        "\n",
        "    # Tokenize each sentence and add it to the list\n",
        "    for sentence in sentences:\n",
        "        if pd.isnull(sentence):\n",
        "            sentence = \"\"\n",
        "        tokenized_sentence = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length,\n",
        "            return_tensors='tf',\n",
        "            return_token_type_ids=False,\n",
        "            return_attention_mask=True,\n",
        "            return_overflowing_tokens=False,\n",
        "        )\n",
        "        tokenized_sentences.append(tokenized_sentence)\n",
        "\n",
        "    # Combine tokenized sentences into a single dictionary\n",
        "    tokenized = {}\n",
        "    for key in tokenized_sentences[0].keys():\n",
        "        tokenized[key] = tf.concat([ts[key] for ts in tokenized_sentences], axis=0)\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "# Function to train the BERT model\n",
        "def train_bert_model(data_path, max_length=128, batch_size=32, epochs=3):\n",
        "    # Load and preprocess the data\n",
        "    data = load_data(data_path)\n",
        "    sentences, labels = preprocess_data(data)\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Load BERT tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize sentences\n",
        "    X_train_tokenized = preprocess_test_data(X_train, tokenizer, max_length)\n",
        "    X_test_tokenized = preprocess_test_data(X_test, tokenizer, max_length)\n",
        "\n",
        "    # Load pre-trained BERT model for sequence classification\n",
        "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Define the optimizer with weight decay\n",
        "    optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
        "\n",
        "    # Define the loss function\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train_tokenized,\n",
        "        np.array(y_train),\n",
        "        validation_split=0.2,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_logits = model.predict(X_test_tokenized).logits\n",
        "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"bert_model\")\n",
        "\n",
        "# Function to test the BERT model on new data\n",
        "def test_bert_model(test_data_path, model_path, max_length=128, batch_size=32):\n",
        "    # Load the pre-trained BERT model and tokenizer\n",
        "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Load the test data\n",
        "    test_data = pd.read_excel(test_data_path)\n",
        "\n",
        "    # Tokenize the test data\n",
        "    X_test_tokenized = preprocess_test_data(test_data, tokenizer, max_length)\n",
        "\n",
        "    # Load the weights of the pre-trained model\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_logits = model.predict(X_test_tokenized).logits\n",
        "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
        "\n",
        "    # Add predictions to the test data and save to CSV\n",
        "    test_data['predicted_label'] = y_pred\n",
        "    output_file = \"output_labelled.csv\"\n",
        "    test_data.to_csv(output_file, index=False)\n",
        "    print(f\"Predictions saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXch5ATwzrEz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787,
          "referenced_widgets": [
            "9a31976743784e91a157161b0e6ca0a2",
            "0fc18421db624525812de1ebb85bf30c",
            "a009d3cb9ef74afaabfe98c5c48b6704",
            "ba5317e7c24b4de0bcdf9adfb08031eb",
            "69d5e623fe67430689d69af592c28783",
            "8ce9dc7d025a4d8b8d6b249225664e7e",
            "fa63531df31c478fac038e100f983061",
            "9caa6bdead1e4e95befc12a689f1932c",
            "4792744d5b1a4f40ad62e0d2cc2b643e",
            "a9566017f51e43c7b43c612897dc2c8d",
            "4936e69475eb419e8572abec8d64349b",
            "776b6fd669924a2fa4aed78157e9b396",
            "fe24f8ce12684c6b9097ecd300bd52b3",
            "da8a6e57dd4c47f99b5ed5f438c37583",
            "e5e1709b7399411f9c8881c73a1fbffb",
            "84c9a4106f8a46998c83d441a5e0f18b",
            "5206ee3bc4634ca0a7dc1811b11ae9d2",
            "d975e3440ec047bb9262980268e23feb",
            "bab308c38f8e4e049eb34da19aed6f98",
            "0c2964075ef848909996ac5b22fc7147",
            "9c4b0789bed84d5eba79eaf4a73c5981",
            "c7d7d6b3674048eb957dbd4258612f3d",
            "2a66ec5f49654dad9a1d5e18a439797f",
            "1ce6709a33d043f5a81ae7ce9e6496df",
            "b0adc857f0bd44c1a8a56d6a47179738",
            "7d62992909d7437ba35fdd6bf9f288f0",
            "45c119b77b6241ba8837fd440c5b9b21",
            "e9329c29485740938c65ee6543921de3",
            "6e3bb9c3d9194b0c94627d636a70b023",
            "140f277b970e4636af76ad8fbed3e5d2",
            "b5e69205ef534c67b639ffe8a74fe9db",
            "8d2ac72a6ca44c72a55cac0f154c58cf",
            "59534e7e9eb5427dbbd14e3fbe009fcf",
            "01c78736266d47308bcf06c8159b2d71",
            "c4d6495a5e9b40b8b0f04bcb0475aebd",
            "65d7f964690142288da78518cbb57bb3",
            "d7493a468e8843018d8c5734bbe87f5c",
            "e57257e2a10143dd84514f047ac097b5",
            "22f2f22096a54907977085d18a03c829",
            "deeb2099514548f8baff66d1ea59942b",
            "e9ee6a629fd249928359e29a27331c93",
            "b55c08db22024ac8a891fdc3c6bc3d09",
            "641554f14f35437b8e7ba494a99dd7de",
            "77d04ee4b8714703bdc1dca1460d1019",
            "38c5313066814b6ea8b47adb25c11e55",
            "9451c885cfe04e3bab32be4f9cd056ea",
            "406bc8a4a132469d8de98d19bd722258",
            "835ffeacc46140e5a034175a40e86104",
            "af302ebf5fcf4d1b8a7c4ce84813c298",
            "0c71bcd8031d4d97a437a33b5660abd9",
            "4e002e3efb3b44f2ac3005b7e7c97aa8",
            "93ceca28a7c546819e1a876c1ecc88c3",
            "0ab0981a2f564f60b118a3f9ef581e89",
            "8c9979964b79411a9969a8e862c1df1c",
            "e804fba96ca04c568073d88d61980f3f"
          ]
        },
        "id": "aVEFxa5AwHkD",
        "outputId": "f09185f9-070a-40d4-a945-f11938379be5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a31976743784e91a157161b0e6ca0a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "776b6fd669924a2fa4aed78157e9b396",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a66ec5f49654dad9a1d5e18a439797f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c78736266d47308bcf06c8159b2d71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38c5313066814b6ea8b47adb25c11e55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7da8706b9e10> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7da8706b9e10> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "432/432 [==============================] - 453s 880ms/step - loss: 0.4631 - accuracy: 0.7857 - val_loss: 0.3991 - val_accuracy: 0.8329\n",
            "Epoch 2/3\n",
            "432/432 [==============================] - 381s 881ms/step - loss: 0.2742 - accuracy: 0.8902 - val_loss: 0.4217 - val_accuracy: 0.8393\n",
            "Epoch 3/3\n",
            "432/432 [==============================] - 380s 881ms/step - loss: 0.1301 - accuracy: 0.9544 - val_loss: 0.4824 - val_accuracy: 0.8408\n",
            "135/135 [==============================] - 46s 277ms/step\n",
            "Accuracy: 0.8417882788973824\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      2028\n",
            "           1       0.81      0.91      0.86      2289\n",
            "\n",
            "    accuracy                           0.84      4317\n",
            "   macro avg       0.85      0.84      0.84      4317\n",
            "weighted avg       0.85      0.84      0.84      4317\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train BERT model\n",
        "train_bert_model(\"input_data.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxnz3y_Jzp3H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nSj71EX4wJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42682f04-b740-47a8-d7aa-6a3c4bd97089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 96s 273ms/step\n",
            "Predictions saved to output_labelled.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#load the model and test it\n",
        "test_bert_model(\"test_data.xlsx\", \"bert_model\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB25g3J9wNCz"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "id": "pEdg4f8s-6NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5iJUxTlowN34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123d4034-9ea6-4249-855b-aeef25936199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Sentence before tokenization: today i woke up at o ' clock and took a shower .\n",
            "Sentence before tokenization: It is an enjoyment !\n",
            "Sentence before tokenization: While waiting for them , I wrote a journal in lang - .\n",
            "Sentence before tokenization: As soon as possible , I have to go to bed .\n",
            "Sentence before tokenization: FINALLY , I made it !\n",
            "Sentence before tokenization: After i finished my militery service , \n",
            "Sentence before tokenization: At p .\n",
            "Sentence before tokenization: I am very fun !\n",
            "Sentence before tokenization: T means quiet .\n",
            "Sentence before tokenization: Be aware that customers ca not go to the th and th floors .\n",
            "Sentence before tokenization: I want to go abroad but I do not have enough money and I do not have enough time .\n",
            "Sentence before tokenization: I always write an essay after I come home from my part - time job and then I have no free time .\n",
            "Sentence before tokenization: I came to visit a friend that is studing here .\n",
            "Sentence before tokenization: There are two verses about a cuckoo that explicitly illustrate two heroesphilosophy .\n",
            "Sentence before tokenization: I started Lang - just now , but I am not sure how to use this website .\n",
            "Sentence before tokenization: I am sure that I can get one of them in two days because I have already received a letter saying they will come back again to give it to me .\n",
            "Sentence before tokenization: The way we are\n",
            "Sentence before tokenization: Japanese rap musician\n",
            "Sentence before tokenization: If ordinary female college students in Korea were , they would definitely prefer coffee from those popular brands .\n",
            "Sentence before tokenization: In my opinion .\n",
            "Sentence before tokenization: With eyes glued to the screen , watching their favorite cartoons , children can end up with poor eyesight .\n",
            "Sentence before tokenization: Basil Good morning , sir !\n",
            "Sentence before tokenization: All rooms are equipped with modern furniture .\n",
            "Sentence before tokenization: I have been interested in this volunteer work for a long time , but I did not have much time to do it because I was busy .\n",
            "Sentence before tokenization: Today I was watched it , interesting program broadcasted .\n",
            "Sentence before tokenization: It is a serious problem ! !\n",
            "Sentence before tokenization: When I went to a W .\n",
            "Sentence before tokenization: I was not conscious untill my roommate woke me up .\n",
            "Sentence before tokenization: I heard that Spanish was started from Latin , like English .\n",
            "Sentence before tokenization: Oh , never forget to go to the ball park with my boys next Tuesday .\n",
            "Sentence before tokenization: The commodity of the victory was presented to my colleague is boy .\n",
            "Sentence before tokenization: Which one of these characteristics is most important to you ?\n",
            "Sentence before tokenization: Baseball is a very popular sport in Japan , the same as in America .\n",
            "Sentence before tokenization: However , while smelling of dear my hometown , I usually feel that this place had passed by without notice during my absent in this place , and that past precious days never come back .\n",
            "Sentence before tokenization: Today I entered Lang - to study English .\n",
            "Sentence before tokenization: I realized I could take a significant step to a bright future .\n",
            "Sentence before tokenization: The best way is to educate children .\n",
            "Sentence before tokenization: In Japan , It rises by the discussion that the player who removes PK is bad or not bad .\n",
            "Sentence before tokenization: It has not started now .\n",
            "Sentence before tokenization: Then I got a new one , so I decided to take my old iPhone to bits !\n",
            "Sentence before tokenization: by a lot of engineer is effort .\n",
            "Sentence before tokenization: I made a japanese dish with them for dinner .\n",
            "Sentence before tokenization: I ca not correspond to human society .\n",
            "Sentence before tokenization: Today is - .\n",
            "Sentence before tokenization: I went to a restaurant with my baby for the first time .\n",
            "Sentence before tokenization: I only study at school .\n",
            "Sentence before tokenization: I managed to wake up in time , however I was not able to understand what he said at all .\n",
            "Sentence before tokenization: As I said above , champagne is a special New Year beverage .\n",
            "Sentence before tokenization: Bye bye .\n",
            "Sentence before tokenization: It was very noisy outside because my dad was talking with someone .\n",
            "Sentence before tokenization: Do you have any idea to improve listening skill of English ?\n",
            "Sentence before tokenization: Sometimes you have to wait a long time , but at other times , if you are lucky , somebody picks you up immediately .\n",
            "Sentence before tokenization: How can I contact my friend in Sendai ?\n",
            "Sentence before tokenization: Below is the summary of the previous story written by me .\n",
            "Sentence before tokenization: The postgraduate craze reflects many social problems .\n",
            "Sentence before tokenization: A Life without a cat , that is very lonely .\n",
            "Sentence before tokenization: So that is why they will miss a lot of chances to make a new friend .\n",
            "Sentence before tokenization: Cameron Diaz was awesome too .\n",
            "Sentence before tokenization: The game stared at .\n",
            "Sentence before tokenization: It was not bad , but .\n",
            "Sentence before tokenization: Long time no see !\n",
            "Sentence before tokenization: I opened America account .\n",
            "Sentence before tokenization: I slept well last night .\n",
            "Sentence before tokenization: The audience is laughing and applauding .\n",
            "Sentence before tokenization: My native language is Japanese .\n",
            "Sentence before tokenization: As for making a presentation , I recognized that it is very important to prepare and practice once and again .\n",
            "Sentence before tokenization: I hope they will be the champion as they did last time .\n",
            "Sentence before tokenization: Next , I went to department store to research to Laptop .\n",
            "Sentence before tokenization: I hate the doctor . He killed my dog , because he did not know how to save animals !\n",
            "Sentence before tokenization: I am allergic to Japanese cedar pollinosis so I am feeling blue .\n",
            "Sentence before tokenization: April , \n",
            "Sentence before tokenization: It is said to be the last and most beautiful beach in the world .\n",
            "Sentence before tokenization: He was reportedly trying to get along with the local people , wearing the same clothes and speaking the same language .\n",
            "Sentence before tokenization: Hi , this is Yuki .\n",
            "Sentence before tokenization: I recently became hooked on Cyworld\n",
            "Sentence before tokenization: I hope that my son wins a foot race .\n",
            "Sentence before tokenization: birthday present\n",
            "Sentence before tokenization: There are some rooms and a small cafe in the darkness .\n",
            "Sentence before tokenization: Very distant dream\n",
            "Sentence before tokenization: A music of a chorus group\n",
            "Sentence before tokenization: Hi I am a Japanese .\n",
            "Sentence before tokenization: I know that .\n",
            "Sentence before tokenization: though it changes , It is regrettable to have disqualified Mr .\n",
            "Sentence before tokenization: That is ok .\n",
            "Sentence before tokenization: Now my hobby is learning English ! ! ! ! !\n",
            "Sentence before tokenization: Well , thanks to all the people who are with me and who are yet to come .\n",
            "Sentence before tokenization: I want my own road bike someday .\n",
            "Sentence before tokenization: The cherry blossoms are in full bloom .\n",
            "Sentence before tokenization: Topic it has recently been announced that a new restaurant may be built in your neighbourhood .\n",
            "Sentence before tokenization: When you put on the snap of the side to the constriction of the waist , but a little bit high portion sensuously , \n",
            "Sentence before tokenization: Good luck , everyone !\n",
            "Sentence before tokenization: At that time , I was not able to speak English at all .\n",
            "Sentence before tokenization: I meet grand mother and uncle and sister after long time .\n",
            "Sentence before tokenization: Do you have any idea how to spend a dark time without using electricity ?\n",
            "Sentence before tokenization: It means may .\n",
            "Sentence before tokenization: I had a plan to go out with my daughter , but I canceled it .\n",
            "Sentence before tokenization: It looks like a little green monster ?\n",
            "Sentence before tokenization: I ca not get anything without try .\n",
            "Sentence before tokenization: Very sweeeeet ! !\n",
            "Sentence before tokenization:  Over five years , the children had done everything theirselves .\n",
            "Sentence before tokenization: I bought a DVD ' Core Rhythms ' recently and work out once in three days .\n",
            "Sentence before tokenization: I have been watching the\n",
            "Sentence before tokenization: I am TORI !\n",
            "Sentence before tokenization: I slept during most of the holidays .\n",
            "Sentence before tokenization: What is your best effective learning ?\n",
            "Sentence before tokenization: Now , I am studying English mainly by Dictation or by Shadowing .\n",
            "Sentence before tokenization: He became years old , the day before yesterday .\n",
            "Sentence before tokenization: I think hackers just have to resign themselves to having a large random component in their reputations .\n",
            "Sentence before tokenization: It may be my fault that I did not check it when I got it but .\n",
            "Sentence before tokenization: I am eighteen .\n",
            "Sentence before tokenization: Maybe you could give me some examples in which collocations each of them sounds the best ?\n",
            "Sentence before tokenization: One of my colleagues is very skilled at it and really kind enough to teach me how to give good sales talk to customers .\n",
            "Sentence before tokenization: He answered , Yes , I have but there are some in London .\n",
            "Sentence before tokenization: She is very brave and did not complain about anything .\n",
            "Sentence before tokenization: But what is this ?\n",
            "Sentence before tokenization: But the fresh feeling and passion were gone quickly , instead I felt afraid and embarrassed .\n",
            "Sentence before tokenization: Fortunately , my father woke up at that time .\n",
            "Sentence before tokenization: Consequently , a group is more likely to make risky decisions than individuals .\n",
            "Sentence before tokenization: Now I would like to express my gratitude to you , who are reading my first day .\n",
            "Sentence before tokenization: If the cherry trees are in full blossom next weekend , I want to go somewhere to see them .\n",
            "Sentence before tokenization: Easy to refresh , or to stand up straight spine , or to feel hand and feet warm up and do , I was told that such power .\n",
            "Sentence before tokenization:  there is no hope , there is only despair \n",
            "Sentence before tokenization: Both qualities are essential in life .\n",
            "Sentence before tokenization: Casio is are more expensive than other manufacturers ' , but their quality is better than other manufacturers ' .\n",
            "Sentence before tokenization: I go to the station and visit a bookstore .\n",
            "Sentence before tokenization: It s intended for th graders and th graders .\n",
            "Sentence before tokenization: The way we are\n",
            "Sentence before tokenization: Do you remember us ?\n",
            "Sentence before tokenization: I want to eat Macdonald is hamburger .\n",
            "Sentence before tokenization: If I can not enter the History class , my chance of entering university will definitely grow slimmer .\n",
            "Sentence before tokenization: I want to become able to write and speak English well .\n",
            "Sentence before tokenization: There are three ways people find their sweetheart .\n",
            "Sentence before tokenization: Thanks to reading it .\n",
            "Sentence before tokenization: I tried to understand , as we have not been to the same place , so this is normal .\n",
            "Sentence before tokenization: When I got there , I saw many tourists .\n",
            "Sentence before tokenization: I thought It was a slight cold .\n",
            "Sentence before tokenization: This is a traditional story from japan .\n",
            "Sentence before tokenization: What is such a working person called ?\n",
            "Sentence before tokenization: Would you please teach me ?\n",
            "Sentence before tokenization: The second Sunday of May is Mother is Day in Japan as it is in some other countries , and this day fell upon May th this year .\n",
            "Sentence before tokenization: Finally he was arrested yesterday .\n",
            "Sentence before tokenization: Many thanks !\n",
            "Sentence before tokenization: I really enjoy keeping my blog in English .\n",
            "Sentence before tokenization: And then , the rabbit takes a rest on the grass .\n",
            "Sentence before tokenization: It totally took about minites for the interview .\n",
            "Sentence before tokenization: At last , I would like to thank you again my friends for your encouragement and support !\n",
            "Sentence before tokenization: He is superb , a real big stiff .\n",
            "Sentence before tokenization: The main purpose of this trip is to see a soap factory on Corfu island .\n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: Today is very cold and windy day .\n",
            "Sentence before tokenization: My father gets up so early for the money .\n",
            "Sentence before tokenization: I am preparing for the CATTI test - a translation test in China .\n",
            "Sentence before tokenization: I have practice menu one after another .\n",
            "Sentence before tokenization: Afterwards , he taught us christmas songs .\n",
            "Sentence before tokenization: Finally I called Lost and Found center in train company\n",
            "Sentence before tokenization: It was more interesting than any Academy Award for best motion picture of that I saw .\n",
            "Sentence before tokenization: One man wore tie and white shirt and black pants looked like business man .\n",
            "Sentence before tokenization: After few years later , I will study more about Construction IT .\n",
            "Sentence before tokenization: I knew that I did not want to know .\n",
            "Sentence before tokenization: It is the only international university in China with its main task set at teaching the Chinese language and culture to foreign students .\n",
            "Sentence before tokenization: And then , the wind will cool down .\n",
            "Sentence before tokenization: It is one of Chinese noodles in Japan .\n",
            "Sentence before tokenization: Anything that distracts her or helps her to feel good will be helpful to him .\n",
            "Sentence before tokenization: You are too happy to notice how happy you are .\n",
            "Sentence before tokenization: I had a good time tonight .\n",
            "Sentence before tokenization: But he came back to the monarch of Walachia .\n",
            "Sentence before tokenization: Actually , I lost my much - loved aunt for cancer .\n",
            "Sentence before tokenization: Today one of the banks unveiled their director is remunerations .\n",
            "Sentence before tokenization: I visited London two years ago .\n",
            "Sentence before tokenization: because today is the anniversary of our fifth month\n",
            "Sentence before tokenization: It was fun .\n",
            "Sentence before tokenization: Friends of my mother live there and we exchanged houses for weeks .\n",
            "Sentence before tokenization: There is no equivalent grammar in Japanese for present perfect so it sometimes confuses me .\n",
            "Sentence before tokenization: how the hell could i study something that will be needed for myself in the future ?\n",
            "Sentence before tokenization: Last thursday I took my first English lesson in this year .\n",
            "Sentence before tokenization: Which season do you like most ?\n",
            "Sentence before tokenization: It is system development with several companies .\n",
            "Sentence before tokenization: Today I am going to write about my business trip .\n",
            "Sentence before tokenization: A man , Gyeong - Chul Park , is interacting with society as a doctor and having other various experiences even now .\n",
            "Sentence before tokenization: My great - grandparents on my grandmother is side enjoyed their lives for over years .\n",
            "Sentence before tokenization: Then , I went to the school .\n",
            "Sentence before tokenization: That video is really funny and you can understand how to use but it was not Japanese ones because we have toilet papers in the bathroom .\n",
            "Sentence before tokenization: They need me to do something for them .\n",
            "Sentence before tokenization: Oh my goodness !\n",
            "Sentence before tokenization: I have never heard a better album , from French or US rap .\n",
            "Sentence before tokenization: My exams are over and now I have some time to kill .\n",
            "Sentence before tokenization: I recently studied English with this song in the background .\n",
            "Sentence before tokenization: Even normal Japanese university students can get around marks .\n",
            "Sentence before tokenization: Do it .\n",
            "Sentence before tokenization: I just came home from the movie theater .\n",
            "Sentence before tokenization: I left the company at , and got home at .\n",
            "Sentence before tokenization: Have you ever seen such a great work ?\n",
            "Sentence before tokenization: I ca not speak fluent English but I will do more English studies .\n",
            "Sentence before tokenization: The wind was warm and felt good .\n",
            "Sentence before tokenization: For example , when a student learns that the word part anti means against , and also knows the meaning of the word corrosive .\n",
            "Sentence before tokenization: So , I need your help .\n",
            "Sentence before tokenization: She says How can you treat me like this ? You never talk to me anymore .\n",
            "Sentence before tokenization: I ca not write English today with correct .\n",
            "Sentence before tokenization: My diary -\n",
            "Sentence before tokenization: B The local tournament .\n",
            "Sentence before tokenization: However , this often does not develop into a romance .\n",
            "Sentence before tokenization: I am learning English .\n",
            "Sentence before tokenization: My son was born on Feb .\n",
            "Sentence before tokenization: We have only hours by .\n",
            "Sentence before tokenization: What salad did the newly marred couple order in the restaurant ?\n",
            "Sentence before tokenization: But after we met or times , he told me that we are incredibly getting alone and I feel you like family , like my younger sister .\n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: You might see a familiar scene for the Japanese in which two people argue in front of a cashier\n",
            "Sentence before tokenization:  Relational database - It uses the attribution like the number value , index , etc . and letter string expressed object in order to categorize something .\n",
            "Sentence before tokenization: The lesson is once a fortnight and , come to think of it , it has been almost years since I started .\n",
            "Sentence before tokenization: But I like that feeling of the rain .\n",
            "Sentence before tokenization: These figures clearly support the disadvantages of ELLs compared to native speakers as the seemingly slight coverage difference leads to critical comprehension gaps .\n",
            "Sentence before tokenization: If you would like to try it , you can go to Wholefood to buy it .\n",
            "Sentence before tokenization: By the way , do you know what voluntary retirement is ?\n",
            "Sentence before tokenization: This is my Saturday , \n",
            "Sentence before tokenization: The insufferable crying .\n",
            "Sentence before tokenization: Every year ! !\n",
            "Sentence before tokenization: Happy new year\n",
            "Sentence before tokenization: They are from Korea .\n",
            "Sentence before tokenization: We had to run many ups and downs there in the highland .\n",
            "Sentence before tokenization: In particular , they often have an original or special lunch .\n",
            "Sentence before tokenization: The organization as a whole must be engaged to create the conditions for your own and your team s success .\n",
            "Sentence before tokenization: Then she asked me , How do you say in English Black framed glasses are popular in Japan ? Although I know she is nervous about English , I have no idea why she wants to know that exression for the first thing !\n",
            "Sentence before tokenization: I could not agree more with the comments that expensive style of marriage is recommended\n",
            "Sentence before tokenization: So I lately watch lots of movies at home in the daylight .\n",
            "Sentence before tokenization: We have been friend for years .\n",
            "Sentence before tokenization: I am sure that I can make higher quality reports or essay by using machines than by hand .\n",
            "Sentence before tokenization: i was hurt my pride .\n",
            "Sentence before tokenization: People do not think they might be infected .\n",
            "Sentence before tokenization: Already the cat died to become sopping .\n",
            "Sentence before tokenization: We took the hot spring times .\n",
            "Sentence before tokenization: Moreover , when I interview musicians who are not Japanese , I would like to talk to them in English without an interpreter .\n",
            "Sentence before tokenization: I hit those goggles and my right eye started bleeding .\n",
            "Sentence before tokenization: FYI o not pick a small theatre .\n",
            "Sentence before tokenization: There are many ways to find a job newspaper advertisements , \n",
            "Sentence before tokenization: Jazz Night At Hotel Nikko SF\n",
            "Sentence before tokenization: So I will watch it from my workplace .\n",
            "Sentence before tokenization: My weight is kg .\n",
            "Sentence before tokenization: Our Japan soccer team has won in all the games of the Asian cup so far .\n",
            "Sentence before tokenization: Part time job\n",
            "Sentence before tokenization: Normally , the weapon was not able to use with item , but the one handed sword can .\n",
            "Sentence before tokenization: The weather is not good recently .\n",
            "Sentence before tokenization: There is some methods of helping without getting into trouble , such as calling the police , taking pictures of the criminal and so on .\n",
            "Sentence before tokenization: There was the earthquake yesterday .\n",
            "Sentence before tokenization: I visited medical insurance company to consult about medical insurance that day .\n",
            "Sentence before tokenization: So , I m tired , besides , I am sleepy .\n",
            "Sentence before tokenization: My First Online English Lesson\n",
            "Sentence before tokenization: In the evening , I went away for a change of air .\n",
            "Sentence before tokenization: But is it good things for China at that time ?\n",
            "Sentence before tokenization: God bless you !\n",
            "Sentence before tokenization: Sum\n",
            "Sentence before tokenization: I development\n",
            "Sentence before tokenization: - English teacher for middle school student .\n",
            "Sentence before tokenization: And I took a lot of pictures there .\n",
            "Sentence before tokenization: He is talking with his mom on Skype .\n",
            "Sentence before tokenization: The fabric of the large pattern which seems to be North European is impressive .\n",
            "Sentence before tokenization: today is rainy .\n",
            "Sentence before tokenization: It becomes an onion gratin soup\n",
            "Sentence before tokenization: We are going to go to the shopping centre today .\n",
            "Sentence before tokenization: What kind of nation arrests foreigners for no reason ?\n",
            "Sentence before tokenization: Usually , I feel sleepy over o ' clock am .\n",
            "Sentence before tokenization: She also listed up Recommendations for Recovery and Forty things I needed the Most , and these are very informative .\n",
            "Sentence before tokenization: Mothers Day in Australia is tomorrow\n",
            "Sentence before tokenization: Reading books on a mobile phone .\n",
            "Sentence before tokenization: He looks not to like looking up the literature .\n",
            "Sentence before tokenization: I orderd to hamberger , And I have eating it on outside of the shop .\n",
            "Sentence before tokenization: So , I stayed in my house all day and read a book .\n",
            "Sentence before tokenization: I want to celebrate it , but I have no boyfriend .\n",
            "Sentence before tokenization: I think I learned more than I taught , and one of the things I learned is how hard it can be to study English .\n",
            "Sentence before tokenization: Do you believe in macro - anomalies ?\n",
            "Sentence before tokenization: Anyways , I want to know how this phenomenon happens in the brain completely .\n",
            "Sentence before tokenization: Whatever your dream is - study abroad , work in other culture , communicate with friends from other contries - it will come true with your little but continuous effort .\n",
            "Sentence before tokenization: At worse I have no enough experience about this , so can somebody help me ?\n",
            "Sentence before tokenization: That will born itself without you .\n",
            "Sentence before tokenization: What time is the best time ?\n",
            "Sentence before tokenization: I think he is cute !\n",
            "Sentence before tokenization: Instead of I wish the author had written more about it , he wrote .\n",
            "Sentence before tokenization: Second , I saw Jaisalmer .\n",
            "Sentence before tokenization: AV board , shelf and rack .\n",
            "Sentence before tokenization: I know learning German is one way , but many European people are really good at English .\n",
            "Sentence before tokenization: My neighbor TOTORO\n",
            "Sentence before tokenization: There are games on Thursday and I go to school .\n",
            "Sentence before tokenization: But I want to make my blog very interesting even if my mother tongue is not English .\n",
            "Sentence before tokenization: It seems like his blood test came out pretty good and the vet reduced his medicine a bit .\n",
            "Sentence before tokenization: Study English every day\n",
            "Sentence before tokenization: I asked my friend .\n",
            "Sentence before tokenization: I seem she was very fun and happy !\n",
            "Sentence before tokenization: laugh of my friends was heard in my ears .\n",
            "Sentence before tokenization: Recently we moved to this town for my husband is work .\n",
            "Sentence before tokenization: work overtime\n",
            "Sentence before tokenization: I work at a sheep meat factory .\n",
            "Sentence before tokenization: I hate this season , because everyday it is raining .\n",
            "Sentence before tokenization: There was a girl who made the special hat which Mad Hatter was wearing .\n",
            "Sentence before tokenization: Having read the book , I would gradually like to see my hero do something .\n",
            "Sentence before tokenization: Besides , they spent time very cleverly , because of which there was little time left to play .\n",
            "Sentence before tokenization: Then , when I overheard a police siren suddenly , he was captured for violation of over speed . \n",
            "Sentence before tokenization: Yesterday I went to KARAOKE with my friends .\n",
            "Sentence before tokenization: That is because I am a student .\n",
            "Sentence before tokenization: There are so many mistakes thay I did not implove .\n",
            "Sentence before tokenization: I will try to translate one Brazilian song !\n",
            "Sentence before tokenization: I went out for a drink at a pub as always early last night .\n",
            "Sentence before tokenization: Also , not just dealing with these problems , government should find the roots of crim .\n",
            "Sentence before tokenization: He is a pro snowboarder .\n",
            "Sentence before tokenization: Now I am drinking a can of beer at home , because the presentation has finished finally ! ! !\n",
            "Sentence before tokenization: To put priorities not on myself but on others .\n",
            "Sentence before tokenization: Nevertheless , my wife seems to be able to keep sleeping even under\n",
            "Sentence before tokenization: personnal changes\n",
            "Sentence before tokenization: By the way , I was received some presents from my teacher of Chinese today .\n",
            "Sentence before tokenization: Beautiful flowers blossom out in your footsteps .\n",
            "Sentence before tokenization: Such conducts are prohibited ethically my company .\n",
            "Sentence before tokenization: So we asked the front desk clerk whether we could change into another class .\n",
            "Sentence before tokenization: Old people tend to lose their health and , after their retirement , they tend to lose their purpose in life .\n",
            "Sentence before tokenization: Almost my classmates decided to take it , so finally I took part in it .\n",
            "Sentence before tokenization: For many years , Chinese poets have written about long lost lovers finding each other .\n",
            "Sentence before tokenization: Cosmetic surgery\n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: That is what I am wondering about my English might be getting worse .\n",
            "Sentence before tokenization: Piles of oranges and huge pans of paella are there ?\n",
            "Sentence before tokenization: Can you be the one to explain that for me ?\n",
            "Sentence before tokenization: I am writting this with a dictionary , but I wish I could write without it !\n",
            "Sentence before tokenization: demonstration class participation attendance other\n",
            "Sentence before tokenization: We were to be safe , but I want to run a risk to survey .\n",
            "Sentence before tokenization: I went to the beach with my friend yesterday , It was so fun !\n",
            "Sentence before tokenization: In this sentence , the three movies are products .\n",
            "Sentence before tokenization: The creators of this movie must be big fans of sci - fi , \n",
            "Sentence before tokenization: There is a masterpiece movie named Bicycle Thief in Italy .\n",
            "Sentence before tokenization: In those days all I wanted was just to know a few words so that I could say just a few sentences in class .\n",
            "Sentence before tokenization: I want to be a good teacher for my children , so I will study everything for teaching children very hard ! !\n",
            "Sentence before tokenization: But many Japanese do not agree with tax systems of these countries .\n",
            "Sentence before tokenization:  . Around to days later , the sporozoites develop by binary fission , and become the merozoites , which are haploid forms .\n",
            "Sentence before tokenization: Hi everyone .\n",
            "Sentence before tokenization: For example , even nowadays , some parents force their children to develop in their private opinion , but we now always recommend individual characters . Parents should not force their children to do what they want , but to help them to find and develop their own interests .\n",
            "Sentence before tokenization: For example , Pantenon in Rome uses a different kind of concrete from modern architecture .\n",
            "Sentence before tokenization: I was born and raised in Japan , and I guess you already know that .\n",
            "Sentence before tokenization: I m really moved .\n",
            "Sentence before tokenization: while they are still students .\n",
            "Sentence before tokenization: Then I got home and headed for hiking .\n",
            "Sentence before tokenization: Does someone know a English speaker who want to study Japanese .\n",
            "Sentence before tokenization: Main purpose of this travel is to see a soap factory in Corfu island .\n",
            "Sentence before tokenization: Now , we have to wait\n",
            "Sentence before tokenization: Christmas with comfortable temperature is very attractive for those people who have been tired of freezing - cold winter .\n",
            "Sentence before tokenization: Lumpini Park .\n",
            "Sentence before tokenization: Somehow , I am kind of missing them .\n",
            "Sentence before tokenization: I stocked many cup noodles in order to save my money .\n",
            "Sentence before tokenization: I should buy their performece tikects somehow .\n",
            "Sentence before tokenization: I am so pleased .\n",
            "Sentence before tokenization: My school starts summer vacation in August .\n",
            "Sentence before tokenization: Today s daily is a little bit long , is n t it ?\n",
            "Sentence before tokenization: When I driven my car , so it was very scary !\n",
            "Sentence before tokenization: For me , the typical one is that made of egg .\n",
            "Sentence before tokenization: Who has ever tried to take it ?\n",
            "Sentence before tokenization: now , I like read or movies !\n",
            "Sentence before tokenization: why did you become teacher ?\n",
            "Sentence before tokenization:  Sorry , I am not a native speaker , but I would say , These movies from A to G are famous each other . .\n",
            "Sentence before tokenization: What if the WW should happen between the U .\n",
            "Sentence before tokenization: But some pen I put in without using .\n",
            "Sentence before tokenization: Key words bamboo charcoal fabric , derivation weave , derivation weft , directionality of tensile properties\n",
            "Sentence before tokenization: However , It was difficult for me to understand English then .\n",
            "Sentence before tokenization: This is a fairyland I think !\n",
            "Sentence before tokenization: One is that I steamed apples , sweet potatoes and dried prunes without any seasonings .\n",
            "Sentence before tokenization: Since then , there had been a whining sound every night .\n",
            "Sentence before tokenization: He gave me advice , explaining legal bases related my case mainly in technical terms .\n",
            "Sentence before tokenization: He is a very direct man .\n",
            "Sentence before tokenization:  We do not need toothpaste , and we should use a very soft brush for cleaning all over our teeth . \n",
            "Sentence before tokenization: Have a nice weekends .\n",
            "Sentence before tokenization: It ' summer time !\n",
            "Sentence before tokenization: Please check the audio file from above .\n",
            "Sentence before tokenization: She had an English trial lesson before , so she seemed to feel relaxed a little bit .\n",
            "Sentence before tokenization: I love to watch many movies .\n",
            "Sentence before tokenization: Therefore , I worked concentrated and did many things .\n",
            "Sentence before tokenization: It is very interesting !\n",
            "Sentence before tokenization: I felt a little sick .\n",
            "Sentence before tokenization: We successfully got the papers and quickly returned home .\n",
            "Sentence before tokenization: I think elevator is breaking and to be in a hurry .\n",
            "Sentence before tokenization: What is the difference between the sentences below\n",
            "Sentence before tokenization: In Japan , more and more people are starting it .\n",
            "Sentence before tokenization: I used to have a lunch , watch movies , go shopping and go to somewhere with her .\n",
            "Sentence before tokenization: I could not follow scenes and subs when I watched ' Transformers ' with D because it moved very quickly and were busy , so this time , I could easy watch ' Green Lantern ' .\n",
            "Sentence before tokenization: But I ca not do that now .\n",
            "Sentence before tokenization: So I always had expectation of gratitude from others who were treated with kidness by me , and I was angry when they disappointed me .\n",
            "Sentence before tokenization: He said the importance of being ernest and thinking ernestly .\n",
            "Sentence before tokenization: By the way , about your last question , I disagree with arranging marriages .\n",
            "Sentence before tokenization: On TV , there was a years old girl interviewed in Vancouver .\n",
            "Sentence before tokenization: In my country there are many Internet users and more mobile - phone subscribers .\n",
            "Sentence before tokenization: I took a day off yesterday , so I went to my daughter s elementary school for picking her that afternoon .\n",
            "Sentence before tokenization: If you are interested , please read previous ones and correct them as well .\n",
            "Sentence before tokenization: Anciently it is usual for children to take care of old people .\n",
            "Sentence before tokenization: I am really looking forward to working there .\n",
            "Sentence before tokenization: Reporter Good morning , Linda !First of all , thank you for accepting our invitation !\n",
            "Sentence before tokenization: If you have the idea of a well - balanced meal or good exercise , please tell me !\n",
            "Sentence before tokenization: Because they are .\n",
            "Sentence before tokenization: We have seen people coming .\n",
            "Sentence before tokenization: After that , we decided to go home at am .\n",
            "Sentence before tokenization: Advance in technology have made using the library more convenient .\n",
            "Sentence before tokenization: email to my teacher\n",
            "Sentence before tokenization: It was not a bit of a problem for me because I was full of expectation and pleasure that I was going to see the exhibition at last !\n",
            "Sentence before tokenization: The problem is GRE is going to be revised from August , and it is becoming more difficult for Japanese probably .\n",
            "Sentence before tokenization: I have studied English for years .\n",
            "Sentence before tokenization: English pronunciation is difficult .\n",
            "Sentence before tokenization: The first is Jaca .\n",
            "Sentence before tokenization: It has young man and middle woman that they fell in love at first sight .\n",
            "Sentence before tokenization: A new fiscal year just started today , st April !\n",
            "Sentence before tokenization: My wife will give birth at the end of this month .\n",
            "Sentence before tokenization: All the things in this world are alway changing and Hope will always wait you just around the corner .\n",
            "Sentence before tokenization: And this time , I bought English books .\n",
            "Sentence before tokenization: Bye bye vacations .\n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: That is all for today .\n",
            "Sentence before tokenization: I could not sell my service without their supports .\n",
            "Sentence before tokenization: Every day\n",
            "Sentence before tokenization: However , it is going to be raining for a week in Korea .\n",
            "Sentence before tokenization: In the class , students make presentations about their research .\n",
            "Sentence before tokenization: The last third picture shows\n",
            "Sentence before tokenization: It is remarkable to plan it years ago .\n",
            "Sentence before tokenization: I felt absolutely refreshed by the good smell and beautiful flowers .\n",
            "Sentence before tokenization: So , this weeks I sleep many times .\n",
            "Sentence before tokenization: In , the president of America Calvin Coolidge suggested setting up Father is Day as the national day to build a closer band between fathers and children and make fathers aware of their responsibilities .\n",
            "Sentence before tokenization: of my department officers were moved elsewhere .\n",
            "Sentence before tokenization: the first day\n",
            "Sentence before tokenization: It was the first snow of last year ! I ca not forget it !\n",
            "Sentence before tokenization: She did not spiritless , so I and other friends gave her a lift .\n",
            "Sentence before tokenization: See you later .\n",
            "Sentence before tokenization: She must have thought ' I want to eat eels .\n",
            "Sentence before tokenization: I bought a bag at Grace Continental on Thursday .\n",
            "Sentence before tokenization: I ran into friend who I have not seen for a long time on the subway .\n",
            "Sentence before tokenization: There are a couple of theories why the singularity happens .\n",
            "Sentence before tokenization: It was yummy !\n",
            "Sentence before tokenization: So , I clened my room very hard .\n",
            "Sentence before tokenization: There is a famous saying Neither friends nor trivals are everlasting , but only profits . If we want to get more interests , we should cooperate , not against .\n",
            "Sentence before tokenization: I know I need some maintenance for the house .\n",
            "Sentence before tokenization: I wandered around Shibuya for a short while .\n",
            "Sentence before tokenization: Tonight , I will go to watch basketball game , Hannaryz vs Phoenex .\n",
            "Sentence before tokenization: I bought a movie from the iphone app store today .\n",
            "Sentence before tokenization: My father , mother , brother and me .\n",
            "Sentence before tokenization: Also we can recognize our progress status at graphs .\n",
            "Sentence before tokenization: I get thirsty .\n",
            "Sentence before tokenization: How stupid they were ?\n",
            "Sentence before tokenization: i m curious , all of a sudden ! !\n",
            "Sentence before tokenization: In the course of the ride , we witnessed a spider is web , which looked brand - new and shining reflecting fresh morning dew .\n",
            "Sentence before tokenization: The last third picture shows\n",
            "Sentence before tokenization: But it seems impossible today .\n",
            "Sentence before tokenization: Kamehameha is No . from a questionnaire .\n",
            "Sentence before tokenization: All the animals on the breeding farm always walk around in small cages .\n",
            "Sentence before tokenization: I like English very much .\n",
            "Sentence before tokenization: Nowadays people have become more and more aware of the significance of education .\n",
            "Sentence before tokenization: Watching the sea condition , they seemed to hesitate like us .\n",
            "Sentence before tokenization: My eyes stung from the contact lenses .\n",
            "Sentence before tokenization: In addition , there are good websites where you can play shogi for free .\n",
            "Sentence before tokenization: My name is mimoza .\n",
            "Sentence before tokenization: There is your future , if you reach out .\n",
            "Sentence before tokenization: A family got on it , and they sat behind me .\n",
            "Sentence before tokenization: A Leisurely Day\n",
            "Sentence before tokenization: It is so long .\n",
            "Sentence before tokenization: She is very cute and nice .\n",
            "Sentence before tokenization: Our trip was interesting .\n",
            "Sentence before tokenization: So I have become lazy , for instance , slept until pm , watching TV for about hours and did not do anything .\n",
            "Sentence before tokenization: Suddenly , my dog woke up , jumped and started running after . something .\n",
            "Sentence before tokenization: I have been busy .\n",
            "Sentence before tokenization: I was wondering if anyone could tell me another way to say it , please .\n",
            "Sentence before tokenization: I do not no why some - how I got teary eyes .\n",
            "Sentence before tokenization: All teachers are very good persons .\n",
            "Sentence before tokenization: frightening\n",
            "Sentence before tokenization: I have been excited and really wanted to see this movie since a month ago .\n",
            "Sentence before tokenization: I told her that I am a gentleman and know how to behave myself , but\n",
            "Sentence before tokenization: Yeah , actually , the character is a baby .\n",
            "Sentence before tokenization: years of age - That old woman ?\n",
            "Sentence before tokenization: I want to write about my favorite shooting game series , which is Touhou .\n",
            "Sentence before tokenization: Workaholic Japanese is a past tale\n",
            "Sentence before tokenization: especially fat people really dangerous\n",
            "Sentence before tokenization: Shocked me .\n",
            "Sentence before tokenization: In Japan , there are only three sizes of dresses in a general way .\n",
            "Sentence before tokenization: CONGRATULATION IS EQUIVALENT NO JOB\n",
            "Sentence before tokenization: But , my feelings like ' I did it ! ! ' or some different environment than usual let me have a tolerance , I think .\n",
            "Sentence before tokenization: Thank you for your email and sending me the detailed TV commercial script .\n",
            "Sentence before tokenization: Get up\n",
            "Sentence before tokenization: i really like cooking .\n",
            "Sentence before tokenization: Anyway , finishing the presentation was a big load off my mind .\n",
            "Sentence before tokenization: I love this sentence the best\n",
            "Sentence before tokenization: With all due respect , I am so tired I just want to take a rest .\n",
            "Sentence before tokenization: And the dances were in the orbit of the planets .\n",
            "Sentence before tokenization: There was nothing special about it , apart from the fact that my face in the photo on my new license card looked a bit fatter than my previous one .\n",
            "Sentence before tokenization: After your correction , I will upload the sentence here again , and hope you read the sentences in English so I can practice pronunciation .\n",
            "Sentence before tokenization: Sentences For Practice\n",
            "Sentence before tokenization: This is one of my favorites !\n",
            "Sentence before tokenization: In much the same way , Japanese pronunciation of English tends to sound strange to you .\n",
            "Sentence before tokenization: I have change my work time again .\n",
            "Sentence before tokenization: I also intended to understand the lectures there deeply .\n",
            "Sentence before tokenization: Foreign foods are an average , How much do foods cost ?\n",
            "Sentence before tokenization: However , it is already , I have to go to bed to have a refreshing morning tomorrow .\n",
            "Sentence before tokenization: were be happy because Waddah that a famous magician come and they ask him to help them .\n",
            "Sentence before tokenization: Lady GaGa\n",
            "Sentence before tokenization: The army of the west is advantageous .\n",
            "Sentence before tokenization: We are going into the forest to pick up firewoods for winter today .\n",
            "Sentence before tokenization: His voice was amazing !\n",
            "Sentence before tokenization: It is not until you fail that you realize what your life is like .\n",
            "Sentence before tokenization: I have no time to rest because of work .\n",
            "Sentence before tokenization: I am not good at play snowboard .\n",
            "Sentence before tokenization: About my American friend\n",
            "Sentence before tokenization: I am always tired nowdays .\n",
            "Sentence before tokenization: My summer vacation was finished\n",
            "Sentence before tokenization: An American swimmer attained gold medals .\n",
            "Sentence before tokenization: Hello , everyone ! \n",
            "Sentence before tokenization: I studied English this morning .\n",
            "Sentence before tokenization: Chalmers Street\n",
            "Sentence before tokenization: This research was done during the period from August to September .\n",
            "Sentence before tokenization: Therefore , it was always angry to me from the teacher at the school .\n",
            "Sentence before tokenization: So I will use this phrase to make sentences .\n",
            "Sentence before tokenization: In the US , there are many student studying abroad .\n",
            "Sentence before tokenization: If you want to meet him , you should be away from Tokyo .\n",
            "Sentence before tokenization: I have a English workshop with my friends .\n",
            "Sentence before tokenization: We enjoyed surfboarding at the sea in the every morning .\n",
            "Sentence before tokenization: That is it for today .\n",
            "Sentence before tokenization: Which season of the year do you like the best ?\n",
            "Sentence before tokenization: Firstly , we usualy get many latest machines , for example , PC , mobile phone .\n",
            "Sentence before tokenization: I must doing my homework quickly .\n",
            "Sentence before tokenization: I love to drive a car with my friend or my wife .\n",
            "Sentence before tokenization: I want everyone to know how interesting the Japanese is .\n",
            "Sentence before tokenization: When I thought of what I can do for my country and those who live there , I came up with the idea of joining the Military to become a pilot .\n",
            "Sentence before tokenization: I askd to him that introduced English teacher to mine .\n",
            "Sentence before tokenization: By the way , I received some presents from my Chinese teacher today .\n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: I ca not speak English .\n",
            "Sentence before tokenization: during I saw the movie I thought war is never happend again\n",
            "Sentence before tokenization: I will go to Europe on the summer vacation .\n",
            "Sentence before tokenization: Today , I introduce my favorite band .\n",
            "Sentence before tokenization:  With the bell pushed for many times , he finally answered the door with reluctance .\n",
            "Sentence before tokenization: Others are in relationships and will settle down soon I think .\n",
            "Sentence before tokenization: It just happened that I feel that the same day is intended by someone .\n",
            "Sentence before tokenization: aroud seoul with my car\n",
            "Sentence before tokenization: After the surprise , I saw the shop more carefully .\n",
            "Sentence before tokenization: So I search content of some work .\n",
            "Sentence before tokenization: This movie was made in Russia and was released last year .\n",
            "Sentence before tokenization: i am so nervous .\n",
            "Sentence before tokenization: There are many foreigner staff who speak English fluently and Japanese people want to improve their English skills .\n",
            "Sentence before tokenization: Yesterday was the th anniversary of John Lennon is death .\n",
            "Sentence before tokenization: BUT Ransom did nt get it and is still talking crap at me .\n",
            "Sentence before tokenization: First of all , there might be good traffic without waiting too much time so that I do nt have to waste time commuting between home and office .\n",
            "Sentence before tokenization: So far , I have written about journal entries on Lang - and taken about online English conversation lessons since February .\n",
            "Sentence before tokenization: This video is about a dog which wants to do something to a statue ?\n",
            "Sentence before tokenization: It is hard to convey all my idea in only pages , so I will write my thesis as a detailed version of the article .\n",
            "Sentence before tokenization: Next week I am going to apply some prestigious university in England .\n",
            "Sentence before tokenization: Mother took heed of each of our worries and helped us overcome them .\n",
            "Sentence before tokenization: Am I right about these understandings ?\n",
            "Sentence before tokenization: Also , I can help you to study Chinese .\n",
            "Sentence before tokenization: But it s very hot , easy to get tired .\n",
            "Sentence before tokenization: Samuel Wood and Andrew French , scientific officer in California s Stemagen Corporation Lab , created five cloned human embryos , which were said to be later destroyed .\n",
            "Sentence before tokenization: That is why I was annoyed .\n",
            "Sentence before tokenization: But It also showed the world is coming to end by .\n",
            "Sentence before tokenization: Part time job\n",
            "Sentence before tokenization: I know well how she is feeling now .\n",
            "Sentence before tokenization: Well , maybe it is a good thing because it does not go badly .\n",
            "Sentence before tokenization: The Championships , Wimbledon\n",
            "Sentence before tokenization: If I can not enter the History class , my chances of entering university will definitely grow slimmer .\n",
            "Sentence before tokenization: I have lived in Memuro town for the whole five years .\n",
            "Sentence before tokenization: I sometimes watch movie and confirm my e - mail .\n",
            "Sentence before tokenization: Today , I am updating this accout by using my mobile phone .\n",
            "Sentence before tokenization: Most of Japaneses students start our English educations from this conversations .\n",
            "Sentence before tokenization: Usually almost Japanese get a days which is nice .\n",
            "Sentence before tokenization: I especially use some of the Firefox addons\n",
            "Sentence before tokenization: After about hour , I arrived at my new home .\n",
            "Sentence before tokenization: See you later !\n",
            "Sentence before tokenization: Summer Sonic\n",
            "Sentence before tokenization: This is a ride .\n",
            "Sentence before tokenization: Although history is the past , our attitude is very important as it will influence our posterity .\n",
            "Sentence before tokenization: Is TOEIC getting more difficult or my English skills getting worse ?\n",
            "Sentence before tokenization: This year , I hope that I can try to use this way to cook the rice balls .\n",
            "Sentence before tokenization: But this is an interesting movie .\n",
            "Sentence before tokenization: In fact , I am not sure how this system works .\n",
            "Sentence before tokenization: I am a high school student .\n",
            "Sentence before tokenization: In short , even if American solders arrived in Okinawa , we never surrendered the War .\n",
            "Sentence before tokenization: Today , I went to get a part - time job .\n",
            "Sentence before tokenization: I did nt have any reason not to join it ! !\n",
            "Sentence before tokenization: And she is invit me to go on cinema , Of course i said .\n",
            "Sentence before tokenization: The first day of Lang - !\n",
            "Sentence before tokenization: Translated version\n",
            "Sentence before tokenization: A hamburger made by MOS is so delicious and healthy .\n",
            "Sentence before tokenization: Brandon and Seth were better than Hunter at playing billiards .\n",
            "Sentence before tokenization: In short , the twentieth century has brought many facilities for the current generation .\n",
            "Sentence before tokenization: Thanks everyone !\n",
            "Sentence before tokenization: Good day .\n",
            "Sentence before tokenization: About a week ago , we moved into the new apartment .\n",
            "Sentence before tokenization: Indeed , two youngers were murdered by gangs .\n",
            "Sentence before tokenization: When the seminar ended , I was thinking that , it was time for me to have a healthy lifestyle .\n",
            "Sentence before tokenization: Today , I watched a movie The King is Speech .\n",
            "Sentence before tokenization: I look forward to the latter part shown in spring .\n",
            "Sentence before tokenization: All the hobbies I have are very expensive .\n",
            "Sentence before tokenization: I have a restaurant here in Japan .\n",
            "Sentence before tokenization: My school is two years college , so I will transfer to another years university and I will take a class two years .\n",
            "Sentence before tokenization: THe other reason is that i would like to enjoy the life filled with pression .\n",
            "Sentence before tokenization: When I was a high school student , I did not like it either .\n",
            "Sentence before tokenization: My name is nuk .\n",
            "Sentence before tokenization: He is an iron man !\n",
            "Sentence before tokenization: Then he was brought in America on the ship , and sold on Wednesday June th , at o ' clock , at Bank is arcade , with women and other men .\n",
            "Sentence before tokenization: Probably , he talked about something related to Christianity but it could not catch his words .\n",
            "Sentence before tokenization: Listen to me , please everyone .\n",
            "Sentence before tokenization: happy to hear from you !\n",
            "Sentence before tokenization: I wasted all the day watching YouTube .\n",
            "Sentence before tokenization: Recently , it is not rain .\n",
            "Sentence before tokenization: Next weekend , I am going to a diving school to get a diving licence .\n",
            "Sentence before tokenization: I hope today will be good day .\n",
            "Sentence before tokenization: I came to Australia months ago and am still living here .\n",
            "Sentence before tokenization: vaporize and evaporate .\n",
            "Sentence before tokenization: My school is exam is very difficult , so I could not solve it .\n",
            "Sentence before tokenization: I would like to know\n",
            "Sentence before tokenization: I want to keep a diary for as long as possible .\n",
            "Sentence before tokenization: I know Bob is not that into you . means Bob does not like you very much . or something like that .\n",
            "Sentence before tokenization: Do you know a PC room ?\n",
            "Sentence before tokenization: I took same picture .\n",
            "Sentence before tokenization: Teen Girl\n",
            "Sentence before tokenization: I could not go to the live concert hall because I had to take the trumpet lesson .\n",
            "Sentence before tokenization: I had written a bit more for this part , but I thought it is getting too long .\n",
            "Sentence before tokenization: All right !\n",
            "Sentence before tokenization: When I reached the shop at minutes to , several people are already waiting in a line in front of the shop .\n",
            "Sentence before tokenization: I think I need to listen to his live music as soon as possible .\n",
            "Sentence before tokenization: posted at\n",
            "Sentence before tokenization: Change my cellphone\n",
            "Sentence before tokenization: Also , nearby areas are overgrown with many wildflowers .\n",
            "Sentence before tokenization: I study the comments and corrections for my diary .\n",
            "Sentence before tokenization: I want to sleep in on holiday , at least .\n",
            "Sentence before tokenization: I have been reading The Snows of Kilimanjaro by Ernest Hemingway this week .\n",
            "Sentence before tokenization: I want to be them even I age .\n",
            "Sentence before tokenization: Toady I start to take Lang - diary .\n",
            "Sentence before tokenization: Cherry blossom is my favorite flower\n",
            "Sentence before tokenization: It is a good thing I recall this site .\n",
            "Sentence before tokenization: DO NOT BE HUBRIS .\n",
            "Sentence before tokenization: My TOEIC target score is .\n",
            "Sentence before tokenization: Preventive measure on cold .\n",
            "Sentence before tokenization: So I do not have much time to write this journal entry because I have to get ready to go school before I go to bed .\n",
            "Sentence before tokenization: What we did are playing video games , playing some sports and so on .\n",
            "Sentence before tokenization: I know that we ca not go back to common friends . Hopefully , you will find a soul mate soon , and forget how unhappy we were when we were in a relationship in the past .\n",
            "Sentence before tokenization: I still do not have enough English skills to keep up with my classes with local\n",
            "Sentence before tokenization: And also I do not get an Undeliverable Item Notice\n",
            "Sentence before tokenization: I need your help ! !\n",
            "Sentence before tokenization: I watched the game from the right field seat , where fans can stand , cheer on , sing songs for the players .\n",
            "Sentence before tokenization: We captured the beautiful beach long time ! !\n",
            "Sentence before tokenization: very hard times .\n",
            "Sentence before tokenization: I stop and look around .\n",
            "Sentence before tokenization: I think the word suspicious is ambiguous .\n",
            "Sentence before tokenization: Going to future expresses a conclusion regarding the immediate future or an action in the near future that has already been planned or prepared .\n",
            "Sentence before tokenization: Because I m not American ?\n",
            "Sentence before tokenization: Finaly , I will get I - from University where I want to go !\n",
            "Sentence before tokenization: I think there are at least three types of beer .\n",
            "Sentence before tokenization: After it , moreover , english class will be start from to .\n",
            "Sentence before tokenization: And the might change too !\n",
            "Sentence before tokenization: It was sunny day .\n",
            "Sentence before tokenization: I have a role - play in my book .\n",
            "Sentence before tokenization: We can learn a lot from the past .\n",
            "Sentence before tokenization: At first nothing was on the desk , but there was only a desktop computer .\n",
            "Sentence before tokenization: But I saw that she was still a bit sad .\n",
            "Sentence before tokenization: And more , I can stand without smoking at all for a couple of days !\n",
            "Sentence before tokenization: It also is difficult now .\n",
            "Sentence before tokenization: The spread of rice farming\n",
            "Sentence before tokenization: - All he had to do was to say no\n",
            "Sentence before tokenization: the legs like Japanese radishes\n",
            "Sentence before tokenization: I am also learning Japanese , but to be a free user here , I ca not choose more than foreign languages to learn .\n",
            "Sentence before tokenization: There are lots of things I am not proficient at enough .\n",
            "Sentence before tokenization: Hi everybody .\n",
            "Sentence before tokenization: It was very big and there were many people there .\n",
            "Sentence before tokenization: For example , I had to go home by O ' clock untill graduated highschool and I could not leave any food even a grain of rice .\n",
            "Sentence before tokenization: Is this a good self - introduction ?\n",
            "Sentence before tokenization: Although our journey ended with serious sickness , many of us got a fever or problems with our stomach .\n",
            "Sentence before tokenization: Hello everybody .\n",
            "Sentence before tokenization: January th is the Three Wise Men Day .\n",
            "Sentence before tokenization: I will try my best and you should try your best for your dream .\n",
            "Sentence before tokenization: I need something to write with .\n",
            "Sentence before tokenization: If I borrow a DK room , it would cost a rent for yen yen .\n",
            "Sentence before tokenization: First and greatest holiday of the New Testament church is celebrating of Easter .\n",
            "Sentence before tokenization: I was taught this cite by my friend , and I got the urge to memorize it .\n",
            "Sentence before tokenization: Because my English is not fluent .\n",
            "Sentence before tokenization: My current job\n",
            "Sentence before tokenization: Actually , I am not involved with it at the moment because my part is as a cashier .\n",
            "Sentence before tokenization: But I think there is another reason .\n",
            "Sentence before tokenization: We should take immediate action to the problems .\n",
            "Sentence before tokenization: since we do not want to make him or her feel unpleasant by denying his or her opinion .\n",
            "Sentence before tokenization: becuse i .\n",
            "Sentence before tokenization: Commuting on the first day\n",
            "Sentence before tokenization: Because I ca not meet friends .\n",
            "Sentence before tokenization: When I cry , she comes to me and licks my hand .\n",
            "Sentence before tokenization: I hope to do this job well .\n",
            "Sentence before tokenization: The three things will cost me a pretty penny .\n",
            "Sentence before tokenization: My pants under the scrub gown gradually slid down because I had not tied the waist lace of the pants fast .\n",
            "Sentence before tokenization: Most Koreans might hate TOEIC .\n",
            "Sentence before tokenization: i am a new user of lang , actually i do nt know how to use this website well .\n",
            "Sentence before tokenization: We made pair with next person and practiced in this lecture .\n",
            "Sentence before tokenization: It has become too long .\n",
            "Sentence before tokenization: I still feel nervous when I sit in my seat because my boss is seat is next to me .\n",
            "Sentence before tokenization: but we do not want to spend so much money .\n",
            "Sentence before tokenization: Today , I had my colleague teach me how to use the equipment for thermal evaporation .\n",
            "Sentence before tokenization: He checked my lower back as he was pushing with his hands roughly .\n",
            "Sentence before tokenization: So we did not worry so much .\n",
            "Sentence before tokenization: It is knock on my door\n",
            "Sentence before tokenization: Link A lot of handmade carp steamers swimming in the sky .\n",
            "Sentence before tokenization: I wanted to quit this job many times on winter in particular .\n",
            "Sentence before tokenization: Hot Summer Day\n",
            "Sentence before tokenization: But I found it difficult to stand .\n",
            "Sentence before tokenization: Shortly , a SOS system like Superman and an angel\n",
            "Sentence before tokenization: Will they come next year ?\n",
            "Sentence before tokenization: All the newspaper headline have reported about Japan is Earthquake and the nuclear plant for the past days .\n",
            "Sentence before tokenization: and the lack of supplies in the cities is continuing .\n",
            "Sentence before tokenization: Some people disagree with this policy , and mention that their salaries should not be too higher than ordinary people is , another group agrees with this policy .\n",
            "Sentence before tokenization: For example , Valentines Day , of course , I will stay with my girlfriend .\n",
            "Sentence before tokenization: Today the Gion festival parade was held in Kyoto .\n",
            "Sentence before tokenization: On th - Jan . , I left Japan and th - Jan .\n",
            "Sentence before tokenization: I am getting ready for a trip\n",
            "Sentence before tokenization: But I have a feeling in my heart that it is possible that I can to that by experience .\n",
            "Sentence before tokenization: no reality\n",
            "Sentence before tokenization: Good night .\n",
            "Sentence before tokenization: I like to get advice from older friends , because they have more experience .\n",
            "Sentence before tokenization: It has various beautiful shapes and meanings .\n",
            "Sentence before tokenization: I liked it .\n",
            "Sentence before tokenization: tossing their heads in a sprightly dance .\n",
            "Sentence before tokenization: But we will have series of holiday five days ! !\n",
            "Sentence before tokenization: And could I have your number ?\n",
            "Sentence before tokenization: I tried to understand like we have not been in the same place , so this is normal .\n",
            "Sentence before tokenization: Nowadays , my mind is stuck .\n",
            "Sentence before tokenization: please correct in writing .\n",
            "Sentence before tokenization: I slept today at night autonomy studying time .\n",
            "Sentence before tokenization: I had an English lesson at an English school today .\n",
            "Sentence before tokenization: Contrary to their attempt to show their strong attitude , I notice they need to offend others to hold their self - esteem , thus they depend on external factors as offending others is often seemed as a sign of insecurity or low self - esteem .\n",
            "Sentence before tokenization: Sometimes I write a scientific paper about my study in English .\n",
            "Sentence before tokenization: yesterday a colleague of mine left this company .\n",
            "Sentence before tokenization: There was no opportunity to do volunteer work .\n",
            "Sentence before tokenization: Although I was like , hmm , it was a good explanation .\n",
            "Sentence before tokenization: But I did not know what to do .\n",
            "Sentence before tokenization: Actually , I think it is at the beginning , but let me finish .\n",
            "Sentence before tokenization: But it still has not solved .\n",
            "Sentence before tokenization: Meanwhile , there is an issue about what they are called .\n",
            "Sentence before tokenization: I think it is good to share grief and joy but it happens so often .\n",
            "Sentence before tokenization: All I did today was try to read a book and sleep on it and wake up , then I tried again and slept again .\n",
            "Sentence before tokenization: That is why I am forced to use the old bad puffer on Android .\n",
            "Sentence before tokenization: I felt this view probably had lasted for thousands of years .\n",
            "Sentence before tokenization: This is the company that I think is doing what I want to do and making stakeholders happy .\n",
            "Sentence before tokenization: Good evening everyone !\n",
            "Sentence before tokenization: Table cloth\n",
            "Sentence before tokenization: Whatever their bicycles are for child size .\n",
            "Sentence before tokenization: I promise that you will be trapped in fantastic Mexican cuisine\n",
            "Sentence before tokenization: I work a lot , and when resting , I try to spend time with my friends .\n",
            "Sentence before tokenization: Both are fermented rice , and traditional drink .\n",
            "Sentence before tokenization: Senegalese men can be so gullible .\n",
            "Sentence before tokenization: I have nothing to fear .\n",
            "Sentence before tokenization: Hello my name is Pekari .\n",
            "Sentence before tokenization: elephant elephant\n",
            "Sentence before tokenization: This is enough in almost all cases .\n",
            "Sentence before tokenization: Would someone please check my diary entry ?\n",
            "Sentence before tokenization: This is my visitation gift for you .\n",
            "Sentence before tokenization: Now try to start to learn English .\n",
            "Sentence before tokenization: He told me that there is fantastic event in this jail .\n",
            "Sentence before tokenization: On April th , a British guy crashed local election activity in Chiba .\n",
            "Sentence before tokenization: So patience for new reactions must enable me to affirm and love my life more profoundly .\n",
            "Sentence before tokenization: That s why my English is broken\n",
            "Sentence before tokenization: I strongly recommend you go there at least once in your life !\n",
            "Sentence before tokenization: Juliet asked a priest for help , and the priest had a plan so that Juliet could pretend to take poison to commit suicide and he could tell the truth to Romeo on time .\n",
            "Sentence before tokenization: As for Japanese comics , called manga , One Peace is the most famous of them all in Japan .\n",
            "Sentence before tokenization: I think she quitted the negotiation after that and asked me to recommend her to my friends if they wanted to learn English .\n",
            "Sentence before tokenization: The Airline reminds all that only citizens of Russian Federation at the age under years old and over years old are permitted for this special price .\n",
            "Sentence before tokenization: But it is hard for me to do that .\n",
            "Sentence before tokenization: Well , Japanese is very complexed .\n",
            "Sentence before tokenization: I will still use the same words , structures , and patterns .\n",
            "Sentence before tokenization: i had looked for house in this morning\n",
            "Sentence before tokenization: I have an increased appetite these days .\n",
            "Sentence before tokenization: Today was .\n",
            "Sentence before tokenization: Finally he arrested yesterday .\n",
            "Sentence before tokenization: Should I take a hair of the dog ? ?\n",
            "Sentence before tokenization: hi everyone\n",
            "Sentence before tokenization: And the sharks without their fins are destined to die .\n",
            "Sentence before tokenization: She has received great respect and love from Japanese citizens as a Judo star .\n",
            "Sentence before tokenization: At the time , some of them asked me that I could open my mouth and show them my tooth .\n",
            "Sentence before tokenization: But I do not have a driver is license .\n",
            "Sentence before tokenization: Perhaps from the middle of next week the rainy season will start .\n",
            "Sentence before tokenization: I am a little disappointed with this movie .\n",
            "Sentence before tokenization: Also , customers who bought the promoted products usually had good experience and impression of the products .\n",
            "Sentence before tokenization: She is absolutely worried about it .\n",
            "Sentence before tokenization: No thumbing , no reading whole book to find one little thing .\n",
            "Sentence before tokenization: ?\n",
            "Sentence before tokenization: test xo\n",
            "Sentence before tokenization: I do not know details of that but I am excited to hear that .\n",
            "Sentence before tokenization: But the author said to us that the ability they have is given from being born .\n",
            "Sentence before tokenization: That is why I ca not have a dog .\n",
            "Sentence before tokenization: I used to bring my notebook to note down new vocabulary and my translator to help me look it up .\n",
            "Sentence before tokenization: we should not be scared when tackling oral skills , we should just speak up to our mind and try our best to express ourselves .\n",
            "Sentence before tokenization: A number of people maintain that movies and televisions always need to show audience good people are rewarded and notorious people are punished .\n",
            "Sentence before tokenization: He always has his own spectacular opinion .\n",
            "Sentence before tokenization: Many personal experiences do nt mean the equivalent of remarkable experiences .\n",
            "Sentence before tokenization: Sport is very important for health maintenance .\n",
            "Sentence before tokenization: The fortune - teller uses like their looks , birthday and name to judge someone s future .\n",
            "Sentence before tokenization: It is only years old , but there are very talanted actors and actresses .\n",
            "Sentence before tokenization: I am Japanese .\n",
            "Sentence before tokenization: And this time , I boght English books .\n",
            "Sentence before tokenization: Hello everyone , I have not written a diary for a long time .\n",
            "Sentence before tokenization: It took three hours to finish everything .\n",
            "Sentence before tokenization: I am going to graduate from my graduate school next March and start to work for a firm in Tokyo next April .\n",
            "Sentence before tokenization: This song became famous in France is FIFA World Cup national team , which liked to sing in chorus .\n",
            "Sentence before tokenization: I ca not wait ! !\n",
            "Sentence before tokenization: The computer security examination will come in days after .\n",
            "Sentence before tokenization: I feel much relieved now .\n",
            "Sentence before tokenization: Why did not I review it then ?\n",
            "Sentence before tokenization: Anyway this car looks cool .\n",
            "Sentence before tokenization: Anyway , I hope to improve my skill in this field and to be able to use them effectively .\n",
            "Sentence before tokenization: We had to wait minutes , so we went walking around and windowshopping while waiting .\n",
            "Sentence before tokenization: it was the cafe ! ! !\n",
            "Sentence before tokenization: Everyone , please help me to correct the mistakes . Thank you very much .\n",
            "Sentence before tokenization: However it is good to think about it .\n",
            "Sentence before tokenization: I found it just now because I am actually writing a private article in English . It is the first time for me .\n",
            "Sentence before tokenization: As I said earlier , they might dislike modifying , yet they come by what s significant to succeed in life .\n",
            "Sentence before tokenization: I want to know the words of a song for a reason .\n",
            "Sentence before tokenization: I receive a TOEIC test next month .\n",
            "Sentence before tokenization: It seems then , that we could choose our roommate or colleague .\n",
            "Sentence before tokenization: American life\n",
            "Sentence before tokenization: Good morning ! !\n",
            "Sentence before tokenization: Yesterday was my last day at English school in Vancouver !\n",
            "Sentence before tokenization: What kind of animal do you see on the moon ?\n",
            "Sentence before tokenization: I sometimes watch an English drama called Dollhouse on the way home .\n",
            "Sentence before tokenization: A Are you going to Tokyo tomorrow ?\n",
            "Sentence before tokenization: So , I usually jog and exercise a lot and break a sweat before drinking beer .\n",
            "Sentence before tokenization: But to improve my English skills , I watched and will watch .\n",
            "Sentence before tokenization: It seems that I have had a cold , but I have a good appetite and do not have a fever .\n",
            "Sentence before tokenization: Modern refrigerators can make ice .\n",
            "Sentence before tokenization: Especially , rhythm has mysterious power which has not elucidated yet .\n",
            "Sentence before tokenization: Please teach me an efficient way to learn Chinese ! !\n",
            "Sentence before tokenization: I will work as a chemist , so I will have to use English .\n",
            "Sentence before tokenization: - I like to study in the morning .\n",
            "Sentence before tokenization: They got a box from the wrecked ship and there was a map in it .\n",
            "Sentence before tokenization: High blood pressure or diabetes are major health problems caused by obesity .\n",
            "Sentence before tokenization: I fell very love that relationship between two cats .\n",
            "Sentence before tokenization: I wonder if the safety and toughness of it would be alright .\n",
            "Sentence before tokenization: japan and korea is really close , so we can meet sometimes , i suppose .\n",
            "Sentence before tokenization: I have not contacted them for a very long time , because when we graduate from college , we are busy with ourselves new job or study .\n",
            "Sentence before tokenization: Where do you go for relaxation ?\n",
            "Sentence before tokenization: My friend knows about Korean actors and dramas very well , so they enjoyed the slow conversation about them and shared the feeling beyond the languages .\n",
            "Sentence before tokenization: And then , she was obsessed with this playmat .\n",
            "Sentence before tokenization: However , I am a student , so I do not have enough money to donate .\n",
            "Sentence before tokenization: Authentic love is full of vigor and life as if it were the drizzle of spring .\n",
            "Sentence before tokenization: These days our family members all like to talk about making friends with boys .\n",
            "Sentence before tokenization: we also talked the Japan , many Chinese have a bad impression to Japan , because they have ever invaded China and killed a lot of people in Nanjing city , so Nanjing people extremely hate Japan .\n",
            "Sentence before tokenization: She has black hair and a tender voice .\n",
            "Sentence before tokenization: I stood there for almost a minute since I really could not move .\n",
            "Sentence before tokenization: I came back home a few days ago from Bangkok .\n",
            "Sentence before tokenization: Now I am having summer holydays so I learn it in internet but I will go to the courses in Spanish autumn .\n",
            "Sentence before tokenization: Have you ever heard of it ?\n",
            "Sentence before tokenization: They said I just live in my own world and never try to accept others into my world .\n",
            "Sentence before tokenization: In South Korea , Ms .\n",
            "Sentence before tokenization: I would like to continue to do this style , as far as I do not forget about it .\n",
            "Sentence before tokenization: Initiation ceremony\n",
            "Sentence before tokenization: It is far from central Tokyo , and it took about one and half hours by car from my house .\n",
            "Sentence before tokenization: Therefore many workers are demanding reduction of working hours .\n",
            "Sentence before tokenization: By the tale pain table of life that I could bend\n",
            "Sentence before tokenization: By the time goes by , it gets difficult to meet all of my friends because I have less free time than before .\n",
            "Sentence before tokenization: Do nt be that way !\n",
            "Sentence before tokenization: I like the time ! !\n",
            "Sentence before tokenization: or is there another word suitable here ? .\n",
            "Sentence before tokenization: Finally , Darcy looks attractive first because of fine tall form and noble face , but his poor affability cause a general disgust which end his popularity .\n",
            "Sentence before tokenization: I enjoyed very much spending time with my friends , but my conscious pricks me now because of my laziness .\n",
            "Sentence before tokenization: Through this experience , I became aware of the global environment .\n",
            "Sentence before tokenization: I notice that I have to improve my English more every time I guide visitors from overseas .\n",
            "Sentence before tokenization: The doll makes a parson is wish come true .\n",
            "Sentence before tokenization: This movie is about how fictional heroes become true heroes .\n",
            "Sentence before tokenization: I noticed that the time when the test just started .\n",
            "Sentence before tokenization: Instead of that , we went to Okinawa World , which is an amusement park in Okinawa .\n",
            "Sentence before tokenization: You should find differences between this country and Russia .\n",
            "Sentence before tokenization: Some friends asked me what happened and what made me cut my hair , and I answered I was broken - hearted .\n",
            "Sentence before tokenization: I started studying English at middle school but it was not serious .\n",
            "Sentence before tokenization: The core of this subject is the Cultural Landscape changes and social processes of the connection why do we have different Cultural Landscape Symbolism ?\n",
            "Sentence before tokenization:  answered I , having turned over on one side .\n",
            "Sentence before tokenization: A stag beatle is very rare .\n",
            "Sentence before tokenization: I have only a few more days off , so I have to do it in a hurry .\n",
            "Sentence before tokenization: I feel very sorry for the people .\n",
            "Sentence before tokenization: He seems to have a bit trouble .\n",
            "Sentence before tokenization: To be honest , it s not the kind of the thing you can tell a man you just met .\n",
            "Sentence before tokenization: When I was a student , I was a terribly bad English learner .\n",
            "Sentence before tokenization: And I found myself falling out from my house with BIG ANGER .\n",
            "Sentence before tokenization: The mine map was developed by Tony Buzan and the way attracts many people , such as business people and teachers .\n",
            "Sentence before tokenization: I speak a smidgen of English .\n",
            "Sentence before tokenization: Where there is a will , there is a way .\n",
            "Sentence before tokenization: They were all serious and urgent problems .\n",
            "Sentence before tokenization: So , is the name correct when it comes to English grammar ?\n",
            "Sentence before tokenization: When I come home and seem to open the door with my key , \n",
            "Sentence before tokenization: Last Sunday , I went to Karaoke with my cousin .\n",
            "Sentence before tokenization: although this is my own view , stress is a very important sensor that tells me existence of potential risk .\n",
            "Sentence before tokenization: I mailed to professor to ask whether I can visit his lab or not .\n",
            "Sentence before tokenization: What does the mode mean ?\n",
            "Sentence before tokenization: Just before the cherry came out , we brought the bark of the mountain cherry , and we did some waxing and something like that on it .\n",
            "Sentence before tokenization: I got a lot of vigor from them .\n",
            "Sentence before tokenization: So we did not worry so much .\n",
            "Sentence before tokenization: I was shaken by this song is aggressive melody part when I heard it for the first time .\n",
            "Sentence before tokenization: Recently I have begun to learn German .\n",
            "Sentence before tokenization: Lang - is nice , but .\n",
            "Sentence before tokenization: I went to a shrine near my house on st .\n",
            "Sentence before tokenization: I went there again and again , but I did not know about the tree .\n",
            "Sentence before tokenization: These advantages are critical to training a successful Media Informatics researcher because Media Informatics requires both advanced facilities and the support of industries .\n",
            "Sentence before tokenization: What is the difference between want to and would like to ?\n",
            "Sentence before tokenization: I can say It is tiring so easily .\n",
            "Sentence before tokenization: But I think is little more commonly used .\n",
            "Sentence before tokenization: I learned that I should try .\n",
            "Sentence before tokenization: I cooked mutch it .\n",
            "Sentence before tokenization: diary\n",
            "Sentence before tokenization: Today i went to paticipate in an interview about World Economic Forum , and it is also called Davos .\n",
            "Sentence before tokenization: Customer No , I m not .\n",
            "Sentence before tokenization: Although my English is not good , I hope to get your kindness revise .\n",
            "Sentence before tokenization: How nice , I am thanked by the customer !\n",
            "Sentence before tokenization: I want to do the story of daily life and the hobby .\n",
            "Sentence before tokenization: Although I ca not travel so many times because I am student , I like to travel .\n",
            "Sentence before tokenization: The other day one of my friends talked about a conversation of a father with his son in English .\n",
            "Sentence before tokenization: I regret that I have not played the piano very much for last weeks .\n",
            "Sentence before tokenization: We college students should study better , so that we can set some mechanism can not only clean the pollution but also create something without polluting .\n",
            "Sentence before tokenization: I have a question about how to use the phraze like that .\n",
            "Sentence before tokenization: Some random stuff\n",
            "Sentence before tokenization: When I came back , only to detect sign of the girl s leave .\n",
            "Sentence before tokenization: I remember every morning when I got up , the first feeling it gave to me was the dream .\n",
            "Sentence before tokenization: My lines diary\n",
            "Sentence before tokenization: affirmative sentence\n",
            "Sentence before tokenization: It was very fun .\n",
            "Sentence before tokenization: It was covered by water .\n",
            "Sentence before tokenization: Soon after , he was rescured from the jail !\n",
            "Sentence before tokenization: Most Japanese people have never related to Muslims .\n",
            "Sentence before tokenization: I gave myself one day to have a rest and to run away .\n",
            "Sentence before tokenization: I am going to meet my friends on Christmas eve !\n",
            "Sentence before tokenization: Its rainy day !\n",
            "Sentence before tokenization: His strategies are strange .\n",
            "Sentence before tokenization: Hi !\n",
            "Sentence before tokenization: Last May , one monk burned himself to offer to Buddha on an embankment near Nakdong river .\n",
            "Sentence before tokenization: Accordingly , I encountered the most funny business .\n",
            "Sentence before tokenization: It was Saturday evening when my notebook had that problem again .\n",
            "Sentence before tokenization: There are a lot of funny characters who seem to be in our office .\n",
            "Sentence before tokenization: delicious chicken and sooooooooooo delicious chicken .\n",
            "Sentence before tokenization: Okay , I wo not discuss that one of the worst and most serious accidents on this site .\n",
            "Sentence before tokenization: Did you know ?\n",
            "Sentence before tokenization: I made both for my daughter .\n",
            "Sentence before tokenization: But the Golden Week ticket was sold out , so I decided to skip the class on Tuesday .\n",
            "Sentence before tokenization: How they can survive by now ! !\n",
            "Sentence before tokenization: When the seminar ended , I was thinking that it was time for me to have a healthy lifestyle .\n",
            "Sentence before tokenization: they also help us to exchange information and gain knowledge which could not in the past .\n",
            "Sentence before tokenization: After working in Tokyo for years , I was transferred to Malaysia .\n",
            "Sentence before tokenization: I m going to do my best to do so !\n",
            "Sentence before tokenization: Nowdays , My mind is suck .\n",
            "Sentence before tokenization: Anyway , since he had just joined this marine hard training , I would like to cheer him up !\n",
            "Sentence before tokenization: And why did they need Japanese ?\n",
            "Sentence before tokenization: Happy New Year\n",
            "Sentence before tokenization: We did not afraid anymore .\n",
            "Sentence before tokenization: After that my friend asked me ' Let is go to a beach ' suddenly !\n",
            "Sentence before tokenization: When I was a school girl , I used to write a novel .\n",
            "Sentence before tokenization: Today was very fun day .\n",
            "Sentence before tokenization: And importantly , with those frozen vegetables , I do not have to go to the supermarket again this week .\n",
            "Sentence before tokenization: Is five years long ? Is it long enough to meet the people who will marry me ? I think it is a big problem .\n",
            "Sentence before tokenization: I really appreciated my colleagues ' advice .\n",
            "Sentence before tokenization: This is it !\n",
            "Sentence before tokenization: At the same time , I can be satisfied with my fine appreciation of beauty .\n",
            "Sentence before tokenization: Maybe it s a kind of climatic change which should be kept a close eye on .\n",
            "Sentence before tokenization: The reason why I chose these is the main actor and the atmosphere of the movie world .\n",
            "Sentence before tokenization: Iris Sound Project\n",
            "Sentence before tokenization: I was running to the station and I sweated a lot .\n",
            "Sentence before tokenization: But now , I love to have Korean traditional style dishes .\n",
            "Sentence before tokenization: I regret very much .\n",
            "Sentence before tokenization: Also I was noticed my city is bright .\n",
            "Sentence before tokenization: This world provides us .\n",
            "Sentence before tokenization: Okay , this is my first post in English here , so .\n",
            "Sentence before tokenization: Japanese often eat foreign sweets , especially European one , and like it .\n",
            "Sentence before tokenization: Was there the right judicial process to accuse Osama and put out the death penalty ?\n",
            "Sentence before tokenization: Do you ?\n",
            "Sentence before tokenization: So these two countries have not been reluctant to accept each others ' culture for many years .\n",
            "Sentence before tokenization: My next year resolution\n",
            "Sentence before tokenization: I am seeking websites that have sorts of interesting visualized information on country population , products , histories and so on .\n",
            "Sentence before tokenization: Today I have a question .\n",
            "Sentence before tokenization: This is my favorite song\n",
            "Sentence before tokenization: The Farewell !\n",
            "Sentence before tokenization: It was really tasty .\n",
            "Sentence before tokenization: The story is about a single man who is years old living with a girl who is years old .\n",
            "Sentence before tokenization: I really like her character .\n",
            "Sentence before tokenization: I showed him the MEXT application form .\n",
            "Sentence before tokenization: As soon as I got home , I only ordered Samurai Warriors Chronicle .\n",
            "Sentence before tokenization: I could not agree more with the comments that an expensive style of marriage is recommended .\n",
            "Sentence before tokenization: please check this out with your academic viewpoint ! !\n",
            "Sentence before tokenization: There are pan - coolers in my office .\n",
            "Sentence before tokenization: I feel a bit lonely .\n",
            "Sentence before tokenization: Today , I want to have a wonderful time .\n",
            "Sentence before tokenization: Thanks again for your warm - hearted consideration .\n",
            "Sentence before tokenization: My reading skills are very good , but I can not do writing in English .\n",
            "Sentence before tokenization: More help\n",
            "Sentence before tokenization: We supposed to have ice cream of haagen - dazs which is a little dear in China .\n",
            "Sentence before tokenization: I have been studying the Indonesian language and Indonesian culture since the middle of August .\n",
            "Sentence before tokenization: I hope I will , as usual , apply .\n",
            "Sentence before tokenization: And the game s spending money is also unexpensive .\n",
            "Sentence before tokenization: In this discussion , a well - known Chinese man who has been living in Japan for over twenty years pointed out that Japanese people tend to believe the news reported and the comments made by mass media without trying to make sure whether or not what mass media says is reliable and trying to think about what mass media intends to do .\n",
            "Sentence before tokenization: Yesterday I bought a new notebook PC on the Internet .\n",
            "Sentence before tokenization: the last weekend\n",
            "Sentence before tokenization: I have made around speeches in Japanese and English .\n",
            "Sentence before tokenization: A summer day\n",
            "Sentence before tokenization:  , \n",
            "Sentence before tokenization: So , I do not use English well .\n",
            "Sentence before tokenization: The only thing is that he has not his ambition .\n",
            "Sentence before tokenization: I will be sophomore in high school ! ?\n",
            "Sentence before tokenization: I am not an easy - going girl , since I have not met all of them .\n",
            "Sentence before tokenization: Medicines or medical supplies sometimes have different names between countries .\n",
            "Sentence before tokenization: An addition to the fresh fragrance\n",
            "Sentence before tokenization: She had lived with her father and grandmother\n",
            "Sentence before tokenization: However , I m not sure if its detection effects show the same level in water samples as well as in food samples .\n",
            "Sentence before tokenization: There are a bookcase , a TV , and a long sofa in the room .\n",
            "Sentence before tokenization: I play video games sometimes .\n",
            "Sentence before tokenization: Boot PIRKA and take before and after photos and post them from the PickUp screen .\n",
            "Sentence before tokenization: So , my nickname is INDEX and I ' ma - year - old boy who is now living in Seoul , the capital city of South Korea .\n",
            "Sentence before tokenization: My weight was kg .\n",
            "Sentence before tokenization: i have just read a little .\n",
            "Sentence before tokenization: Today I came to write something in English , because of finding my English not improved at all .\n",
            "Sentence before tokenization: When we work to bring awareness to the memories that are dictating our decisions , we are able to make conscious choices about our lives .\n",
            "Sentence before tokenization: I hope they like my dessert ! !\n",
            "Sentence before tokenization: I hope I will never go to see the dentist to extract my teeth .\n",
            "Sentence before tokenization: They made much more test than Langley on small hill , which name is Kill Devil Hills which is famous for kitty howk .\n",
            "Sentence before tokenization: Continued on - .\n",
            "Sentence before tokenization: Eh , I just do not know what else to tell you .\n",
            "Sentence before tokenization: Please come to this table , and talk each other in English .\n",
            "Sentence before tokenization: The Disney is a bit far from Central .\n",
            "Sentence before tokenization: Some students are running around the school .\n",
            "Sentence before tokenization: I met a friendly Indian guy who is a professor .\n",
            "Sentence before tokenization: I always listen and discuss something with her .\n",
            "Sentence before tokenization: Kyoto is very beautiful city .\n",
            "Sentence before tokenization: I am supposed to stay there for months so perhaps , at the latest , I will come back to Japan at the end of December .\n",
            "Sentence before tokenization: Do you know this Japanese anime ?\n",
            "Sentence before tokenization: This is my Declaration\n",
            "Sentence before tokenization: In my opinion , they often buy products in stores directly and they do not do bargain .\n",
            "Sentence before tokenization: Maybe I will post a picture of Suwon Hwaseong\n",
            "Sentence before tokenization: It was around pm , a perfect time for a pleasant walk .\n",
            "Sentence before tokenization: Nothing can match it is pleasent and fantacy .\n",
            "Sentence before tokenization: I have heard that it is the biggest in the world though I do not know whether it is a fact or not .\n",
            "Sentence before tokenization: He had gone in the distance .\n",
            "Sentence before tokenization: The staff are also pleasant and the timing of serving dishes is good .\n",
            "Sentence before tokenization: I did not know that there are other friendly words instead of Hi or Hey\n",
            "Sentence before tokenization: And in the case of myself , I think my short - tempered character is a bottleneck as yet .\n",
            "Sentence before tokenization: That is right !\n",
            "Sentence before tokenization: I am from Russia .\n",
            "Sentence before tokenization: Sometimes when I m tired of learning them , I want to give them up .\n",
            "Sentence before tokenization: I wonder if I may have forgot it .\n",
            "Sentence before tokenization: Today I am not able to keep a journal anymore .\n",
            "Sentence before tokenization: I try to speak the language of economics .\n",
            "Sentence before tokenization: hmmm I need to diet later , it will start tomorrow ! !\n",
            "Sentence before tokenization: negative sentences\n",
            "Sentence before tokenization: I have a sofa in the living room .\n",
            "Sentence before tokenization: I have watched news on TV yesterday .\n",
            "Sentence before tokenization: I wonder how the dolphins are trained like that .\n",
            "Sentence before tokenization: I m taking the exam in December and I only have a few months left so I have to study as hard as I can .\n",
            "Sentence before tokenization: in Japan .\n",
            "Sentence before tokenization: Listening Practice\n",
            "Sentence before tokenization: After that I could not run .\n",
            "Sentence before tokenization: I do nt like taking classes at my university\n",
            "Sentence before tokenization: let s us enjoy with me .\n",
            "Sentence before tokenization: Indeed they are mimosa trees , a kind of flower that is given to women in the Women is Day , on March th .\n",
            "Sentence before tokenization: VBA is just one of them .\n",
            "Sentence before tokenization: Reading a book in English is good practice because it includes a tons of slangs .\n",
            "Sentence before tokenization: Oh my buddha ! ! !\n",
            "Sentence before tokenization: After this thing , I carefully observed people eating free food samples .\n",
            "Sentence before tokenization: I want to become good at English .\n",
            "Sentence before tokenization: First of all , let me be clear , I am not an ideologist , a right wing or left wing person .\n",
            "Sentence before tokenization: Do you have any idea to spend a dark time without using electrisity ?\n",
            "Sentence before tokenization: What do you want for your birthday present ?\n",
            "Sentence before tokenization: For example , I felt doubts about my life and university life .\n",
            "Sentence before tokenization: This original story was so serious , so I thought there was no laughing point like the trick of magic .\n",
            "Sentence before tokenization: However , one may argue that such system will covey a false idea that only a small number of people deserve such recognition and even discourage some potential individuals .\n",
            "Sentence before tokenization: I hope that my son wins a foot race .\n",
            "Sentence before tokenization: The person answered him I will come at once .\n",
            "Sentence before tokenization: The most famous are\n",
            "Sentence before tokenization: i will consider the curriculum one more time .\n",
            "Sentence before tokenization: School school school S\n",
            "Sentence before tokenization: I am of medium height - I have got cm .\n",
            "Sentence before tokenization: I still remember clearly when I was young , my father told me , life is tough , we ca not be with you and help you all the time .\n",
            "Sentence before tokenization: He asked his parents about it .\n",
            "Sentence before tokenization: I am frustrated .\n",
            "Sentence before tokenization: The old lady s eyes flashed for a moment .\n",
            "Sentence before tokenization: Yet I has reflected on myself of my behavior back home .\n",
            "Sentence before tokenization: He cried and I told him to go to a hospital .\n",
            "Sentence before tokenization: The car was traveling at a speed of kilometers an hour .\n",
            "Sentence before tokenization: We could spend some time to stay together .\n",
            "Sentence before tokenization: Weekend better not be rainy .\n",
            "Sentence before tokenization: If there is a good article , it may not be translated into Japanese .\n",
            "Sentence before tokenization: I got a good new recently .\n",
            "Sentence before tokenization: I only want to know your opinion about this problem .\n",
            "Sentence before tokenization: Recently I have used Twitter again .\n",
            "Sentence before tokenization: He frequently said life of postdoctoral fellow is very stressful because they have to obtain many results of experiments to get academic position .\n",
            "Sentence before tokenization: So I bet with my co - worker that if I get over score in TOEIC he will buy me an extra digital TV inch .\n",
            "Sentence before tokenization: Mid - Autumn Festival\n",
            "Sentence before tokenization: I almost forgot how to smile from the bottom of my heart .\n",
            "Sentence before tokenization: We must return to ourselves .\n",
            "Sentence before tokenization: Besides , parent is authority may challenged when their children question something .\n",
            "Sentence before tokenization: I did not go down to my hometown where my parents still lived because I had to work and had to start to work when it began to end .\n",
            "Sentence before tokenization: A daily exercise .\n",
            "Sentence before tokenization: It is personal .\n",
            "Sentence before tokenization: There is not the flow of wind .\n",
            "Sentence before tokenization: At the time , Japan suffered from chronic energy deficiency due to the rapid economic growth and was struggling to discover the solution .\n",
            "Sentence before tokenization: I am absolutely attracted by the city is charm , and I look forward to making a great success in the next few years , even though I am now just twenty years old .\n",
            "Sentence before tokenization: Thank you for reading !\n",
            "Sentence before tokenization: If you want to talk to a good friend , honest , sweet and tender , you can do with me at any moment , I am a good person , kind , loyal and sincere .\n",
            "Sentence before tokenization: Afternoon I will exercise in a near by park .\n",
            "Sentence before tokenization: Let me introduce myself part\n",
            "Sentence before tokenization: but i know to write well even though i feel jittery to write .\n",
            "Sentence before tokenization: I absolutely need to know how to tell this feeling .\n",
            "Sentence before tokenization: Many reasons for the events in this book have came to my minds and I am still thinking of some .\n",
            "Sentence before tokenization: But I started with a sore throat because the exhaust gas was much higher than in Japan .\n",
            "Sentence before tokenization: Because many Asian people study English .\n",
            "Sentence before tokenization: haha , waiting for you friends ! !\n",
            "Sentence before tokenization: So , I requested Doctor to prescribe a medicine to soothe instead of taking surgey .\n",
            "Sentence before tokenization: Laforgue felt his body tremble .\n",
            "Sentence before tokenization: After three hours driving , we arrived at the car park .\n",
            "Sentence before tokenization: She was not sure she could pass them or not .\n",
            "Sentence before tokenization: Work and study are very important things for us and social life .\n",
            "Sentence before tokenization: This writer committed suicide three years ago .\n",
            "Sentence before tokenization: This is my visitation gift for you .\n",
            "Sentence before tokenization: The video ended\n",
            "Sentence before tokenization: I like music very much !\n",
            "Sentence before tokenization: In addition , I can learn how important keeping a promise or a rule is from friends when I play with them .\n",
            "Sentence before tokenization: Tonight we are going to watch the film at St Lukes .\n",
            "Sentence before tokenization: What a messy day !\n",
            "Sentence before tokenization: I expect that these trends might be able to generate the new type of contents which is not only the replacement of paper books but has some mutimedia characteristics , such as text , photo , video , and sound voice .\n",
            "Sentence before tokenization: will treasure - My religion comes from the American\n",
            "Sentence before tokenization: I was so impressed that though the fiscal situation and limited human resources are tough , he is enjoying his work and just focused on how to make the service grow bigger and better .\n",
            "Sentence before tokenization: They share some similarities in living atmosphere and chances of education .\n",
            "Sentence before tokenization: Even a native Japanese suffers that problem .\n",
            "Sentence before tokenization: I was talking about Japanese yen and American dollar .\n",
            "Sentence before tokenization: I could make a lot of friends .\n",
            "Sentence before tokenization: But the guy changed the channel without a word .\n",
            "Sentence before tokenization: Tonight , I dropped by a rental shop on my way home to return a CD which I had rented last week .\n",
            "Sentence before tokenization: I had a good time tonight .\n",
            "Sentence before tokenization: For example , when ALT come to school , I talk to him , but only greeting .\n",
            "Sentence before tokenization: Sometimes when we wake up , we may suddenly miss someone in our dream last night so much .\n",
            "Sentence before tokenization: First , put fresh tomato , onion , boiled potato , turmeric and curry leaves into coconut milk .\n",
            "Sentence before tokenization: Below is the summary for the previous story written by me .\n",
            "Sentence before tokenization: My mom bought me a coat\n",
            "Sentence before tokenization: And when they find predators , they make an alarm and let their group members flee .\n",
            "Sentence before tokenization: By the way , today is my birthday .\n",
            "Sentence before tokenization:  I give , and it shall be given . \n",
            "Sentence before tokenization: What kind of fiction person do you like ?\n",
            "Sentence before tokenization: Many drug users are employed and drug use has a bad influence on all Americans .\n",
            "Sentence before tokenization: journal\n",
            "Sentence before tokenization: Delta , P , Q - \n",
            "Sentence before tokenization: And the most badly was the fact that we could not bathe for three days and believe me this spectacle was not the most pleasant .\n",
            "Sentence before tokenization: I am so tired and sleepy today .\n",
            "Sentence before tokenization: I took part in the tournament for once .\n",
            "Sentence before tokenization: Anyway , it is good news !\n",
            "Sentence before tokenization: The most important thing , in my opinion , is that you can do several things in real time .\n",
            "Sentence before tokenization: It is not boiled easily .\n",
            "Sentence before tokenization: To sum up , by taking into account the aforementioned reasons , which may sometimes intertwine into an organic whole and thus become more persuasive than any single one of them , we may safely arrive at the conclusion that the importance of location depends on the condition of different companies .\n",
            "Sentence before tokenization: Plase help me .\n",
            "Sentence before tokenization: Does Someome use Autocad ?\n",
            "Sentence before tokenization: I know Java and I can programming in Java .\n",
            "Sentence before tokenization: He did not let us bore at any time for forty minutes in his class .\n",
            "Sentence before tokenization: I have practiced juggling for years .\n",
            "Sentence before tokenization: I am confused .\n",
            "Sentence before tokenization: Two and three is five .\n",
            "Sentence before tokenization: In short note .\n",
            "Sentence before tokenization: That interview was an English conversation test .\n",
            "Sentence before tokenization: Today is Job\n",
            "Sentence before tokenization: He is one of my favorite authors and I have already had a few book both in Japanese and In English .\n",
            "Sentence before tokenization: The time to decide\n",
            "Sentence before tokenization: Japanese people\n",
            "Sentence before tokenization: However I think the greatest film I have seen is The godfather .\n",
            "Sentence before tokenization: My seminar\n",
            "Sentence before tokenization: Please wish I good luck .\n",
            "Sentence before tokenization: Though Japanese summer is very hot and humid , such a condition is good for doing sports , I think .\n",
            "Sentence before tokenization: My tooth hurts .\n",
            "Sentence before tokenization: Maybe . I think that is caused by the lasting typical cold winter pressure pattern .\n",
            "Sentence before tokenization: But the story was interesting .\n",
            "Sentence before tokenization: We drunk and had fun .\n",
            "Sentence before tokenization: Today is the first day going to school after the Chinese New Year vacation .\n",
            "Sentence before tokenization: I think that I took courage .\n",
            "Sentence before tokenization: I could nt sleep well last night and I also woke up midnight .\n",
            "Sentence before tokenization: However , she returned to the shop next day and she said to the store manager , I do not like the ring I bought yesterday . \n",
            "Sentence before tokenization: I really do not know how to handle these kids or their weird ideas that have a bad influence on their class .\n",
            "Sentence before tokenization: I wondered if tango performed by Japanese women seemed attractive to foreigners since they usually express themselves in different ways indirectly .\n",
            "Sentence before tokenization: I still like her !\n",
            "Sentence before tokenization:  - You do nt need to speak so loud , he can hear you .\n",
            "Sentence before tokenization: I do nt know then .\n",
            "Sentence before tokenization: I wanted to watch Japan and Korea play in the finals of the qualifying games .\n",
            "Sentence before tokenization: translate sentences per day .\n",
            "Sentence before tokenization: lacking taste or savor TASTELESS lacking in qualities that interest , stimulate , or challenge ULL , FLAT\n",
            "Sentence before tokenization: I learned that keeping practice was the best way to improve language skills .\n",
            "Sentence before tokenization: One of them was a family with my surname .\n",
            "Sentence before tokenization: If you like , please become my friend and help each other .\n",
            "Sentence before tokenization: I heard that Ben was also the favorite cartoon of the US President Obama , however , I knew only Doraemon .\n",
            "Sentence before tokenization: I am hungry .\n",
            "Sentence before tokenization: the scale has two meanings ?\n",
            "Sentence before tokenization: I , however , realized that the story that I knew had probably been dramatized and arranged somehow as I watched a BBC drama starring Colin Firth now .\n",
            "Sentence before tokenization: Thanks a lot ! ! ! !\n",
            "Sentence before tokenization: He had to work until p .m . everyday on last week .\n",
            "Sentence before tokenization: I have a question !\n",
            "Sentence before tokenization: Anyway , in spite of all uncomfortable and unfamiliar things , the drama is really well made in the aspects of opening sequence , insightful conversation and idiosyncratic theme and sophisticiated stage setting , etc .\n",
            "Sentence before tokenization: And help someone who is an English user .\n",
            "Sentence before tokenization: I can not help but grin a little , but at the same time , I think to myself that it is probably one of the happy moments in life .\n",
            "Sentence before tokenization: Today is dinner was pasta .\n",
            "Sentence before tokenization: First , you look at your native language sentence .\n",
            "Sentence before tokenization: But it makes me feel so good that it is hard to resist its temptation .\n",
            "Sentence before tokenization: They offered flats and rooms for rate .\n",
            "Sentence before tokenization: Check out the reviews . You ll see everyone is talking nicely about her .\n",
            "Sentence before tokenization: It is difficult to master English .\n",
            "Sentence before tokenization: It was actually rather cold inside and still no light .\n",
            "Sentence before tokenization: So I am trying to write this diary .\n",
            "Sentence before tokenization: What do I do ?\n",
            "Sentence before tokenization: I really enjoy keeping my blog in English .\n",
            "Sentence before tokenization: He had not been playing with his best friend Campanella , which was popular among his classmates , for a long time .\n",
            "Sentence before tokenization: Her smile makes me happy .\n",
            "Sentence before tokenization: They all were very cool !\n",
            "Sentence before tokenization: I do not know why it happened , but my friend told me that my yesterday is diary entry was something like help me with my Spanish , but I had put that in ENGLISH ! ! !\n",
            "Sentence before tokenization: I do not know the details of that but I am excited to hear that .\n",
            "Sentence before tokenization: I am a - year - old researcher .\n",
            "Sentence before tokenization: He is not good at studying and sport .\n",
            "Sentence before tokenization: scaled GUNDAM\n",
            "Sentence before tokenization: We stayed there until morning !\n",
            "Sentence before tokenization: There were various performances and many things to play .\n",
            "Sentence before tokenization: I was very happy !\n",
            "Sentence before tokenization: But we usually focus on not speaking but reading according to grammar .\n",
            "Sentence before tokenization: Make the airline business attractive !\n",
            "Sentence before tokenization: It is attached to my mouth every class .\n",
            "Sentence before tokenization: I arrived there at around am and I was told to write as many as three pieces of medical questionnaire .\n",
            "Sentence before tokenization: An old building could be the witness of a dynasty exchange , family history or even a romantic love story .\n",
            "Sentence before tokenization: It is very hard for me .\n",
            "Sentence before tokenization: I will take step by step and do my best .\n",
            "Sentence before tokenization: After the talk , she changed the rice ball with his persimmon seed .\n",
            "Sentence before tokenization: I have read English and Chinese versions of the novels .\n",
            "Sentence before tokenization: On the first day of the so - called Golden Week , the th of April , the entire route became available .\n",
            "Sentence before tokenization: A vegetable farm\n",
            "Sentence before tokenization: We are going to have camera installation today .\n",
            "Sentence before tokenization: I found the word remotization in this sentence\n",
            "Sentence before tokenization: Luckily the class offers free morning tea , that is the only reason for me to attend the class .\n",
            "Sentence before tokenization: When I was a kid I always had an astronomy book in my hand , looking at picture of the Giant Jupiter , Saturn and all of her halos and learning about how universe in general without understanding the whole proportion and concept behind it .\n",
            "Sentence before tokenization: Hierarchy , direct vs .\n",
            "Sentence before tokenization: July Is About To End !\n",
            "Sentence before tokenization: I have not written a diary in Japanese .\n",
            "Sentence before tokenization: I do every time !\n",
            "Sentence before tokenization: What a big change !\n",
            "Sentence before tokenization: It stores some liquid which smells like a nectar , but the liquid is an aqueous solution which can liquefy anything .\n",
            "Sentence before tokenization: But tomorrow , I should work hard .\n",
            "Sentence before tokenization: I have memorized a lot of words in English literally translated from Japanese since I was twelve years old , however , I can use it only ten percent out of the vocabulary .\n",
            "Sentence before tokenization: I only imagined a hamburger because if I was watching TV I would like to eat foods which are easy to eat .\n",
            "Sentence before tokenization: and they said Goodbye when I got back to my car .\n",
            "Sentence before tokenization: However , we should enjoy worldcup as just international festival .\n",
            "Sentence before tokenization: Millionaire is a very famous quiz show and a lot of programs are running in the world .\n",
            "Sentence before tokenization: I came to Kenting with my friends first time .\n",
            "Sentence before tokenization: LOTUS prevent this mechanism and accelerate formation of nerve consequently .\n",
            "Sentence before tokenization: The shelter is executive started to narrate the history , circumstances , spirit and goal of the shelter .\n",
            "Sentence before tokenization: Learning English\n",
            "Sentence before tokenization: I met a lot of friends who had left my company a few years ago .\n",
            "Sentence before tokenization: Lecturers explained very quickly , without taking a rest .\n",
            "Sentence before tokenization: Because he seems to be kind to senior volunteers , but he is not kind to young volunteers .\n",
            "Sentence before tokenization: What is wrong with me ?\n",
            "Sentence before tokenization: Ultimately , his daughter was in trouble - after leaving her - she did not know how she could live on earth without her dad , mom and brother .\n",
            "Sentence before tokenization: original version is .\n",
            "Sentence before tokenization: People often say that the duty of your room means a confusion of your mind .\n",
            "Sentence before tokenization: And exciting\n",
            "Sentence before tokenization: But I am sad that they left this place .\n",
            "Sentence before tokenization: He turned himself and found more than ten tadpoles on the ground . Some of them were still alive and moving .\n",
            "Sentence before tokenization: I am still a child .\n",
            "Sentence before tokenization: sick of itlol\n",
            "Sentence before tokenization: As far as I know , computer server rental business is appropriate for such small shop .\n",
            "Sentence before tokenization: we had look the item in the internet and then cook fallow the internet .\n",
            "Sentence before tokenization: It was very interesting and my teacher is my personal model to follow ! !\n",
            "Sentence before tokenization: Hello , Everyone ! I am Erica .\n",
            "Sentence before tokenization: He is a good man who help other people .\n",
            "Sentence before tokenization: Cold and warm\n",
            "Sentence before tokenization: Thank you for your e - mail .\n",
            "Sentence before tokenization: Thank for you reading !\n",
            "Sentence before tokenization: As I said above , champagne is a special New Year beverage .\n",
            "Sentence before tokenization: Entrance Exam\n",
            "Sentence before tokenization: A specialized professor can teach his students the most valuable information and know - how .\n",
            "Sentence before tokenization: And this is my first time to make foreign friends .\n",
            "Sentence before tokenization: I mean most of people include me have to think of the prices before they buy some foods .\n",
            "Sentence before tokenization: In particular , retail stores can not earn much money because they deal with fresh materials such as fresh fruit , vegetables and so on .\n",
            "Sentence before tokenization: My time is your time .\n",
            "Sentence before tokenization: Line from Desperate housewives\n",
            "Sentence before tokenization: There are a lot of opportunities to study a language ! !\n",
            "Sentence before tokenization: it is very sad .\n",
            "Sentence before tokenization: My sister stay there alone because she must attend a wedding party of her friend .\n",
            "Sentence before tokenization: I want to become him girlfriend .\n",
            "Sentence before tokenization: Thanks to these courses , I live a well - regulated life .\n",
            "Sentence before tokenization: I went to my friend is house and attended the small party .\n",
            "Sentence before tokenization: Very very exciting ! !\n",
            "Sentence before tokenization: She must have thought ' I want to eat eels .\n",
            "Sentence before tokenization: Taking control of my mind\n",
            "Sentence before tokenization: If a woman is not supported in being unhappy sometimes , then she can never truly be happy .\n",
            "Sentence before tokenization: When I see the number in deposit passbook increase , I will happy so much .\n",
            "Sentence before tokenization: Even though the condition was very bad , I was glad to be in nature .\n",
            "Sentence before tokenization: However , I do it .\n",
            "Sentence before tokenization: Chinese is very important for getting a job or getting a nice school grade because Chinese is also one of subjects at high schools like English .\n",
            "Sentence before tokenization: She texted me she wanted to meet me somewhere to give me some little souvenirs from Hokkaido , so I proposed to her that I go there .\n",
            "Sentence before tokenization: Then I will be happy every day .\n",
            "Sentence before tokenization: Like the moon , things look different by the points you see from .\n",
            "Sentence before tokenization: The Farewell !\n",
            "Sentence before tokenization: In is and is any young people longed a car .\n",
            "Sentence before tokenization: It is sunny today .\n",
            "Sentence before tokenization: I need more confidence in my life .\n",
            "Sentence before tokenization: Would you or friends around you like to study in China ?\n",
            "Sentence before tokenization: There is a scene which implies the moment when he got ready to move on to the tomorrow .\n",
            "Sentence before tokenization: Wow , it was a tough job .\n",
            "Sentence before tokenization: But the funny part was I found it easier to translate Chinese into English .\n",
            "Sentence before tokenization: Have you ever heard about dim sum ?\n",
            "Sentence before tokenization: I think that is not German .\n",
            "Sentence before tokenization: It is made from the mat rush .\n",
            "Sentence before tokenization: I hope I will be able to master English as quick as possible with this state - of - art technology .\n",
            "Sentence before tokenization: But actually I have not made an effort .\n",
            "Sentence before tokenization: I really did n t like this a lot , but I hoped that Marcos would appear one day .\n",
            "Sentence before tokenization: On the island , many rabbits live .\n",
            "Sentence before tokenization:  , But do not judge me ! !\n",
            "Sentence before tokenization: Actually , I do not like recording my voice and listening to it because after listening to my voice , I know I will be disappointed .\n",
            "Sentence before tokenization: Before asking her , I always thought it is much better to know one thing very well because in our society , working experience is an essential condition for finding a good job , but without sound knowledge to at least one field , it is very hard for us to get a job .\n",
            "Sentence before tokenization: I arrived the company in time .\n",
            "Sentence before tokenization: A low salary job can not give you a luxurious life but it can give you a smooth and steady life .\n",
            "Sentence before tokenization: You can always take time to spend working , having a party .\n",
            "Sentence before tokenization: It was strongly recommended by several people who live in NZ and are not Japanese .\n",
            "Sentence before tokenization: What am I ?\n",
            "Sentence before tokenization: We took it for granted .\n",
            "Sentence before tokenization: I like rice better than breads .\n",
            "Sentence before tokenization: Stop taking strangers ' photos on the subway or train\n",
            "Sentence before tokenization: I afraid my Professor to receive .\n",
            "Sentence before tokenization: It s intended for th graders and th graders .\n",
            "Sentence before tokenization: Dear Prof .\n",
            "Sentence before tokenization: I like study but I ca not do it very long time .\n",
            "Sentence before tokenization: I started Lang - because I wanted to learn English .\n",
            "Sentence before tokenization: I need to try hard at English study .\n",
            "Sentence before tokenization: Through this study abroad , I want to learn to cope with trouble and difficult situations on my own .\n",
            "Sentence before tokenization: So he made a bridge on the river and allowed the couple can meet only once a year .\n",
            "Sentence before tokenization: A Chinese guy had difficulties finding a job , so he called a job consultant for help .\n",
            "Sentence before tokenization: As soon as I got up , I heated the room with an air conditioner .\n",
            "Sentence before tokenization: Nothing can match its pleasure and imagination .\n",
            "Sentence before tokenization: I live in Tokyo now .\n",
            "Sentence before tokenization: But I sometimes like to take a boat and go on a lake and enjoy the calm and fresh air on the water .\n",
            "Sentence before tokenization: I found that It is not such a simple cartoon for children as it looks like .\n",
            "Sentence before tokenization: But , My ex - boss and ex - colleagues always talk about a work and they brush down someone else .\n",
            "Sentence before tokenization: I began crying .\n",
            "Sentence before tokenization: The latest typhoon th prevented heat wave and cooled Japan .\n",
            "Sentence before tokenization: In fact , I think this cooking smells bad , but I like this cooking .\n",
            "Sentence before tokenization: I felt a little sick .\n",
            "Sentence before tokenization: I hope enjoy .\n",
            "Sentence before tokenization: It is more exciting than I expected , \n",
            "Sentence before tokenization: Also nearby are overgrown with many wildflowers .\n",
            "Sentence before tokenization: Google have trusted their business model since they founded their company .\n",
            "Sentence before tokenization: He was as abrupt with me as he could ever be , keeping that utter impassivity of his the whole time .\n",
            "Sentence before tokenization: I am two years old now .\n",
            "Sentence before tokenization: And I have a poor English .\n",
            "Sentence before tokenization: Am I too naive or too ignorant ?\n",
            "Sentence before tokenization: I really hope I get my own car ! !\n",
            "Sentence before tokenization: In the first place , that stuff bores me , and in the second place , my parents would have about two hemorrhages apiece if I told anything pretty personal about them . \n",
            "Sentence before tokenization: in several times .\n",
            "Sentence before tokenization: I am in a little bit difficult mental state and often depressed .\n",
            "Sentence before tokenization: We can order it comfortably .\n",
            "Sentence before tokenization: Hello all !\n",
            "Sentence before tokenization: Some people say that because of the Internet , TV will disappear some day instead .\n",
            "Sentence before tokenization: I could not drink a lot , though it was all - you - can - drink .\n",
            "Sentence before tokenization: It was very cold .\n",
            "Sentence before tokenization: but yesterday he absolutely showed all of his ability .\n",
            "Sentence before tokenization: The way Japanese behave is likely to be influenced by the behavior of others and by their concern for what others will think of them .\n",
            "Sentence before tokenization: I , ' m shocked\n",
            "Sentence before tokenization: Present rospects prefer products with a strong positive impression at first sight .\n",
            "Sentence before tokenization: I do not know exactly when Chinese characters came to Korea .\n",
            "Sentence before tokenization: I bet the price of bread will go up !\n",
            "Sentence before tokenization: There is no details description in this book .\n",
            "Sentence before tokenization: a Look at the girl dancing .\n",
            "Sentence before tokenization: It is even hard to open eyes widely .\n",
            "Sentence before tokenization: Through all seasons , I enjoy doing Yoga and cooking .\n",
            "Sentence before tokenization: This essay will discuss positive qualities and negative qualities .\n",
            "Sentence before tokenization: October th is a national holiday in Japan .\n",
            "Sentence before tokenization: The Moon Festival is usually celebrated during middle Fall .\n",
            "Sentence before tokenization: Even though I am tired now .\n",
            "Sentence before tokenization: Is the sentence above natural English , and a grammatical sentence ?\n",
            "Sentence before tokenization: Of course , I am one who is speaking with a local accent .\n",
            "Sentence before tokenization: Mascara and Panda\n",
            "Sentence before tokenization: Such as notwithstanding , last but not least .\n",
            "Sentence before tokenization: It is so very cold outside\n",
            "Sentence before tokenization: I hope I play piano very well .\n",
            "Sentence before tokenization: Some problems may be solved but some are not .\n",
            "Sentence before tokenization: I respect the peopel who is oral very well .\n",
            "Sentence before tokenization: Sometimes violence is the only solution .\n",
            "Sentence before tokenization: After the year filming , the movie was a big hit with people around the world .\n",
            "Sentence before tokenization: Thank you for reading , your corrections and your comments .\n",
            "Sentence before tokenization: Now I have finished studying , am going to start work , and I want to make another trip to England .\n",
            "Sentence before tokenization: I need a teacher who can take care of me for a long time .\n",
            "Sentence before tokenization: This time their recruitment for the election has started in May .\n",
            "Sentence before tokenization: Yes , I know that some people do that .\n",
            "Sentence before tokenization: But , when I watched a moving picture that someone has played video games , my feeling has changed .\n",
            "Sentence before tokenization: On my way home , I found that the mountain in back of my home looks green and vital .\n",
            "Sentence before tokenization: Let me see who is the most brave child .\n",
            "Sentence before tokenization: By the way , this series started in .\n",
            "Sentence before tokenization: I love the smell of muffins and coffee . It makes me feel so happy .\n",
            "Sentence before tokenization: And this is sure to be a drawback in his career .\n",
            "Sentence before tokenization: Also , you can catch a dangerous disease .\n",
            "Sentence before tokenization: It is too late , though .\n",
            "Sentence before tokenization: So I always had an expectation of gratitude from others who were treated with kindness by me , and I was angry when they disappointed me .\n",
            "Sentence before tokenization: Scary stuff !\n",
            "Sentence before tokenization: My sisters and I were very excited when we saw the bicycle .\n",
            "Sentence before tokenization: My closings and books were lying about in the room .\n",
            "Sentence before tokenization: In the US , there are many students studying abroad .\n",
            "Sentence before tokenization: And of course I ca not afford to buy a car .\n",
            "Sentence before tokenization: Then , I decided to apply for this job and skip those classes if I can successfully get that chance .\n",
            "Sentence before tokenization: I went to school .\n",
            "Sentence before tokenization: I found this website totally by luck .\n",
            "Sentence before tokenization: All offers are exclusive services to customers of Sun and Fun tours .\n",
            "Sentence before tokenization: Where are you from ?\n",
            "Sentence before tokenization: What do you like about buffet cooking ?\n",
            "Sentence before tokenization: I do not know why , but I might have some anxiety about what to do after going back to Korea though I really want to go to Korea as soon as possible .\n",
            "Sentence before tokenization: Usually , we use a lot of agricultural chemicals .\n",
            "Sentence before tokenization: But , oh , I can write a brief account of my Irish holiday , which ended on Tuesday .\n",
            "Sentence before tokenization: I think i was so lazy .\n",
            "Sentence before tokenization: but I woke up at , am .\n",
            "Sentence before tokenization: I like to translate Finnish song lyrics into English .\n",
            "Sentence before tokenization: It is too exepensive .\n",
            "Sentence before tokenization: What we did was play video games , play some sports and so on .\n",
            "Sentence before tokenization: I will soon go to buy gifts .\n",
            "Sentence before tokenization: But I do not have much money .\n",
            "Sentence before tokenization: I do not think I am short - tempered , but I have no patience when it comes to situations like that if I am in line waiting for my turn listening to people blabbering on .\n",
            "Sentence before tokenization: So Kay could not believe how the Corlesone family had a relationship with him .\n",
            "Sentence before tokenization: Soy sauce bulgogi speedy recipe WOW ! !\n",
            "Sentence before tokenization: New week\n",
            "Sentence before tokenization: I wonder how much I improved my speaking abilities within two months .\n",
            "Sentence before tokenization: I went to the counter and asked to use it .\n",
            "Sentence before tokenization: Thank you for your consideration .\n",
            "Sentence before tokenization: Initiation ceremony\n",
            "Sentence before tokenization: So , if an entry is talking about sushi , other sushi - related entries will be listed in the corner of your browser .\n",
            "Sentence before tokenization: This book is written based on a large amount of scientific data .\n",
            "Sentence before tokenization: I am looking forward to watching next season\n",
            "Sentence before tokenization: I had a very interesting class the other day .\n",
            "Sentence before tokenization: I can feel a little bit of the improvement because I can read what I really want to read more than before .\n",
            "Sentence before tokenization: from bad to good\n",
            "Sentence before tokenization: Why do they need creativity ?\n",
            "Sentence before tokenization: But after we met or times , he told me that we are incredibly getting alone and I feel you like family , like my younger sister .\n",
            "Sentence before tokenization: My English instructor in that day is derived from France .\n",
            "Sentence before tokenization: Please leave me alone .\n",
            "Sentence before tokenization: Cool Day\n",
            "Sentence before tokenization: It became very cold rapidly in a day .\n",
            "Sentence before tokenization: I thought my hair looked like a boy is , and that my former long hair was better .\n",
            "Sentence before tokenization: Yes I totally can accept it .\n",
            "Sentence before tokenization: It was seen and he said .\n",
            "Sentence before tokenization: So I could do nothing but slept .\n",
            "Sentence before tokenization: The time talking them are very precious for me .\n",
            "Sentence before tokenization: The first chapter introduces Chinese use and habits and political economics , the second talks about Chinese distribution and car characteristics , the third examines the stories of Joint Ventures between Chinese car producers and foreign ones , the fourth discusses the automotive industry in the rest of Asia , the fifth deals with automakers ' strategies in Asia .\n",
            "Sentence before tokenization: I may be getting a cold .\n",
            "Sentence before tokenization: thank you for read my daily .\n",
            "Sentence before tokenization: I study Chinese every day at lunchtime .\n",
            "Sentence before tokenization: We ablsolutely have no class of speaking enlgish .\n",
            "Sentence before tokenization: I can not speak English well .\n",
            "Sentence before tokenization: I want to stay home and study Linux in my room for about a week .\n",
            "Sentence before tokenization: But , my English is very poor , especially speaking .\n",
            "Sentence before tokenization: Today I went to church .\n",
            "Sentence before tokenization: This research conducted in the U .\n",
            "Sentence before tokenization: I am so worried .\n",
            "Sentence before tokenization: What is more ?\n",
            "Sentence before tokenization: The easiest way to forget past life with good memories is to dream a new life with expectation .\n",
            "Sentence before tokenization: I play video games sometimes .\n",
            "Sentence before tokenization: I was satisfied with the long story .\n",
            "Sentence before tokenization: I met an American person who can learn to write and speak Thai very well last week .\n",
            "Sentence before tokenization: Love is not all hot , and some is also quiet .\n",
            "Sentence before tokenization: Now the middil exams is coming .\n",
            "Sentence before tokenization: I thought I would like to go there and see its parade .\n",
            "Sentence before tokenization: Thus it has been years since the last time I wrote an English essay .\n",
            "Sentence before tokenization: It is better for me to get up earlier in the morning .\n",
            "Sentence before tokenization: Check my contents ! ! ! Help me ! !\n",
            "Sentence before tokenization: I raust it with garlic and the basil souse put .\n",
            "Sentence before tokenization: difference of will and be going to\n",
            "Sentence before tokenization: They are doing their best in their new life here in America .\n",
            "Sentence before tokenization: However , there are only a small number of people who can speak English fluently and follow English news and movies .\n",
            "Sentence before tokenization: I also know if I had not caused the accident , nothing would have happened to him .\n",
            "Sentence before tokenization: I have some friends in N .\n",
            "Sentence before tokenization: My friends kindly worry about me .\n",
            "Sentence before tokenization:  Describe a sport , a game , or a group activity people enjoy doing in your country .\n",
            "Sentence before tokenization: Contemporary writings\n",
            "Sentence before tokenization: I was not a cool guy .\n",
            "Sentence before tokenization: Maybe ?\n",
            "Sentence before tokenization: The occurrence was years ago , she told me that .\n",
            "Sentence before tokenization: There was a girl who made the special hat which Mad Hatter was wearing .\n",
            "Sentence before tokenization: In particular , the Japanese defense was effective against Argentine .\n",
            "Sentence before tokenization: So I study English writing .\n",
            "Sentence before tokenization: very simple things .\n",
            "Sentence before tokenization: to be continued .\n",
            "Sentence before tokenization: Because I will go to India for two months , we need some communication tools .\n",
            "Sentence before tokenization: Maybe I will be here untill on july .\n",
            "Sentence before tokenization: But later , I heard a kind of sound that someone was opening the door .\n",
            "Sentence before tokenization: First of all , they have better memory than the elderly .\n",
            "Sentence before tokenization: Dancing with big fun is great !\n",
            "Sentence before tokenization: goodbye and have a good days in chicago .\n",
            "Sentence before tokenization: thank you\n",
            "Sentence before tokenization: I thought I wanted to die many times .\n",
            "Sentence before tokenization: I called my mom to tell her .\n",
            "Sentence before tokenization: Did they expect anything to eat ?\n",
            "Sentence before tokenization: hard or joy\n",
            "Sentence before tokenization: Edison was faill over when he had tried to figure out bulb .\n",
            "Sentence before tokenization: The European Union needs to engage in planning future developments , taking into account lessons learned from the present crisis , as well as global risk factors .\n",
            "Sentence before tokenization: I am a foreign trade person , and my boss is an Indian .\n",
            "Sentence before tokenization: The new year is only left days in Korea .\n",
            "Sentence before tokenization: I had a hard day yesterday .\n",
            "Sentence before tokenization: It is difficult for me to talk about everything in English in minutes .\n",
            "Sentence before tokenization: I go to the ESL school twice a week now .\n",
            "Sentence before tokenization: Although , I think we can not enjoy ourselves without spending time .\n",
            "Sentence before tokenization: At first , I expected few people would receive them but almost everyone received them .\n",
            "Sentence before tokenization: But my wife wants to go to a beach resort .\n",
            "Sentence before tokenization: She won a prestigious musical award years in a row .\n",
            "Sentence before tokenization: My experiments are performed on weekdays because I can not use study devices and the help of technicians on the weekend .\n",
            "Sentence before tokenization: I am safe ! - Japanese Earthquake\n",
            "Sentence before tokenization: Is it nice ?\n",
            "Sentence before tokenization: By the way , he was a good man .\n",
            "Sentence before tokenization: Land is barren and plant withers away .\n",
            "Sentence before tokenization: First of all , population growth has gratly influenced on the world .\n",
            "Sentence before tokenization: Today is my day - off .\n",
            "Sentence before tokenization: But they rarely learn how to write English effectively , correctly .\n",
            "Sentence before tokenization: He is loudly speaking to sell .\n",
            "Sentence before tokenization: One paper was written in words .\n",
            "Sentence before tokenization: What is your purpose in learning languages ?\n",
            "Sentence before tokenization: I ca not play soccer but it makes me happy\n",
            "Sentence before tokenization: My today is mistake\n",
            "Sentence before tokenization: We prepared dinner by ourselves .\n",
            "Sentence before tokenization: I drove my car to the distant library and my favorite books were read for over hours .\n",
            "Sentence before tokenization: The teachers are really encouraging and motivating and I m learning a great deal from them .\n",
            "Sentence before tokenization: I have been advertising my class since I set the ball rolling as an English teacher for kids .\n",
            "Sentence before tokenization: The picture\n",
            "Sentence before tokenization: All the teachers are very good people .\n",
            "Sentence before tokenization: Whenever I buy something from Amazon .\n",
            "Sentence before tokenization: So , could we make a contact between the two organizations ?We are interested in it and have huge enthusiasm to make it .\n",
            "Sentence before tokenization: And never have students ' vacations anymore .\n",
            "Sentence before tokenization: Your fantasy is incredibly like mine !\n",
            "Sentence before tokenization: It is accidental .\n",
            "Sentence before tokenization: First of all , it is different in terms of word order .\n",
            "Sentence before tokenization: He plays with so many great artists , like Stan Gets , Chick Corea , Pat Metheny or Keith Jarrett and is known as a contemporary jazz musician as well .\n",
            "Sentence before tokenization: They would rather watch the football match actually , which was surprising !\n",
            "Sentence before tokenization: This attempt seemed to fail to catch on with my daughters .\n",
            "Sentence before tokenization: The printer worked again , another coupon said that buy half dozen and get discount .\n",
            "Sentence before tokenization: Big windy day\n",
            "Sentence before tokenization: chinese food has so many cooking techniques , and it is really hard to master them , i can cook too , but only normal dishes , and dumplings , i ca nt make noodles now , though i love the hand - made noodles so much , but i always make them in bad shape , so i have to practice more \n",
            "Sentence before tokenization: Sunday II\n",
            "Sentence before tokenization: Almost sleeping today .\n",
            "Sentence before tokenization: Unfortunately , I have slept on the bus when I go back to home from school .\n",
            "Sentence before tokenization: Main Courses Criminal Law , Civil Law , Accounting , Intellectual Property Law , Principles of Economics , Contract Law , Economic Law , Banking Law\n",
            "Sentence before tokenization: How to learn English words\n",
            "Sentence before tokenization: Those will be burned after drying and completed after about a month from today .\n",
            "Sentence before tokenization: The faithful translation may be mistranslation .\n",
            "Sentence before tokenization: Only you go with me\n",
            "Sentence before tokenization:  It is not a big deal to me . I watched the news and thought , because I grew up in Niigata , and I used to play in the snow .\n",
            "Sentence before tokenization: Nice to meet you ! !\n",
            "Sentence before tokenization: Often , a person who is late for minutes may skip pardoning at all .\n",
            "Sentence before tokenization: We successfully got the papers and quickly returned home .\n",
            "Sentence before tokenization: We are in Winter , and my brother did not take his coat because in the morning it was sunny .\n",
            "Sentence before tokenization: The waitress told us you guys have finished everything , it is good .\n",
            "Sentence before tokenization: but I also would like to make the most of my spare time to brush up on my English skills .\n",
            "Sentence before tokenization: I will tell you the correct answers .\n",
            "Sentence before tokenization: Most of all , because they , as well as me , needed to get more stamina from the food .\n",
            "Sentence before tokenization: Hot Spring\n",
            "Sentence before tokenization: At last I could climbed the mountain and I walked five hours that day .\n",
            "Sentence before tokenization: and the other answer , a man said that he wanted to be a sports car , the color of which was blue and made in japan .\n",
            "Sentence before tokenization: When you speak something , you can lead the conversation .\n",
            "Sentence before tokenization: It is not only delicious , but also plentiful and cheap .\n",
            "Sentence before tokenization: Lord of the rings two towers\n",
            "Sentence before tokenization: I got married I have two sons years old .\n",
            "Sentence before tokenization: Haha thanks my folks I love ya\n",
            "Sentence before tokenization: For instance , one of my friends could not decide what kinds of jobs to apply for , since he did not have any confidence in himself and he was not interested in anything .\n",
            "Sentence before tokenization: She was back to sleeping soon by feeding my breast .\n",
            "Sentence before tokenization: I slept well last night .\n",
            "Sentence before tokenization: And look over there , someone looks strange come .\n",
            "Sentence before tokenization: is high hurdles compared to passive study like leading and listening , \n",
            "Sentence before tokenization: Tomorrow is Saturday .\n",
            "Sentence before tokenization: Those kind of experience made me grow up I guess .\n",
            "Sentence before tokenization: Because it had a multi - touch screen and the glass was so thin .\n",
            "Sentence before tokenization: Fetch my glasses from my room !\n",
            "Sentence before tokenization: As we know , carrying a gun is illegal in China .\n",
            "Sentence before tokenization: I am not good at dissect my last score or weak points , nor think up I the best tactics .\n",
            "Sentence before tokenization: But I am studying English and Chinese now .\n",
            "Sentence before tokenization: Thanks , autumn !\n",
            "Sentence before tokenization: good night\n",
            "Sentence before tokenization: I have watch TV about high - school volleyball .\n",
            "Sentence before tokenization: It was coverd over by water .\n",
            "Sentence before tokenization: If it makes everyone happy and joyful and gives them a reason to cheer after such difficult times , then we have been successful .\n",
            "Sentence before tokenization: They were farmers , lost fields .\n",
            "Sentence before tokenization: I do not know why I am thinking about that cafe .\n",
            "Sentence before tokenization: Me against English\n",
            "Sentence before tokenization: I have reasons that I decided to close the nuclear plants .\n",
            "Sentence before tokenization: I like the BOURNE series and Matt Damon .\n",
            "Sentence before tokenization: I am worried for a while about this problem .\n",
            "Sentence before tokenization: There is a website which I would like to see .\n",
            "Sentence before tokenization: I can feel the gentle wind from the sea and breathe the flesh air .\n",
            "Sentence before tokenization: Therefore the condition of a needle is not good .\n",
            "Sentence before tokenization: He said in the US they do not have this kind of rock paper scissors .\n",
            "Sentence before tokenization: Feeling moments , which make up your story .\n",
            "Sentence before tokenization: I hope I will see you skating there .\n",
            "Sentence before tokenization: I arrived at the company on time .\n",
            "Sentence before tokenization: Please tell me in English .\n",
            "Sentence before tokenization: i went to the concert on sunday .\n",
            "Sentence before tokenization: I have visited Thailand , Indonesia , Malaysia , Italy , Egypt , China , and Canada .\n",
            "Sentence before tokenization: Excuse Me !\n",
            "Sentence before tokenization: For example .\n",
            "Sentence before tokenization: Holy Bible\n",
            "Sentence before tokenization: Tsunami was m high .\n",
            "Sentence before tokenization: and I had a look at the customer is hands when the accounting .\n",
            "Sentence before tokenization: This is what I was looking for .\n",
            "Sentence before tokenization: That changed my life forever .\n",
            "Sentence before tokenization: It is one of the blue cheese , and containing a blue mold .\n",
            "Sentence before tokenization: The most hated gadget for the British people .\n",
            "Sentence before tokenization: I ca not vote this election .\n",
            "Sentence before tokenization: However in Japan , cellphone owners must use the service carrier that sold the phone .\n",
            "Sentence before tokenization: I picked it up and put it in the plastic bag with the others .\n",
            "Sentence before tokenization: What a shame .\n",
            "Sentence before tokenization: Though it is happy , I feel lonely honestly .\n",
            "Sentence before tokenization: And we had a fun time .\n",
            "Sentence before tokenization: it is a bit , correct ?\n",
            "Sentence before tokenization: Do you know any good places ?\n",
            "Sentence before tokenization: For my listening practice , I wrote what I could hear .\n",
            "Sentence before tokenization: It gives them a brain wash .\n",
            "Sentence before tokenization: However , her level is surprising .\n",
            "Sentence before tokenization: I have many international penpal friends\n",
            "Sentence before tokenization: They are cute , are not they ?\n",
            "Sentence before tokenization: Q What is in the box ?\n",
            "Sentence before tokenization: The vent hole was used for colliery ventilation before , but now it is not used .\n",
            "Sentence before tokenization: I wish I could sing all of their songs .\n",
            "Sentence before tokenization: It was like reading about a stranger , because I changed pretty much .\n",
            "Sentence before tokenization: I ca not let this get to me !\n",
            "Sentence before tokenization: I learned a lot of words when I was a high school student .\n",
            "Sentence before tokenization: It seemed she suffered from peritonitis .\n",
            "Sentence before tokenization: Playing cards\n",
            "Sentence before tokenization: I felt like all of the theater poeple watch me .\n",
            "Sentence before tokenization: She also ignored other people because they were poor .\n",
            "Sentence before tokenization: However , it has been cold like winter in recent weeks , and I heard it still snowed in some mountain areas last weekend .\n",
            "Sentence before tokenization: Because the bird out of my tent kept crying as mee - mee - .\n",
            "Sentence before tokenization: Spring is comming to the corner .\n",
            "Sentence before tokenization: I looked outside and I felt sadness .\n",
            "Sentence before tokenization: lol Anyway , this class means a lot to me and I m sure it was worthwhile which will not only improve my English but broaden my thoughts and views in a good way .\n",
            "Sentence before tokenization: There is big cherry tree in my company is garden .\n",
            "Sentence before tokenization: I have never try to played sonwbording .\n",
            "Sentence before tokenization: As if in a sauna\n",
            "Sentence before tokenization: months ago\n",
            "Sentence before tokenization: Drunken driver is problem is not only there city but also all over the world , of course also Japan .\n",
            "Sentence before tokenization: VBA is just one way of them .\n",
            "Sentence before tokenization: And i finally got to release the huge burden , when my teacher postponed the deadline .\n",
            "Sentence before tokenization: After a few hours , my legs became tired and my bum started aching but the beautiful scenery distracted my mind from the tiredness and pain .\n",
            "Sentence before tokenization: Today I felt a little tired from the morning .\n",
            "Sentence before tokenization: Our watermelons grow near Astrakhan .\n",
            "Sentence before tokenization: father , mother , two sisters .\n",
            "Sentence before tokenization:  Sports and health courses are made clear in the standards pointing out that taking that the student develops as center , the student is main body position seriously , while paying attention to bringing the teaching activity , the middle teacher leading factor effect into play , emphasizing a student is main body position specially , learning enthusiasm and latent energy , and improving student sports in order to bring them into play sufficiently .\n",
            "Sentence before tokenization: Good evening !\n",
            "Sentence before tokenization: I have never climed Mt .\n",
            "Sentence before tokenization: I am very sad .\n",
            "Sentence before tokenization: And also , viewers who understand Japanese can read the Japanese and guess what I want to say .\n",
            "Sentence before tokenization: everyday there are a lot of things you have to face it , how to be happy ?\n",
            "Sentence before tokenization: I like picture books , so it is work is very fun !\n",
            "Sentence before tokenization: I ran approximately five kilometers this morning too .\n",
            "Sentence before tokenization: Dear Sir Madam , \n",
            "Sentence before tokenization: My father came home and she struck into another alley .\n",
            "Sentence before tokenization: I would like to explain in detail .\n",
            "Sentence before tokenization: so that it will never happen to me if you know what I mean haha .\n",
            "Sentence before tokenization: And there are four people in the family , parents , son and daughter .\n",
            "Sentence before tokenization: I am glad you were here .\n",
            "Sentence before tokenization: After minutes eating rice and tiny shrimp , seeing carefully the mab , I hurried run to my motorbike .\n",
            "Sentence before tokenization: I do not know where those hot summer days have gone .\n",
            "Sentence before tokenization: I have not known them before my friend told me .\n",
            "Sentence before tokenization: Why is it so popular among Japanese ?\n",
            "Sentence before tokenization: I feel so inconvenience , because I always buy something drink in station .\n",
            "Sentence before tokenization: I feel very sad . Are they all right now ?\n",
            "Sentence before tokenization:  I would like to restart practicing Karate , which I practised until I graduated from university .\n",
            "Sentence before tokenization: First , I want to tell you about myself .\n",
            "Sentence before tokenization: She seemed to be lost , and tried to ask someone where she was now .\n",
            "Sentence before tokenization: I went to Nissan Stadium for the first time .\n",
            "Sentence before tokenization: I have to go before my tears drop .\n",
            "Sentence before tokenization: And I will choose or .\n",
            "Sentence before tokenization: That phrase is what I said to the customers over the counter when I asked them to enter their PIN for their debit cards .\n",
            "Sentence before tokenization: game fun\n",
            "Sentence before tokenization: The first one is to wake up earlier at the morning .\n",
            "Sentence before tokenization: I thought topics\n",
            "Sentence before tokenization: I am not sure what effect the radiation leakage has on the food at this time .\n",
            "Sentence before tokenization: Could you tell me how you say it if you were me ? ?\n",
            "Sentence before tokenization: I think she does not have to diet any more , but she is a woman at the age of .\n",
            "Sentence before tokenization: Please correct this in writing .\n",
            "Sentence before tokenization: I would like to buy an English text book .\n",
            "Sentence before tokenization: Do not you interested in this ?\n",
            "Sentence before tokenization: To conclude , Mr\n",
            "Sentence before tokenization: Anyone do not enjoy dishs , drinks , and service .\n",
            "Sentence before tokenization: So I must be ready for dinner before I go to play them .\n",
            "Sentence before tokenization: to be continued .\n",
            "Sentence before tokenization: So today he came to see the house .\n",
            "Sentence before tokenization: I then started cursing him till we arrived in Dakar .\n",
            "Sentence before tokenization: Yesterday , I injected new function to one module .\n",
            "Sentence before tokenization: To communicate\n",
            "Sentence before tokenization: I do not know whether he is smart or not , but he is a very good squash player .\n",
            "Sentence before tokenization: I had a curry for lunch with my friend .\n",
            "Sentence before tokenization: But there is a dog in Q .\n",
            "Sentence before tokenization: He is a good friend , and I do not want to lose him .\n",
            "Sentence before tokenization: This year , I can not try new things .\n",
            "Sentence before tokenization: The hero is the coach of the team .\n",
            "Sentence before tokenization: We all expect to use the language to explore different cultures .\n",
            "Sentence before tokenization: I have no complain about my coworker , my job .\n",
            "Sentence before tokenization: And , I became a big person \n",
            "Sentence before tokenization: In contrast , there are not so many processes that need to be followed if your purchasing is just a laptop in a small company . All you need to do is just to get an approval from your direct manager and then buy it , and get your payback for it right now .\n",
            "Sentence before tokenization: So .\n",
            "Sentence before tokenization: In fact it takes only minutes to go to Kobe from Kyoto by JR , but takes minutes by Hankyu - train .\n",
            "Sentence before tokenization: I want to sleep and relax ! ! !\n",
            "Sentence before tokenization: Hello , my name is Pekari .\n",
            "Sentence before tokenization: In Korea , if i had a chance to talk in English , with my friend , i am used to talk in English .\n",
            "Sentence before tokenization: Fortunally , MRy speaks English properly , becouse my German is enough bad .\n",
            "Sentence before tokenization: Knock Knock !\n",
            "Sentence before tokenization: When Japanese people want to study abroad , they have to get good scores in TOEFL or IELTS .\n",
            "Sentence before tokenization: first time , it was easy ! ! !\n",
            "Sentence before tokenization: I think so .\n",
            "Sentence before tokenization: But very near the place of Asakusa , there are new buildings .\n",
            "Sentence before tokenization: According to world values , they are not left - wing , I guess .\n",
            "Sentence before tokenization: After a moment , villagers stared at the old man in wide - eyed amazement .\n",
            "Sentence before tokenization: I wish I have a big house with a large yard so that I can plant lots of plants .\n",
            "Sentence before tokenization: After coffee was a little bitter .\n",
            "Sentence before tokenization: I think that it should be so interested for me .\n",
            "Sentence before tokenization: If you think this is not , can you please suggest other way of saying this sentence ?\n",
            "Sentence before tokenization: Anyway , thank you all for your corrections and comments .\n",
            "Sentence before tokenization: Dreams are important for us , because they are the force that pushes us to success .\n",
            "Sentence before tokenization: That is all you have to do .\n",
            "Sentence before tokenization: I like drawing , reading and cooking vegan recipes .\n",
            "Sentence before tokenization: Ethnicity and Nationality\n",
            "Sentence before tokenization: However , the children who go through the ESL classes are not learning as\n",
            "Sentence before tokenization: Today I will show you a useful and convenient method to use .\n",
            "Sentence before tokenization: I m going to be a dad .\n",
            "Sentence before tokenization: It would be set up according to the traditional norms we accepted generally , such as responsibilities , respects , and equality .\n",
            "Sentence before tokenization: Today , I played kendo .\n",
            "Sentence before tokenization: On the othre hand , my friend was scolded many times by her and even his gurdians !xdddd\n",
            "Sentence before tokenization: Playing drum\n",
            "Sentence before tokenization: The printer worked again . Another coupon said buy half dozen and get a discount .\n",
            "Sentence before tokenization: This is my first diary in Lang - .\n",
            "Sentence before tokenization: Therefore , it can be said that there should be different numbers of male and female students based on what that subject is about .\n",
            "Sentence before tokenization: It is fun to find them in the sea .\n",
            "Sentence before tokenization: In other words , one can not study our cultural heritage without understanding the religious timeline .\n",
            "Sentence before tokenization: That was so much fun and learned a lot about Nepal people and culture .\n",
            "Sentence before tokenization: She asked me a speech there .\n",
            "Sentence before tokenization: Tell me about India , please .\n",
            "Sentence before tokenization: Probably you like them , whether you know it yourself or not .\n",
            "Sentence before tokenization: I should go to bed tonight .\n",
            "Sentence before tokenization: He comes from Brazil and has lived in NZ for years , so he can speak English fluently .\n",
            "Sentence before tokenization: It is true that tubes in NYC is dusky and seems to be dangerous at night .\n",
            "Sentence before tokenization: However , I do not agree with this point of view .\n",
            "Sentence before tokenization: tell one another D .\n",
            "Sentence before tokenization: And I collected many examples that body language in different countries has different meanings .\n",
            "Sentence before tokenization: Not only Japanese but also foreigners know and like them .\n",
            "Sentence before tokenization: I think you can not understand how strong this is by only looking at this shape .\n",
            "Sentence before tokenization: It is necessary and important for me to attend a university .\n",
            "Sentence before tokenization: And I have to go to several places in the US .\n",
            "Sentence before tokenization: I have a lot of homework today .\n",
            "Sentence before tokenization: I did it again !\n",
            "Sentence before tokenization: As some of you know , I go to university in Japan , and my major is political science and economics .\n",
            "Sentence before tokenization: that kind of stuff .\n",
            "Sentence before tokenization: I want to keep learning English .\n",
            "Sentence before tokenization: I m going to eat MacD ! ! !\n",
            "Sentence before tokenization: At that very moment she opened her eyes and smiled .\n",
            "Sentence before tokenization: I am a robot .\n",
            "Sentence before tokenization: But when you are in the office , you can joke with other workers .\n",
            "Sentence before tokenization: I bought a shirt and a cardigan .\n",
            "Sentence before tokenization: I ca nt understand .\n",
            "Sentence before tokenization: I think I will become very tired today .\n",
            "Sentence before tokenization: Please feel free to contact me on Lang - , \n",
            "Sentence before tokenization: Food that he dislikes Crab\n",
            "Sentence before tokenization: In Japanese society , people over are often considered as senior citizens .\n",
            "Sentence before tokenization: I want to eat Macdonald is hamburger .\n",
            "Sentence before tokenization: I have found it for year or more , , How long I will do that ? ?\n",
            "Sentence before tokenization: Of course , the travel fee is very very high .\n",
            "Sentence before tokenization: No . NZ is only Castle\n",
            "Sentence before tokenization: I appreciate that .\n",
            "Sentence before tokenization: Today I went to the International Airport to send off one of my friends , who was going back to China for a one - month holiday .\n",
            "Sentence before tokenization: By the way , I was the first to buy many books .\n",
            "Sentence before tokenization: I wish he was a superman .\n",
            "Sentence before tokenization: Slowly they come closer .\n",
            "Sentence before tokenization: OUTLET MALL\n",
            "Sentence before tokenization: Do you know a good dentist ? I introduced her to the best dentist I know .\n",
            "Sentence before tokenization:  God and music will give you happiness definitely , I told my son . The god is his mother passed away a year ago . The god is his mother passed away a year ago . This movie is so powerful and give us energy to live . This movie is so powerful and gives us energy to live . His mother is still living with us in our heart . His mother is still living with us in our hearts . And he plays the piano with his own feeling like writing a diary . And he plays the piano with his own feeling , like writing a diary . I can feel everything in his music . I can feel everything in his music . God bless him . God bless him . Long time no write . Long time no write . Hi , how have you been ? Hi , how have you been ? Oh , I know I can see that if I read your diary logs . Oh , I know I can see that if I read your diary logs . Also you can see about me if you read my blogs in Japanese . Also , you can see about me if you read my blogs in Japanese . Anyway , I am back here . Anyway , I am back here . I will restart to study English in small steps . I will restart studying English in small steps . What a big change in design this Lang - had . What a big change in design this Lang - has undergone . Maybe I ca not familiarise this for now . Maybe I ca not familiarise myself with this for now . Korea is season is spring now . Korea is season is spring now . I do not like winter because I could not well endure cold weather . I do not like winter because I ca not well endure cold weather . I like to see the road bloomed flowers . I like to see the road bloomed with flowers . Most roses will begin to bloom from late May . Most roses will begin to bloom from late May . I am looking forward to be May ! ! I am looking forward to May ! ! I overslpet myself this morning . I overslept myself this morning . I did not hear alarm bell sound . I did not hear an alarm bell sound . I should have waken up at am , i wake up at am . I should have woken up at am , I woke up at am . Oh my god Oh my god I threw some water on my face . I threw some water on my face . I put ong my clothes hurriedly and went out . I put on my clothes hurriedly and went out . Fourtunately I am not late for work . Fortunately I am not late for work . I reached the work to the minute . I reached the work on time . I had the devil is my luck ! I had the devil is luck ! Do you have a twitter , of blog ? Do you have a Twitter , or blog ? My twitter site is My Twitter site is Click here ! Click here ! It is rainy day It is a rainy day It is rainy day . It is a rainy day . When I have left my home , rain did not came out . When I left home , the rain did not come out . It was warm all the better . It was warmer all the better . I got up AM today . I got up at AM today . I would get up same time now and for ever . I would get up at the same time now and for ever . I have to participate in education in my club . I have to participate in education in my club . I feel good for starting early this morning . I feel good about starting early this morning . now , I am going to a University Cafeteria . Now , I am going to a university cafeteria . I could not eat breakfast , so I am hungry . I could not eat breakfast , so I am hungry . the bible the bible We can make our plans , but the LORD determines our steps . We can make our plans , but the LORD determines our steps . PROVERVS , PROVERVS , It was rainy day . It was a rainy day . We put up together an umbrella . We put up an umbrella together . We had a launch in famous restaurant . We had a lunch in a famous restaurant . This restaurant is famed handmade knife - cut noodles which contained a short - necked clam and variety vagetables .\n",
            "Sentence before tokenization: bye bye\n",
            "Sentence before tokenization: ABC TV acknowledged that ABC committed the handling of\n",
            "Sentence before tokenization: We DO have all those things ?\n",
            "Sentence before tokenization: I started to climb from AM .\n",
            "Sentence before tokenization: Today I am learning English .\n",
            "Sentence before tokenization: I am feeling that spring has just come !\n",
            "Sentence before tokenization: I saw Aussive Australian people going to work who are student , employees , children .\n",
            "Sentence before tokenization: Now I am writing some documents including some tutorials on the basic systems and how to use set up stuff .\n",
            "Sentence before tokenization: as much as possible by various kinds of means .\n",
            "Sentence before tokenization: I feel I should do so .\n",
            "Sentence before tokenization: But I did not notice that .\n",
            "Sentence before tokenization: because shortly join\n",
            "Sentence before tokenization: This is the time to stick together and bring peace in this site .\n",
            "Sentence before tokenization: Backstreet Boys\n",
            "Sentence before tokenization: I am absolutely attracted by the city is charm , and I look forward to making great success in the next few years , even though I am now just twenty years old .\n",
            "Sentence before tokenization: Good by New Year holidays !\n",
            "Sentence before tokenization: I sincerely pray for the repose of their souls .\n",
            "Sentence before tokenization: Additionally , my cold is not better .\n",
            "Sentence before tokenization: I am happy with how I look ! ! ! ! !\n",
            "Sentence before tokenization: I got a new domain !\n",
            "Sentence before tokenization: I can do it .\n",
            "Sentence before tokenization: Her team did not win the match yesterday .\n",
            "Sentence before tokenization: Challenge with preparation and lose with grace if you are a man .\n",
            "Sentence before tokenization: As I save some money , the following thing is to spend them , and I do not have chances to save .\n",
            "Sentence before tokenization: Wo not you have a chair , please ?\n",
            "Sentence before tokenization: It is almost storm .\n",
            "Sentence before tokenization: Someone on this site was wondering why did people want to learn japanease .\n",
            "Sentence before tokenization: Many volunteers repair broken toys once a month there .\n",
            "Sentence before tokenization: I am happy to spend a time with my brother .\n",
            "Sentence before tokenization: I made tofu hamburgers for dinner last night .\n",
            "Sentence before tokenization: I have a dog .\n",
            "Sentence before tokenization: My work is optimizing to develop a quantum memory which can keep quantum information .\n",
            "Sentence before tokenization: Thank you ?\n",
            "Sentence before tokenization: I made it ! !\n",
            "Sentence before tokenization:  , , is the th day of the ninth month of the Japanese traditional moon - calendar .\n",
            "Sentence before tokenization: In my opinion , finding out the actual reasons is very important but I would like to realise them appropriately at the present time .\n",
            "Sentence before tokenization: How should I think of the difference below ?\n",
            "Sentence before tokenization: Since my childhood I have liked to draw . In kindergarten the school girls were standing in a queue so I painted them all dolls , especially dolls in a swimsuit , and clothes that could be put on these dolls .\n",
            "Sentence before tokenization: We need constructive communication , and we should discuss what to do regardless of profession .\n",
            "Sentence before tokenization: Therefore , I think meats are better than fishes .\n",
            "Sentence before tokenization: I do not grab what they say so much despite weeks past .\n",
            "Sentence before tokenization: I was happy to hear that .\n",
            "Sentence before tokenization: Hair cut\n",
            "Sentence before tokenization: So now I am preparing a resume and script .\n",
            "Sentence before tokenization: Our teachers explained every sentence to us , and always ordered us to learn them by heart .\n",
            "Sentence before tokenization: It was great fun for me !\n",
            "Sentence before tokenization: I heard you should send money by registered mail by August th .\n",
            "Sentence before tokenization: My feeling\n",
            "Sentence before tokenization: I went shopping in the department store with my mother .\n",
            "Sentence before tokenization: I actually not .\n",
            "Sentence before tokenization: Also I received some request form the low court\n",
            "Sentence before tokenization: Is it enough for you ?\n",
            "Sentence before tokenization: I would visit some places .\n",
            "Sentence before tokenization: Right after he was arrested , the Minister of MIC was asked for his comments on this matter .\n",
            "Sentence before tokenization: Iris Sound Project\n",
            "Sentence before tokenization: frankly speaking I do not know which is right or wrong .\n",
            "Sentence before tokenization: I will continue learning about education to be a teacher or stop it .\n",
            "Sentence before tokenization: Do you think the Japanese train is too crowded ?\n",
            "Sentence before tokenization: The Japanese SAMURAI umbrella\n",
            "Sentence before tokenization: Today , I cooked hashed meat with rice .\n",
            "Sentence before tokenization: A melody is going on with us .\n",
            "Sentence before tokenization: It is a song describing my country , Belgium .\n",
            "Sentence before tokenization: I feel the speed of child s growth is so fast .\n",
            "Sentence before tokenization: Actually , I did not know we could eat dolphins and Japan has treated dolphins as food until I met a girl who would ever eaten dolphin meat .\n",
            "Sentence before tokenization: After I finished my interview with the manager , he said , I will give you a phone call tomorrow between p . m . to to see if we employ you . But my phone did not ring .\n",
            "Sentence before tokenization: If you want to delete files in a drive F , put them into Recycle Bin , and delete from Recycle Bin .\n",
            "Sentence before tokenization: Due to the event , I was depressed all the day .\n",
            "Sentence before tokenization: so I have little confidence .\n",
            "Sentence before tokenization: Korean thing\n",
            "Sentence before tokenization: The complexity of characters would stand in the middle of Kanji and alphabets , very close to alphabets though .\n",
            "Sentence before tokenization: I departed from Japan to Korea , then I stayed in Incheon , then I departed from Korea to U .\n",
            "Sentence before tokenization: Hello , Nice to meet you .\n",
            "Sentence before tokenization: But frankly .\n",
            "Sentence before tokenization: Also you can catch a dangerous disease .\n",
            "Sentence before tokenization: Especially , I llke Love story is PV .\n",
            "Sentence before tokenization: When Japanese want to study abroad , they have to get good score of TOEFL or IELTS .\n",
            "Sentence before tokenization: But Korean people do not do it even though some of them have tiny ones .\n",
            "Sentence before tokenization: Because there was a wonderful teacher he liked .\n",
            "Sentence before tokenization: Therefore , you do not need to calibrate the foot length and counts per foot step .\n",
            "Sentence before tokenization: So I scanned the sketches into my computer and used the software freehand and photoshop to do the designing .\n",
            "Sentence before tokenization: Our team played once more .\n",
            "Sentence before tokenization: The friend and I are both university students and far from the rich .\n",
            "Sentence before tokenization: Just Korea is developing country than Japan ?\n",
            "Sentence before tokenization: Although I showed my student identification card , I had to show my pass in addtion to my student identification card .\n",
            "Sentence before tokenization: swine flu in Mexico\n",
            "Sentence before tokenization: especialy , I want to became to hear English .\n",
            "Sentence before tokenization: The birthday\n",
            "Sentence before tokenization: Do not forget to charge the battery beforehand .\n",
            "Sentence before tokenization: Recently , I saw one of his books called The pleasures and sorrows of work and felt some kind of relieved .\n",
            "Sentence before tokenization: Anyway I bring up the plant .\n",
            "Sentence before tokenization: When I was a colledge student , I met a Turkish guy .\n",
            "Sentence before tokenization: Above all , nowadays , college students face great employment pressure .\n",
            "Sentence before tokenization: I had a good time .\n",
            "Sentence before tokenization: Today , the emphasis on planting ornamental trees in Vancouver has decreased due to the fact that large trees are needed for their environmental benefits .\n",
            "Sentence before tokenization: thankyou for your helps\n",
            "Sentence before tokenization: He just talked about Korea .\n",
            "Sentence before tokenization: I feel good .\n",
            "Sentence before tokenization: I need something new , fresh , that says I am the one !\n",
            "Sentence before tokenization: It is weird but I think other people have this kind of experience too .\n",
            "Sentence before tokenization: I was enjoyed English conversation .\n",
            "Sentence before tokenization: It is a very eco - friendly product .\n",
            "Sentence before tokenization: I grant a dream .\n",
            "Sentence before tokenization: I managed to achieve the aim on the fourth try .\n",
            "Sentence before tokenization: She answered that she knew lang - for two years ago .\n",
            "Sentence before tokenization: My husband and I go for grocery shopping every weekend .\n",
            "Sentence before tokenization: Every day is a continuance of surprises since I came to Tokyo .\n",
            "Sentence before tokenization: usually and occasionally in my writings .\n",
            "Sentence before tokenization: since we do not want to make him or her feel unpleasant by denying his or her opinion .\n",
            "Sentence before tokenization: I knew the name , but I had never tried to do it .\n",
            "Sentence before tokenization: I should study hard and I should be talkative .\n",
            "Sentence before tokenization: Going to work tomorrow , I can sleep longly\n",
            "Sentence before tokenization: We enjoyed our summer !\n",
            "Sentence before tokenization: But , children around here got survival splits .\n",
            "Sentence before tokenization: The advertisement I made\n",
            "Sentence before tokenization: I woke up at , and arrived at my work at .\n",
            "Sentence before tokenization: Please give me your help to correct it !\n",
            "Sentence before tokenization: I bought some pork livers when I got off work .\n",
            "Sentence before tokenization: It looks like something .\n",
            "Sentence before tokenization: Although today was a part time job in while , Japan was hit a typhoon .\n",
            "Sentence before tokenization: An actor visited a place he visited years ago and met the\n",
            "Sentence before tokenization: If l could go anywhere , I would go to Italy .\n",
            "Sentence before tokenization: i do nt know .\n",
            "Sentence before tokenization: I was almost certain to be working later in Asia , but I felt like I should nt be there , and I felt like a fraud , that my research would be scrutinized , and my findingswould be immediately dismissed , as they were coming from a Caucasian student .\n",
            "Sentence before tokenization: My favorite instrument\n",
            "Sentence before tokenization: The sun does not sympathize with my feelings .\n",
            "Sentence before tokenization: I also understand a little bit of German , but i do not like this language .\n",
            "Sentence before tokenization: She is too little to ride bicycle !\n",
            "Sentence before tokenization: Then , what do I want to do ?\n",
            "Sentence before tokenization: We leaped at the chance to experience D TV in person .\n",
            "Sentence before tokenization: So I love that store .\n",
            "Sentence before tokenization: This is our adopt of company introduction\n",
            "Sentence before tokenization: My father was wounded .\n",
            "Sentence before tokenization: My firends introduced me here and I hope I can make friend with you .\n",
            "Sentence before tokenization: I enjoy the temperature of the four seasons .\n",
            "Sentence before tokenization: Life is too short .\n",
            "Sentence before tokenization: Time flies like an arrow and I have really a plenty of things to do !\n",
            "Sentence before tokenization: It is not the first time .\n",
            "Sentence before tokenization: These questions were about PLAGUE BACILLUS .\n",
            "Sentence before tokenization: I once received the comment shown below .\n",
            "Sentence before tokenization: I think that the Sinam government should support the Humanitarian Aid Programme .\n",
            "Sentence before tokenization: M University , March , \n",
            "Sentence before tokenization: maybe some little text about music .\n",
            "Sentence before tokenization: My noon , my midnight , my talk , my song , \n",
            "Sentence before tokenization: The front makes threats against the fans who have startded a demonstration .\n",
            "Sentence before tokenization: i am learning endocrinology here , and i am looking forward to going further study in US or japan .\n",
            "Sentence before tokenization: In English\n",
            "Sentence before tokenization: The entomologist tried to run away from the place at first , but he was gradually getting accustomed to the oppressive situation .\n",
            "Sentence before tokenization: Recently , Japanese Prime Ministers quit so early .\n",
            "Sentence before tokenization: First of all , thanks for Lang - providing useful tools for us .\n",
            "Sentence before tokenization: I have a part - time job at fast food restaurant .\n",
            "Sentence before tokenization: I think writing is a very difficult skill .\n",
            "Sentence before tokenization: You can correct it at all .\n",
            "Sentence before tokenization: I am yuki .\n",
            "Sentence before tokenization: I am always running towards the ball of the conversation .\n",
            "Sentence before tokenization: After a long freezing winter , spring finally comes .\n",
            "Sentence before tokenization: It was just snowing yesterday .\n",
            "Sentence before tokenization: Became a adult , I work by using ski in winter .\n",
            "Sentence before tokenization: I took some examinations last and this week .\n",
            "Sentence before tokenization: I will be unable to keep the diary for about one week .\n",
            "Sentence before tokenization: She is a good students but I study more less .\n",
            "Sentence before tokenization: So Kay could not believe that how Corlesone family have a realetionship with him .\n",
            "Sentence before tokenization: But , on the earth , why did the price on buckwheat rise twice ? !\n",
            "Sentence before tokenization: Memory is the biggest , time - honored reward for an artist .\n",
            "Sentence before tokenization: But in general , you would nt do so .\n",
            "Sentence before tokenization: To ask about someone is career , you use the pattern \n",
            "Sentence before tokenization: Your wife to try some really good wines .\n",
            "Sentence before tokenization: In my club , there are .\n",
            "Sentence before tokenization: Needless to say , I like good - looking women .\n",
            "Sentence before tokenization: I spent a month there years ago .\n",
            "Sentence before tokenization: Hello everyone , this is Masao in Tokyo Japan .\n",
            "Sentence before tokenization: My friends say that I and my sister look like twins .\n",
            "Sentence before tokenization: I want to go there again !\n",
            "Sentence before tokenization: H N has spreaded in China and all over the world .\n",
            "Sentence before tokenization: As I feel I have enough motivation to write , I am so untalented that nothing is coming up to me , but I just want to say thanks to all the people on lang - , not only those who corrected my journal but also all the correctors on this site .\n",
            "Sentence before tokenization:  I do not know , but tears comes up automatically .\n",
            "Sentence before tokenization: need to see double doctors\n",
            "Sentence before tokenization: He has many problems because he lives in Yokohama where is that the earthquake influence is so big area .\n",
            "Sentence before tokenization: Although some entertaining educational methods have been applied to schooling , the effects of those informal teaching ways are unsatisfied .\n",
            "Sentence before tokenization: But I did not notice that .\n",
            "Sentence before tokenization: Cold and warm\n",
            "Sentence before tokenization: So unless you stay for minutes or longer , you will not be paid for the overtime .\n",
            "Sentence before tokenization: Is it true ?\n",
            "Sentence before tokenization: Our baby Riku cries all the time .\n",
            "Sentence before tokenization: I guess that the reason why I came to like basketball is Japanese comics when I was in elementary school .\n",
            "Sentence before tokenization: Nobody forced or asked her to do so .\n",
            "Sentence before tokenization: Both of these were so hard for me .\n",
            "Sentence before tokenization: I want to sleep\n",
            "Sentence before tokenization: and looked around the inside of ICJ . In addition , I visited the library of ICJ and could find some articles for my thesis .\n",
            "Sentence before tokenization: I recommend that you should have a medical checkup regularly .\n",
            "Sentence before tokenization: Today is a boring day .\n",
            "Sentence before tokenization: ON reading the sentence you understand . it is too far , I can not carry this body with me I give my self to lament , every part of it is just like a star becoming tears .\n",
            "Sentence before tokenization: We are probably going to be good friends !\n",
            "Sentence before tokenization: However , such reactive fixes have not addressed the underlying causes of uncertain inflationary increases and increased utilization .\n",
            "Sentence before tokenization: Second , all you need to do is just workout clothes , a bottle of water , a towel for a lot of sweats .\n",
            "Sentence before tokenization: When it is low tide we go to the sea .\n",
            "Sentence before tokenization: It is called beginning japanology .\n",
            "Sentence before tokenization: I am glad for you to point out my mistake and to teach me the correct sentence .\n",
            "Sentence before tokenization: We needed to walk about min .\n",
            "Sentence before tokenization: However , it sweats .\n",
            "Sentence before tokenization: The service has a lot of customers already .\n",
            "Sentence before tokenization: Lang - no longer remembers me !\n",
            "Sentence before tokenization: I will imitate it little by little .\n",
            "Sentence before tokenization: In Imperial University , classes were conducted in English , French or German .\n",
            "Sentence before tokenization: I want to get a magic wand and broomstick .\n",
            "Sentence before tokenization: I feel the hardness of playing soccer .\n",
            "Sentence before tokenization: I am likely to be a genius , because I can see what governments\n",
            "Sentence before tokenization: If you tell the day is your birthday when you buy a ticket , a ticket seller will give you a Happy Birthday sticker .\n",
            "Sentence before tokenization: He also taught me some tongue twister .\n",
            "Sentence before tokenization: This is my first entry on Lang - .\n",
            "Sentence before tokenization: If you spend such a holiday in New York , you have to pay the payment shown below .\n",
            "Sentence before tokenization: I had a plan to go out with my daughter , but I canceled it .\n",
            "Sentence before tokenization: But if you are already ill with arteriosclerosis , it is better to restrict eating eggs . or eggs per day are acceptable .\n",
            "Sentence before tokenization: I am a second highschool student , so I will take it in one year .\n",
            "Sentence before tokenization: Moreover , a number of them who live alone or live with their husband or wife without young people .\n",
            "Sentence before tokenization: I will write many things such as my studying record about chemistry , physics and English , my thinking on some news and simply event I will experience in the day .\n",
            "Sentence before tokenization: Husband is playing a game next to me .\n",
            "Sentence before tokenization: might apply the custom of transmitting mail after it confirms it again by you .\n",
            "Sentence before tokenization: Then one win and two losses - I was back to square one as an egg .\n",
            "Sentence before tokenization: I love a spa with a slower pace .\n",
            "Sentence before tokenization: Was I correct ?\n",
            "Sentence before tokenization: This is a DVD for shadowing .\n",
            "Sentence before tokenization: And I cleaned the flat and cooked soup .\n",
            "Sentence before tokenization: I want to keep a diary for as a long time as possible .\n",
            "Sentence before tokenization: Hope you enjoy your college life !\n",
            "Sentence before tokenization: Japanese spirit has grown up in this environment .\n",
            "Sentence before tokenization: One firefly flew and stopped at my son is feet .\n",
            "Sentence before tokenization: I will be glad to see your comments .\n",
            "Sentence before tokenization: I hate eating the same food and hunting every day .\n",
            "Sentence before tokenization: I like to read old literature of foreign country .\n",
            "Sentence before tokenization: When I laugh , they know me I was actually very sad .\n",
            "Sentence before tokenization: I have been walking for - hours every day .\n",
            "Sentence before tokenization: There were already a huge number of people there , and I could not even sit .\n",
            "Sentence before tokenization: But it is not so wet as under the rain because water is not falling down but floating in the air .\n",
            "Sentence before tokenization: I am afraid I am not sure about Sailor Moon because I am not a young girl .\n",
            "Sentence before tokenization: The moon wanes , \n",
            "Sentence before tokenization: I do not know how to correct , , , haha\n",
            "Sentence before tokenization: I am sorry about it but it was such fun and I could not help it .\n",
            "Sentence before tokenization:  ' Brave guy , ' I thought , but the next moment I saw several people follow him .\n",
            "Sentence before tokenization: There are local elections in Japan on the weekend .\n",
            "Sentence before tokenization: We had a BBQ at the park , Cleland Park .\n",
            "Sentence before tokenization: Today , I went to go to the gym and I sweated a lot .\n",
            "Sentence before tokenization: I could not help smiling when I saw the card .\n",
            "Sentence before tokenization: Today is Thursday , the weather changed \n",
            "Sentence before tokenization: I love English !\n",
            "Sentence before tokenization: Do not laugh !\n",
            "Sentence before tokenization: because shortly join\n",
            "Sentence before tokenization: In their common sense it seems woman change her family name when she get married .\n",
            "Sentence before tokenization: She loves them a lot .\n",
            "Sentence before tokenization: I found a web service of web - template delivering membership .\n",
            "Sentence before tokenization: Sports meet\n",
            "Sentence before tokenization: I absolutely love rain , but I am really really tired of rains in my town this month .\n",
            "Sentence before tokenization: I use learn idiom as a reference TV .\n",
            "Sentence before tokenization: They are , like my younger brothers and younger sister , really lovely !\n",
            "Sentence before tokenization: However , every place was so crowded with a long queue .\n",
            "Sentence before tokenization: There are some pages trying to translate the lyrics to Japanese , but I do not think any of them are great .\n",
            "Sentence before tokenization: There is an adverb For two hares to chase , no one you wo not catch \n",
            "Sentence before tokenization: Good luck !\n",
            "Sentence before tokenization: And let me begin to write something about my yesterday .\n",
            "Sentence before tokenization: I do not know the whole list .\n",
            "Sentence before tokenization: I was totally surprised .\n",
            "Sentence before tokenization: There are five gold medals in total with them !\n",
            "Sentence before tokenization: It was heavy rainy today .\n",
            "Sentence before tokenization: The one I used , I think that was no good enough .\n",
            "Sentence before tokenization: The name of the meal is ' Iftal ' .\n",
            "Sentence before tokenization: I use a computer when composing music .\n",
            "Sentence before tokenization: Then I have lived Tokyo now .\n",
            "Sentence before tokenization: new bicycle\n",
            "Sentence before tokenization: It is a very polite way to say .\n",
            "Sentence before tokenization: Today I went to a place to donate my BP .\n",
            "Sentence before tokenization: So please help me imporve my English skill .\n",
            "Sentence before tokenization: We college students should study better , so that we can set up some mechanism which can not only clean up the pollution , but also create something without polluting .\n",
            "Sentence before tokenization: I do not like summer .\n",
            "Sentence before tokenization: My mother told me that Santa is gone .\n",
            "Sentence before tokenization: It is lucky that my Mom not only did not care but also taught me enthusiastically .\n",
            "Sentence before tokenization: If only we seek them with our eyes open , there is no unrecognized death .\n",
            "Sentence before tokenization: I only study and sleep these days and I did nt have nothing special .\n",
            "Sentence before tokenization: If you are interested in the website , you should not wait to ask me .\n",
            "Sentence before tokenization: After you finish watching the video clip , please scroll down a little bit .\n",
            "Sentence before tokenization: I did not know what I should write about , but I could not wait !\n",
            "Sentence before tokenization: Since it is the lunar New Year now , his other family went out .\n",
            "Sentence before tokenization: I have his work in English .\n",
            "Sentence before tokenization: The party was the first time all of us had gathered .\n",
            "Sentence before tokenization: Hahaha , , , Specially , that is not good for my body .\n",
            "Sentence before tokenization: Thanks a lot !\n",
            "Sentence before tokenization: So , I ordered twice the regular size .\n",
            "Sentence before tokenization: In Japan , one meal consists of one main food like rice , one side food like meat or fish , and one soup .\n",
            "Sentence before tokenization: It would be difficult but I am sure that it will be worth trying .\n",
            "Sentence before tokenization: Besides , you know , the building\n",
            "Sentence before tokenization: The Model United Nations\n",
            "Sentence before tokenization: Someone who I would ever seen , is not very close to me .\n",
            "Sentence before tokenization: But I can not understand words because these are too difficult .\n",
            "Sentence before tokenization: but my knowledge , what shoud i do ?\n",
            "Sentence before tokenization: father thank you !\n",
            "Sentence before tokenization: cherry blossoms\n",
            "Sentence before tokenization: All his films interesting .\n",
            "Sentence before tokenization: The i n Taglib technology of the JSTL was applied .\n",
            "Sentence before tokenization: So it is good for the diet .\n",
            "Sentence before tokenization: I have no complaints about my coworkers , my job .\n",
            "Sentence before tokenization: Please be a friend . If we ca not speak the same language , it is not so good .\n",
            "Sentence before tokenization: By the way , there is a railroad that runs a steam locomotive in the next swimming pool .\n",
            "Sentence before tokenization: It is important for learning foreign languages to listen a lot .\n",
            "Sentence before tokenization: Be honest with myself .\n",
            "Sentence before tokenization: I hope to get better soon .\n",
            "Sentence before tokenization: Although I did not decide to buy particularly clothes .\n",
            "Sentence before tokenization: I hope I get many friends who teach me these languages .\n",
            "Sentence before tokenization: I think it is enough time to study for them a day .\n",
            "Sentence before tokenization: The biggest problem is that I ca not speak Chinese at all , only very simple greeting words .\n",
            "Sentence before tokenization: Hi , How is it going today ? ?\n",
            "Sentence before tokenization: we are looking forward to your confirmation soon .\n",
            "Sentence before tokenization: He has passed away in th May .\n",
            "Sentence before tokenization: But it can only accept coin and three dollar was needed to use .\n",
            "Sentence before tokenization: This is my first posting but I have no idea what I should write about .\n",
            "Sentence before tokenization: Sometimes getting drunk will cost something people can not afford .\n",
            "Sentence before tokenization: i am in job hunting .\n",
            "Sentence before tokenization: I am going to take a vacation the last week of this month .\n",
            "Sentence before tokenization: I have just watched the movie ' social network '\n",
            "Sentence before tokenization: It is famous that there is always a huge number of Japanese tourists in Hawaii .\n",
            "Sentence before tokenization: So I was relieved !\n",
            "Sentence before tokenization: However , I have to work on presentation and comparative summary\n",
            "Sentence before tokenization: But I have felt burned out before the test .\n",
            "Sentence before tokenization: Your fantasy is incredibly like mine !\n",
            "Sentence before tokenization: I would like to write about my sister .\n",
            "Sentence before tokenization: when i was over sea to travel .\n",
            "Sentence before tokenization: The good is very cheap and the express deliver is fast .\n",
            "Sentence before tokenization: There are mainly two methods .\n",
            "Sentence before tokenization: I thought why I felt bad in the bed .\n",
            "Sentence before tokenization: Since I make my bang , \n",
            "Sentence before tokenization: The so - called ' Handkerchief Prince ' dominated the national sports media coverage five years ago .\n",
            "Sentence before tokenization: There are cream - filled pastry .\n",
            "Sentence before tokenization: He knows that I will go to Canada in this fall .\n",
            "Sentence before tokenization: I went to a cafe with my friend .\n",
            "Sentence before tokenization: The people in the Joumon era invented an earthen vessel more than , years ago .\n",
            "Sentence before tokenization: My mother bought math workbook for me .\n",
            "Sentence before tokenization: As a professional customer service , I take my passion to service everyone . That is my pressure to make customers smile , because that is our object .\n",
            "Sentence before tokenization: It has been a long time .\n",
            "Sentence before tokenization: That is so cute !\n",
            "Sentence before tokenization: I have to go to AEON to learn English this afternoon .\n",
            "Sentence before tokenization: If you work hard , you will have a good time in your school life and your parents will be pleased with your growth too .\n",
            "Sentence before tokenization: I think this is due to abnormal weather .\n",
            "Sentence before tokenization: Blue , to\n",
            "Sentence before tokenization: What is more , which one is easier ?\n",
            "Sentence before tokenization: It is my day off today .\n",
            "Sentence before tokenization: On February is the man is day .\n",
            "Sentence before tokenization: but still difficult for me to use it .\n",
            "Sentence before tokenization: On my way home , I decided to write about this cafe and the book .\n",
            "Sentence before tokenization: The party finished when each people give congratulations and all the best wishes to the host .\n",
            "Sentence before tokenization: This is my first time using Lang - in my life .\n",
            "Sentence before tokenization: I slept at our living room for only one hour .\n",
            "Sentence before tokenization: They all say This is international woman is day , but immediately surprised me , who else is celebrating this holiday ? .\n",
            "Sentence before tokenization: so my wife prepare some food .\n",
            "Sentence before tokenization: If you have time , you should go volunteer for TOHOKU !\n",
            "Sentence before tokenization: It is a common and not interesting type of conversation .\n",
            "Sentence before tokenization: so i m thinking about i will or not .\n",
            "Sentence before tokenization: I really happy and quite surprised .\n",
            "Sentence before tokenization: but I was sleeping at it time .\n",
            "Sentence before tokenization: So I waited for ten minutes .\n",
            "Sentence before tokenization: I have a question .\n",
            "Sentence before tokenization: As soon as I finish my classes , I will go to the movie theater near her house .\n",
            "Sentence before tokenization: Then , I went to a cell phone maintenance center .\n",
            "Sentence before tokenization: Please help Japanese .\n",
            "Sentence before tokenization: In the afternoon , I read a comic and played with Miguel .\n",
            "Sentence before tokenization: It is a serious problem ! !\n",
            "Sentence before tokenization: I recently enrolled on a course at my university .\n",
            "Sentence before tokenization: Anyway , I am going to keep using the soap shampoo for a while .\n",
            "Sentence before tokenization: But he seems very cool , lol .\n",
            "Sentence before tokenization: It is a pitty that I can not get back to there , but I hope and expect that I could be work at overseas branch office somedays .\n",
            "Sentence before tokenization: Yesterday , I tried on kimonos .\n",
            "Sentence before tokenization: The second one is more general .\n",
            "Sentence before tokenization: I must admit , I am not convinced that anyone would answer me , but still I want to try .\n",
            "Sentence before tokenization: Only by this way can I learn English better .\n",
            "Sentence before tokenization: The latest news that most impressed me\n",
            "Sentence before tokenization: That will be great .\n",
            "Sentence before tokenization: I picked up this word in the class when I was a high school student .\n",
            "Sentence before tokenization: Recently , Japanese Prime Ministers quit so early .\n",
            "Sentence before tokenization: Good evening all .\n",
            "Sentence before tokenization: Therefore , if possible , I would like you to make two thank you letters to both of them .\n",
            "Sentence before tokenization: Is there anybody to scold my laziness ?\n",
            "Sentence before tokenization: How poor he is today !\n",
            "Sentence before tokenization: Two months passed from the earthquake .\n",
            "Sentence before tokenization: It looked like it came apart automatically .\n",
            "Sentence before tokenization: But I first saw his work the other day , I was amazed at its dramatic perspective and effective compositions .\n",
            "Sentence before tokenization: I use a computer when compose music .\n",
            "Sentence before tokenization: We ca not purchase movies and TV programs at present in Japan .\n",
            "Sentence before tokenization: So , Could you tell me the interesting anime ?\n",
            "Sentence before tokenization: Wife to her husband I made it to Dallas .\n",
            "Sentence before tokenization: They decided to return him back to Africa .\n",
            "Sentence before tokenization: I chose previous one , because I am not buddist .\n",
            "Sentence before tokenization: But , it was not long before I realized that I can climb over any steep paths by taking step by step .\n",
            "Sentence before tokenization: In pants pockets , on the bed , on the table and so on .\n",
            "Sentence before tokenization: A Tommorow , will you have any time after school ?\n",
            "Sentence before tokenization: People started to eat healthy food which contains less fat and more vitamins .\n",
            "Sentence before tokenization: There are numerous viewing spots of cherry trees in Kyoto .\n",
            "Sentence before tokenization: There was not which .\n",
            "Sentence before tokenization: Yesterday , one of my Japanese friends insisted that ' real ' is not an antonym of ' imaginary ' .\n",
            "Sentence before tokenization: The path is length is about km .\n",
            "Sentence before tokenization: I often ask my friends and classmates what they are planning for the coming May day .\n",
            "Sentence before tokenization: Yesterday I made dumplings for dinner .\n",
            "Sentence before tokenization: Because We foreighner was so difficult to connect an aussie .\n",
            "Sentence before tokenization: but they do not have the whole transcript .\n",
            "Sentence before tokenization: Recently , solving a quiz to get a free ticket for pizzas has been in mode in our school .\n",
            "Sentence before tokenization: I was moved , and think of\n",
            "Sentence before tokenization: I am preparing for shipping .\n",
            "Sentence before tokenization: However , when it comes to electric retail stores , the situation is different .\n",
            "Sentence before tokenization: So I can do anything !\n",
            "Sentence before tokenization: I take a walk my dog every morning and evening , brush his hair , take him a shower and give foods .\n",
            "Sentence before tokenization: Today , I will work in the night shift .\n",
            "Sentence before tokenization: In , I went to America for weeks by myself .\n",
            "Sentence before tokenization: Should I straddle and crush my nuts ?\n",
            "Sentence before tokenization: I do not know the reason why .\n",
            "Sentence before tokenization: Actually , I want to move there to reduce my drift time on the way there .\n",
            "Sentence before tokenization: Therefore , I have had to improve my English skills so I have a plan to move to the next level class .\n",
            "Sentence before tokenization: I tore them into pieces one after another and put them into a plastic bag .\n",
            "Sentence before tokenization: I did nt have any reason not to join it ! !\n",
            "Sentence before tokenization: Is this just a coinsidence ?\n",
            "Sentence before tokenization: I am happy these vegetables I am raising are growing well .\n",
            "Sentence before tokenization: in the background of the picture , some maps are posted on the wall .\n",
            "Sentence before tokenization: The day promised was coming .\n",
            "Sentence before tokenization: I will be looking forward to this latest book .\n",
            "Sentence before tokenization: He is claver than other characters .\n",
            "Sentence before tokenization: GOOD LUCK TO ME AND GOOD LUCK TO YOU .\n",
            "Sentence before tokenization: His dance is powerful and beautiful .\n",
            "Sentence before tokenization: Next we plan to use it in the math class and we want to teach other math teachers how to make use it .\n",
            "Sentence before tokenization: What is the definition of insanity ?\n",
            "Sentence before tokenization: Maybe I am mad , maybe I should see a doctor , I really do not know , but I really have to try on those costumes and that makeup !\n",
            "Sentence before tokenization: I think most people like it .\n",
            "Sentence before tokenization: But , I was forced to wake up by a friend of mine \n",
            "Sentence before tokenization: Now I know that high school boys are childish and foolish , \n",
            "Sentence before tokenization: It was delicious .\n",
            "Sentence before tokenization: Have not you lost your goals ?\n",
            "Sentence before tokenization: I will write something about myself the next time , and I hope you ll help me to correct my mistakes .\n",
            "Sentence before tokenization: It means I put half hot water in the bath and be in it for minutes .\n",
            "Sentence before tokenization: very hot\n",
            "Sentence before tokenization: The height of the tower was taller than it was two months before , compared to the first picture , and construction of the second observatory had just begun .\n",
            "Sentence before tokenization: I always wanted to buy it\n",
            "Sentence before tokenization: However , I think handwriting has something special .\n",
            "Sentence before tokenization: I read chinese young boy is diary who suffering from acne .\n",
            "Sentence before tokenization: Today , I would like to write about the way of thinking .\n",
            "Sentence before tokenization: I Love You that is movie .\n",
            "Sentence before tokenization: I recently became hooked on Cyworld .\n",
            "Sentence before tokenization: It is degrees , but still in the morning .\n",
            "Sentence before tokenization: fully booked already .\n",
            "Sentence before tokenization: It should not be ! ! !\n",
            "Sentence before tokenization: Swine flu in Mexico\n",
            "Sentence before tokenization: A bowl of rice with seasoning ingredients .\n",
            "Sentence before tokenization: i did not go to the lecture today again\n",
            "Sentence before tokenization: Maybe he mocked me .\n",
            "Sentence before tokenization: If you do not mind please make curry a pot .\n",
            "Sentence before tokenization: But movie is story is not interesting\n",
            "Sentence before tokenization: All my friends have now got a job .\n",
            "Sentence before tokenization: I have a lot of sleeping time .\n",
            "Sentence before tokenization: The body is built of Japanese cypresses .\n",
            "Sentence before tokenization: Now , i study Engrish .\n",
            "Sentence before tokenization: I found a website offering web - template delivering membership .\n",
            "Sentence before tokenization: send for\n",
            "Sentence before tokenization: Today the Gion festival parade was held in Kyoto .\n",
            "Sentence before tokenization: Xmas night must be sooo nice\n",
            "Sentence before tokenization: They seem to love each other .\n",
            "Sentence before tokenization: Then I went to a bar where I go often .\n",
            "Sentence before tokenization: I watching to their body every day .\n",
            "Sentence before tokenization: Their mother had gone through a very hard time to have them .\n",
            "Sentence before tokenization: There were beautiful mountains in my home town and we had beautiful snow every winter .\n",
            "Sentence before tokenization: Therefore , I apply only to such companies now .\n",
            "Sentence before tokenization: I seem to have forgotten the feeling of my golf swing in Japan , gradually .\n",
            "Sentence before tokenization: I am an only child , so I am looking forward to having a sister .\n",
            "Sentence before tokenization: The teacher said your speaking skills are low , so you should not change class .\n",
            "Sentence before tokenization: How can we be productive on important lessons ?\n",
            "Sentence before tokenization: I am unbelievable and where do my feelings go on ?\n",
            "Sentence before tokenization: You know , there are a number of people willing to spend money on what they want to buy , such like clothes , cars .\n",
            "Sentence before tokenization: I admit that I was lazy .\n",
            "Sentence before tokenization: Also while some children are litle angels , others are complete brats .\n",
            "Sentence before tokenization: But today I studied , and tomorrow I will have a day off , although on Wednesday we are studying .\n",
            "Sentence before tokenization: is the motel called Best American .\n",
            "Sentence before tokenization: You squandered it all in an hour .\n",
            "Sentence before tokenization: So I sometimes leave dishes in the kitchen after dinner .\n",
            "Sentence before tokenization: Very simple and small water colored pictures .\n",
            "Sentence before tokenization: I love Greek food .\n",
            "Sentence before tokenization: Actually I ca not drink Japanese beeer because it is too bitter for me and taste is also strange .\n",
            "Sentence before tokenization: There is no foreigners here .\n",
            "Sentence before tokenization: Even though we are busy , we should not forget to build our personality .\n",
            "Sentence before tokenization: Comparing with visiting , taking care of a patient is totally different in stress .\n",
            "Sentence before tokenization: I practiced TOELIC is test last night , and it let me down .\n",
            "Sentence before tokenization: I like music .\n",
            "Sentence before tokenization: So may I ask you a favor ? p\n",
            "Sentence before tokenization: I did not keep writting here is not because i am lazy or what but because i do not really have time .\n",
            "Sentence before tokenization: But I still happy .\n",
            "Sentence before tokenization: Because It is hard to find an empty seat at the library .\n",
            "Sentence before tokenization: S , Douglass made up this connection and claimed it during debates with Lincoln as one of strategies in the election .\n",
            "Sentence before tokenization: In Mexico , out of died .\n",
            "Sentence before tokenization: This ? immolation\n",
            "Sentence before tokenization: I think it is quite natural that they do so .\n",
            "Sentence before tokenization: The thing is I want to make a jourey through all over the world for life .\n",
            "Sentence before tokenization: I will try again to check my post to go to the Twitter site .\n",
            "Sentence before tokenization: In a few weeks , I m sure that many stores and shops will start playing Christmas songs .\n",
            "Sentence before tokenization: Use images throughout .\n",
            "Sentence before tokenization: It is a bit sad in the end because both of them died , but at least\n",
            "Sentence before tokenization: But I do not want to absent myself from my work and I do not want to stop dancing .\n",
            "Sentence before tokenization: Today is hot , too .\n",
            "Sentence before tokenization: And these who do become famous often find they want to wake up from lives that are less than dream like .\n",
            "Sentence before tokenization: At that time , French music and Italian music were so different .\n",
            "Sentence before tokenization: Fire alarm was unexpectedly on when I was cooking dinner which is Chinese fried noodle .\n",
            "Sentence before tokenization: Tokyo becomes darker than before at night because people save electricity .\n",
            "Sentence before tokenization: I even appreciate this time .\n",
            "Sentence before tokenization: There are many speshle schools for studying English in Russia .\n",
            "Sentence before tokenization: Thirdly , If anyone would like to learn in chinese .\n",
            "Sentence before tokenization: Is there a better approach ?\n",
            "Sentence before tokenization: the show was planning in commemoration of the anniversary of this bridge .\n",
            "Sentence before tokenization: I was really enjoyed and sang a lot !\n",
            "Sentence before tokenization: Happiness day\n",
            "Sentence before tokenization: I will from time to time to review .\n",
            "Sentence before tokenization: Specifically for Hotter\n",
            "Sentence before tokenization: So I have taken care of her .\n",
            "Sentence before tokenization: Hello everyone !\n",
            "Sentence before tokenization: If you exceed it or not reach it , it is bad for your health . \n",
            "Sentence before tokenization: Growing up brings reality .\n",
            "Sentence before tokenization: Quitting bothered life\n",
            "Sentence before tokenization: So we promised that we would gather in Suwon .\n",
            "Sentence before tokenization: I can listen to her songs in the movie .\n",
            "Sentence before tokenization: I thought He will play around here and does not go far away in my dream but , suddenly my dog wasdisappeared and I tried to find him .\n",
            "Sentence before tokenization: Esteemed jury , take a look at this man standing in the accused dock .\n",
            "Sentence before tokenization: This article observed that although there are several similar ways to manage sustainable fishery in Taiwan , it is scanty of an effective governing process to maintain and enhance outcome of conservation .\n",
            "Sentence before tokenization: But , me !\n",
            "Sentence before tokenization: Mumbling , bumbling .\n",
            "Sentence before tokenization: They seemed soooooo happy .\n",
            "Sentence before tokenization: I need to know about nuclear power plants and global warming .\n",
            "Sentence before tokenization: I like NBA .\n",
            "Sentence before tokenization: Why the students ' who come to Japan really likes science or math ?\n",
            "Sentence before tokenization: Hello everyone .\n",
            "Sentence before tokenization: a baseball cap which is allowed .\n",
            "Sentence before tokenization: While seeing trains , I remembered Amtrak , night bus in Thailand , busy train in India , on top of the bus on the way to Nepal and so on .\n",
            "Sentence before tokenization: In a living room , well - air - conditioned , we are very relaxed doing each one is own job .\n",
            "Sentence before tokenization: So it likes corruption and Eros .\n",
            "Sentence before tokenization: There were not any debate or speech classes when I was a student .\n",
            "Sentence before tokenization: The ending must fit such freshness .\n",
            "Sentence before tokenization: I think that I took courage .\n",
            "Sentence before tokenization: People in the Tohoku area think having parties and drinking sake will contribute to the profit of sake for them .\n",
            "Sentence before tokenization: it is high time to pick it .\n",
            "Sentence before tokenization: After reading the article , we are going to discuss this topic , so I am writing what I thought .\n",
            "Sentence before tokenization: I was very\n",
            "Sentence before tokenization: I feel mournful and desperate .\n",
            "Sentence before tokenization: One of the reasons is that I can not read Arabic at all .\n",
            "Sentence before tokenization: I will try , because it is very interesting .\n",
            "Sentence before tokenization: I hope my sprain will recover and I ll walk without the crutch .\n",
            "Sentence before tokenization: I am already years old .\n",
            "Sentence before tokenization: It is the first program in this festival .\n",
            "Sentence before tokenization: But Q II was not my only love at that time .\n",
            "Sentence before tokenization: There might be two categories in accounting , accounting for finance and accounting for management .\n",
            "Sentence before tokenization: They have fun with board games , \n",
            "Sentence before tokenization: English lesson\n",
            "Sentence before tokenization: But i feel that my writen English is still bad .\n",
            "Sentence before tokenization: English teachers teach how to use and express English for communication in themselves class .\n",
            "Sentence before tokenization: I must be more careful from now and then .\n",
            "Sentence before tokenization: That is why someone like me in our office has to come to the office on holidays .\n",
            "Sentence before tokenization: This information was not true at all .\n",
            "Sentence before tokenization: I also challenged several courses , some were easy and others made me say ' No way ! ' .\n",
            "Sentence before tokenization: She has a lot of wrinkles before her summer vacation .\n",
            "Sentence before tokenization: Today , I went to do a part - time job .\n",
            "Sentence before tokenization: I think we should eat healthy food . It is like Japanese food .\n",
            "Sentence before tokenization: To be frank , I have not been here for a long time as sorts of reasons .\n",
            "Sentence before tokenization: A friend of mine who is a coach of alpine skiing was in New Zealand a week ago with his racers to participate in a race .\n",
            "Sentence before tokenization: Because he is gentle for me , he tell me not have to change .\n",
            "Sentence before tokenization: The thing is I want to make a journey all over the world for life .\n",
            "Sentence before tokenization: The quality is really bad and if you make the little keyhole TV window full - screen , you will just get blocks of moving color .\n",
            "Sentence before tokenization: Thursday is the day I have to ask something to my teacher .\n",
            "Sentence before tokenization: David put his hurt into piano .\n",
            "Sentence before tokenization: The bigger problem is that I have to do other things too much !\n",
            "Sentence before tokenization: My family did not stay at home .\n",
            "Sentence before tokenization: What do you think what there is beyond the door ?\n",
            "Sentence before tokenization: If you visit Korea , we can provide , W for you .\n",
            "Sentence before tokenization: The Sorcerers Apprentice\n",
            "Sentence before tokenization: I do not know why NHK did not use the English abbreviated name .\n",
            "Sentence before tokenization: I did not know the reason , because he can speak just Turkish .\n",
            "Sentence before tokenization: This time their recruitment for election has over in May .\n",
            "Sentence before tokenization: No matter whether you are the one who sends a hidden message or the one who gives an earful , you are not practically doing anything good for you and your friend .\n",
            "Sentence before tokenization: Today is my first time to chat with a foreigner in MSN .\n",
            "Sentence before tokenization: Now , I compare between typoon and hurricane .\n",
            "Sentence before tokenization: It is a merit in the environment .\n",
            "Sentence before tokenization: For the next stage , we will see how LDR works as a line sensor and colour sensor .\n",
            "Sentence before tokenization: How do you say that phrase in English .\n",
            "Sentence before tokenization: after all ! !\n",
            "Sentence before tokenization: Hello ! and please\n",
            "Sentence before tokenization: even though she has year and half left to study Japanese in uni .\n",
            "Sentence before tokenization: Kneel down to the object is level\n",
            "Sentence before tokenization: I can speak Chinese and a little English .\n",
            "Sentence before tokenization: It seems that the English teacher is not aware that the strike is over .\n",
            "Sentence before tokenization: My name is mikitty .\n",
            "Sentence before tokenization: What is your hobby ?\n",
            "Sentence before tokenization: Though it was not good weather , we made a preliminary visit for our next one .\n",
            "Sentence before tokenization: but i even do not know the reason\n",
            "Sentence before tokenization: But I think this book is supposed to be dedicated to grown - ups .\n",
            "Sentence before tokenization: Moreover , in the Harry Potter novels , pumpkin juice is a favorite drink of the students of Hogwart is School of Witchcraft and Wizardry . \n",
            "Sentence before tokenization: I thought how foolish I was .\n",
            "Sentence before tokenization: Nowadays there are a lot of sudden evening showers and thunder .\n",
            "Sentence before tokenization: From next year , my workmate and one of my colleagues who is my best friend in this school will transfer to other school .\n",
            "Sentence before tokenization: I had work hours at japanese sushi restaurants as trial staff yesterday\n",
            "Sentence before tokenization: I have never heard it in English before .\n",
            "Sentence before tokenization: We went to there because the restaurant was close from there .\n",
            "Sentence before tokenization: Taiwan trip diary\n",
            "Sentence before tokenization: This program was broadcast again in the evening .\n",
            "Sentence before tokenization: My father wounded .\n",
            "Sentence before tokenization: My belief is Chirst who loves everybody all over the world and is willing to die on the cross for saving persons from the evil .\n",
            "Sentence before tokenization: People who have various backgrounds , such as residents , tourists and business people , can easily use the public transportation system .\n",
            "Sentence before tokenization: A letter to ask to see us\n",
            "Sentence before tokenization: Can I say in a business situation , like I am going to do something ?\n",
            "Sentence before tokenization: I live honestly with my feeling .\n",
            "Sentence before tokenization: change my value or change my values ? ? ? ?\n",
            "Sentence before tokenization: So , I ordered double of regular size .\n",
            "Sentence before tokenization: She is skillful with her fingers so I asked her to cut my hair .\n",
            "Sentence before tokenization: We will talk about such stuff at our dinner time today .\n",
            "Sentence before tokenization: I think that he had to do whatever he could do .\n",
            "Sentence before tokenization: come back to the most simple love\n",
            "Sentence before tokenization: Our risk management team reports to the meeting quarterly and for this meeting , we have to make conference materials in English .\n",
            "Sentence before tokenization: He is going to check the status this morning .\n",
            "Sentence before tokenization: It was realy admirable .\n",
            "Sentence before tokenization: There will be many mistake , for instance , grammatical or spelling problems , if you notice these mistakes , please tell me .\n",
            "Sentence before tokenization: I am lucky that I did not have to get back home during the worst condition .\n",
            "Sentence before tokenization: The year in which Japan was the rd seems like a different age .\n",
            "Sentence before tokenization: about my life , jobs , and also about love !\n",
            "Sentence before tokenization: Yesterday was an election day in Manorhaven .\n",
            "Sentence before tokenization: Hi , I order you to correct my diary right now ! ! !\n",
            "Sentence before tokenization: The gay marriage\n",
            "Sentence before tokenization: That is really like a addiction .\n",
            "Sentence before tokenization: Have other countries got same anecdotes ?\n",
            "Sentence before tokenization: My friend Dew had never seen anything like that .\n",
            "Sentence before tokenization: The picture\n",
            "Sentence before tokenization: I am a flower designer living in Tokyo , Japan .\n",
            "Sentence before tokenization: The only things he told us was that this was a bridge to either restructuring or bankruptcy , \n",
            "Sentence before tokenization: Good night .\n",
            "Sentence before tokenization: I gave up watching Avatar D .\n",
            "Sentence before tokenization: I am currently learning Latin for school this is my second year learning ! , and I am also learning Japanese recreationally \n",
            "Sentence before tokenization: Katy Perry Firework\n",
            "Sentence before tokenization: public transportation .\n",
            "Sentence before tokenization: I am hungry .\n",
            "Sentence before tokenization: The founder told me You do not need to find a room in harry , otherwise possibly you will find strange house or room .\n",
            "Sentence before tokenization: Me It is difficult to use up all of the food I got .\n",
            "Sentence before tokenization: I know .\n",
            "Sentence before tokenization: The message I wrote to my friend is blog .\n",
            "Sentence before tokenization: When I go out a lot of people are very strange to look at me .\n",
            "Sentence before tokenization: I was so tired , but I got the good practice .\n",
            "Sentence before tokenization: Some think it is beneficial , but other people disagree .\n",
            "Sentence before tokenization: However , I rarely go sightseeing .\n",
            "Sentence before tokenization: I am years old .\n",
            "Sentence before tokenization: This song made famous in the France is FIFA World Cup national team that liked to sing in chorus .\n",
            "Sentence before tokenization: Looking through some major textbooks enabled me to grab it .\n",
            "Sentence before tokenization: The author says when speaking you should know some rules which are comon among English speakers .\n",
            "Sentence before tokenization: However , what is the point of Descartes view ?\n",
            "Sentence before tokenization: I took part in trips as an exchange student of my town .\n",
            "Sentence before tokenization: I had been making homegrown tomatoes and basil this summer .\n",
            "Sentence before tokenization: The entrance test !\n",
            "Sentence before tokenization: Today I went to participate in an interview at the World Economic Forum , and it is also called Davos .\n",
            "Sentence before tokenization: I do not want to imagine that my teacher is going to blame me for the reason for missing class\n",
            "Sentence before tokenization: I just registered right after I got to know about this site .\n",
            "Sentence before tokenization: Which season do you like ?\n",
            "Sentence before tokenization: I want to live in my hometown after retirement .\n",
            "Sentence before tokenization: And let me begun to write something about my yesterday .\n",
            "Sentence before tokenization: These days , North Korea is infant mortality rate is worse than African refugees condition .\n",
            "Sentence before tokenization: The second reason is that I want to learn professional knowledge about the economy .\n",
            "Sentence before tokenization: Be careful , it is not brand name .\n",
            "Sentence before tokenization: Tomorrow is my daughters ' concert at elementary school , but I have to go to work .\n",
            "Sentence before tokenization: His major had nothing to do with cooking .\n",
            "Sentence before tokenization: The student is third grade in junior high school .\n",
            "Sentence before tokenization: What a humdrum life I do !\n",
            "Sentence before tokenization: a dry painful cough that is repeated often\n",
            "Sentence before tokenization: UW means University of Washington , which locates in a beautiful city whose name is Seattle .\n",
            "Sentence before tokenization: thank M for buying the tickets .\n",
            "Sentence before tokenization: A Hey , what do you think about doctors who fall in love with their patient ? \n",
            "Sentence before tokenization: However it is very inconvenient for shopping .\n",
            "Sentence before tokenization: The head of the sonic toothbrush can be changed , so we can share it in my family .\n",
            "Sentence before tokenization: OK , let me see .\n",
            "Sentence before tokenization: Today is a special day .\n",
            "Sentence before tokenization: When I opened the door , Ben was standing there .\n",
            "Sentence before tokenization: Or to make foreign friends ?\n",
            "Sentence before tokenization: Its color is brown and black .\n",
            "Sentence before tokenization: British Life\n",
            "Sentence before tokenization: I was embarrassed .\n",
            "Sentence before tokenization: reality of an art .\n",
            "Sentence before tokenization: He eats a lot and is lazy in our house and yet he does not get fat .\n",
            "Sentence before tokenization: The natural disasters do nt wait for poor people .\n",
            "Sentence before tokenization: It is my first the to play this game , and I really like it and enjoy it .\n",
            "Sentence before tokenization: I do not like people who try to take advantage of native English speakers as a tool for their English .\n",
            "Sentence before tokenization: My favorite actor is Johnny Depp .\n",
            "Sentence before tokenization: That is why I registered here .\n",
            "Sentence before tokenization: The Brodway show in NY is so fantastic that makes me want to see that again , again and again .\n",
            "Sentence before tokenization: My coworkers like to trick me .\n",
            "Sentence before tokenization: Some of them really make me realize how difficult it is for top athletes to do their best and win on such a big stage .\n",
            "Sentence before tokenization: This is it ?\n",
            "Sentence before tokenization: It was great !And so cheap ! !\n",
            "Sentence before tokenization: But , I try to don t pump everything .\n",
            "Sentence before tokenization: I hope that we will go to the th match ! !\n",
            "Sentence before tokenization: Add me if you want to talk together .\n",
            "Sentence before tokenization: This is a kind of dictionary .\n",
            "Sentence before tokenization:  Describe a sport , a game , or a group activity people enjoy doing in your country .\n",
            "Sentence before tokenization: It is important for us to have our goals in life , but it is more important to set effective goals according to your current situation .\n",
            "Sentence before tokenization: At the same time , I was working at a restaurant .\n",
            "Sentence before tokenization: I really love it .\n",
            "Sentence before tokenization: She tried to keep her smile but I noticed she felt uncomfortable the way I negotiated with her .\n",
            "Sentence before tokenization: No way !\n",
            "Sentence before tokenization: She lived in Town house before .\n",
            "Sentence before tokenization: I need to start back up today studying English .\n",
            "Sentence before tokenization: We kept a promise to do Karaoke on Skype tomorrow again .\n",
            "Sentence before tokenization: My weight is kg .\n",
            "Sentence before tokenization: They perform to a brave tune , really brave .\n",
            "Sentence before tokenization: Thus , it is difficult to see another game in Korea .\n",
            "Sentence before tokenization: Take a close look at this .\n",
            "Sentence before tokenization: This is bad ! !\n",
            "Sentence before tokenization: There , most citizen are going out with family to pick up something cute for kids or to get some great bargains for wife or friend .\n",
            "Sentence before tokenization: I know in Europe they do not pay so much attention to appearance and the main goal is personal comfort .\n",
            "Sentence before tokenization: But it is too early for me .\n",
            "Sentence before tokenization: The key to the classification is the amazing fact that irreducible components have the same Coxeter number .\n",
            "Sentence before tokenization: So , I tried to act all sweet to him .\n",
            "Sentence before tokenization: I would go the shopping floor , If I was a young woman .\n",
            "Sentence before tokenization: I think that the iphone is application is useful and convenient , moreover .\n",
            "Sentence before tokenization: Oh my holiday will be over but I feel this summer is too normal .\n",
            "Sentence before tokenization: accurate rules and ask her to follow and let her know why .\n",
            "Sentence before tokenization: So today I want to try to write about one of the problems .\n",
            "Sentence before tokenization: After our third year at university we my classmates and me went to SAO - Special Astronomical Observatory situated near Caucasian mountains and not far from my hometown .\n",
            "Sentence before tokenization: If I have a chance , I d like to try YOSAKOI .\n",
            "Sentence before tokenization: Suddenly I realised that the song was Michael is SMOOTH CRIMINAL\n",
            "Sentence before tokenization: If I could win him , next enemy would be waiting for me .\n",
            "Sentence before tokenization: I really like it .\n",
            "Sentence before tokenization: It was good .\n",
            "Sentence before tokenization: I know learning German is one way , but many European people are really good at English .\n",
            "Sentence before tokenization: I do love cleaning others ' ears as well , but it is more exciting .\n",
            "Sentence before tokenization: On this day people do not work and they can have a time with lovely people .\n",
            "Sentence before tokenization: I got a letter from her .\n",
            "Sentence before tokenization: How about you ?\n",
            "Sentence before tokenization: However , I think , this is a life .\n",
            "Sentence before tokenization: Also , I saw people who study hard for their goal .\n",
            "Sentence before tokenization: I was annoyed because it was at am .\n",
            "Sentence before tokenization: He could not tell her the truth because he did not want to lose their friendship .\n",
            "Sentence before tokenization: But there is no function of correcting like on a PC .\n",
            "Sentence before tokenization: because it would be very hard to learn .\n",
            "Sentence before tokenization: Japanese writer in .\n",
            "Sentence before tokenization: However , he left his bag on the chair .\n",
            "Sentence before tokenization: this journey is to work in the kindergaten .\n",
            "Sentence before tokenization: The plans in this summer\n",
            "Sentence before tokenization: My sister often sends me pictures of my dogs .\n",
            "Sentence before tokenization: Korean people do not soak in the bathtub every day .\n",
            "Sentence before tokenization: There I was looking at a drawing on a paper .\n",
            "Sentence before tokenization: Windy night\n",
            "Sentence before tokenization: I d be very surprised if anything more than a token force is leaving anytime soon .\n",
            "Sentence before tokenization: So if you have got a bit time to talk to me through skype I would be quite splendid !\n",
            "Sentence before tokenization: I wonder how the scenes were made .\n",
            "Sentence before tokenization: Because I heard the season th was the last , but I was not able to understand about this story .\n",
            "Sentence before tokenization: There really were a lot last week and there were even entries which three or more visitors had corrected .\n",
            "Sentence before tokenization: The story is not so real but that is what attracts me .\n",
            "Sentence before tokenization: For example , I did my homework in summer vacation .\n",
            "Sentence before tokenization: This is an unsubstantial solution .\n",
            "Sentence before tokenization: you to do everything .\n",
            "Sentence before tokenization: I must admit , i m not convinced that anyone would answer me , but still i want to try .\n",
            "Sentence before tokenization: I finished my breakfast at six o ' clock , then i sat on the sofa , spent some time wathing UEFA .\n",
            "Sentence before tokenization: However , I have to say that we just require them to learn about basic economics , which means they need to know this knowledge but not deep research .\n",
            "Sentence before tokenization: I went to the school with Natalia .\n",
            "Sentence before tokenization: On the way to home , Gay said me that it was good for me to meet a Japanese lady in the painting club .\n",
            "Sentence before tokenization: As I read an article that a friend of mine who is like my brother has written , says I want to end up my life , I realize what I have done by alienating him while I have been struggling only with my affairs .\n",
            "Sentence before tokenization: How can I do , just let it pass or do not read them ?\n",
            "Sentence before tokenization: The deadline is near , what can I do to prepare for my competition .\n",
            "Sentence before tokenization: Good afternoon , everybody , \n",
            "Sentence before tokenization: Thank you .\n",
            "Sentence before tokenization: But also charming .\n",
            "Sentence before tokenization: related information\n",
            "Sentence before tokenization: I wish I can be a great help !\n",
            "Sentence before tokenization: I went to the ramen restaurant , which is one of the most popular in my hometown .\n",
            "Sentence before tokenization: How did you treat your tooth after coming out in your country ?\n",
            "Sentence before tokenization: There were crabs at this time .\n",
            "Sentence before tokenization: Do you guess why ?\n",
            "Sentence before tokenization: Today I am writing about my instrument .\n",
            "Sentence before tokenization: It recovered about three month .\n",
            "Sentence before tokenization: usually and occasionally on my writings .\n",
            "Sentence before tokenization: In the past I go to sleep at , but after the child was born , I came to sleep earlier .\n",
            "Sentence before tokenization: I went out for a walk with my Jazzercise friend because our usual Jazzercise lesson was closed because of the facility .\n",
            "Sentence before tokenization: Well , My English is basic , but I think that I can be understood .\n",
            "Sentence before tokenization: I have got a long day today .\n",
            "Sentence before tokenization: If you know the information or tourist hot spot in Bangkok , \n",
            "Sentence before tokenization: That is why squid is cut thin or has a lot of slits on the surface when it is served .\n",
            "Sentence before tokenization: Initial\n",
            "Sentence before tokenization: I will enjoy this language - from today .\n",
            "Sentence before tokenization: What happens ?\n",
            "Sentence before tokenization: I really love them .\n",
            "Sentence before tokenization: On the contrary , I think we can say , very strongly totally seriously nervous . I am scary means I make others scared . \n",
            "Sentence before tokenization: who the hell is he ?\n",
            "Sentence before tokenization: In particularly , I love ' Princess Mononoke ' .\n",
            "Sentence before tokenization: It was good weather , the wind was weak southwest , the waves were abdomen to breast high and clean .\n",
            "Sentence before tokenization: The difference between will and be going to\n",
            "Sentence before tokenization: He compared Albert Einstein with Thomas Edison .\n",
            "Sentence before tokenization: But I changed the answer to one question seconds before the end of the test , but it was wrong , U U\n",
            "Sentence before tokenization: Now , you can see blue sky among many clouds .\n",
            "Sentence before tokenization: So I somehow thought it was Chinese and wondered how to pronounce it .\n",
            "Sentence before tokenization: I want to go there next summer !\n",
            "Sentence before tokenization: It was an alarm .\n",
            "Sentence before tokenization: The film show that the beauty of the soul is greater than the man s strength .\n",
            "Sentence before tokenization: I am remebering her shining eyes .\n",
            "Sentence before tokenization: Next time I will write a diary in russian .\n",
            "Sentence before tokenization: Japanese people can see the blue moon anywhere at night .\n",
            "Sentence before tokenization: But my parents ca not understand me .\n",
            "Sentence before tokenization: Could you tell me any specific example ?\n",
            "Sentence before tokenization: so I do not have to study hard ! !\n",
            "Sentence before tokenization: but the inside of the sea was amazing . I could not imagine it before .\n",
            "Sentence before tokenization: One of them is this is nuts ! ! .\n",
            "Sentence before tokenization: at the nearby beach station at last , which was a relief .\n",
            "Sentence before tokenization: I went there with my friend , because tomorrow is her birthday .\n",
            "Sentence before tokenization: My study tour is second day .\n",
            "Sentence before tokenization: I find out that I know nothing about English punctuation .\n",
            "Sentence before tokenization: I will do my best to teach anyone who wants to learn Chinese .\n",
            "Sentence before tokenization: B The local tournament .\n",
            "Sentence before tokenization: no free wifi hotspots in japan\n",
            "Sentence before tokenization: Please check this out first .\n",
            "Sentence before tokenization: Reporter Good morning , Linda ! First of all , thank you for accepting our invitation !\n",
            "Sentence before tokenization: Do not hesitate to contact me\n",
            "Sentence before tokenization: I ate dinner at a beautiful restaurant .\n",
            "Sentence before tokenization: And we are respecting Obama now .\n",
            "Sentence before tokenization: I have a good time in the bus because I talk with a lot of people that I never talk with them , so I can know things about them .\n",
            "Sentence before tokenization: The last time I took the TOEFL test was in July , about two years ago .\n",
            "Sentence before tokenization: That is why someone like me in our office has to come to the office in holidays .\n",
            "Sentence before tokenization: I wandered around Shibuya in a short while .\n",
            "Sentence before tokenization: then she look at me like saying this is the number one rule when you get there and said - .\n",
            "Sentence before tokenization: But unless I moved here last year .\n",
            "Sentence before tokenization: Joy derived from winning can not be gained by any other methods .\n",
            "Sentence before tokenization: No matter how small our dreams are , \n",
            "Sentence before tokenization: That is why this kind of ceremony has not become popular .\n",
            "Sentence before tokenization: But it is often said that the fee for university is the problem .\n",
            "Sentence before tokenization: In the South Pacific Ocean near New Zealand , three boys were missing in the sea .\n",
            "Sentence before tokenization: Thanks for the pressure cooker !\n",
            "Sentence before tokenization: I will finish a textbook in Swedish by summer .\n",
            "Sentence before tokenization: instead of buying it with credit card immediately .\n",
            "Sentence before tokenization: We are not unlike a particularly hardy crustacean .\n",
            "Sentence before tokenization: The picture of your family is very nice .\n",
            "Sentence before tokenization: Do you have any ideas ?\n",
            "Sentence before tokenization: I would be happy to see your version of translation !\n",
            "Sentence before tokenization: Of course , I think to have my daily corrected by everyone also get better English skill .\n",
            "Sentence before tokenization: People often say that the duty of your room means the confusion of your mind .\n",
            "Sentence before tokenization: Today there was a lot of snow on the ground , about cm .\n",
            "Sentence before tokenization: I was thinking that I ca not make it then .\n",
            "Sentence before tokenization: The students at Tokyo University tried dancing to Dangerous by Michael Jackson .\n",
            "Sentence before tokenization: I am back !\n",
            "Sentence before tokenization: and have too much worng grammer .\n",
            "Sentence before tokenization: But I could nt wash by cold water , it will let me feel uncomfortable , even it is a hot day .\n",
            "Sentence before tokenization: Good night .\n",
            "Sentence before tokenization: Recently a general store in the neighborhood was robbed in the night , and the father shot two robbers .\n",
            "Sentence before tokenization: I did nt say that I seem to love you although I love you .\n",
            "Sentence before tokenization: WE - Third photo\n",
            "Sentence before tokenization: Then I heard a lot of noise of a helicopter .\n",
            "Sentence before tokenization: We are probably going to be good friends !\n",
            "Sentence before tokenization: I think spring is coming slowly .\n",
            "Sentence before tokenization: candidates to teach undergraduate students and this is the best popular policy of our institution according to student opinion survey .\n",
            "Sentence before tokenization: It sounds natural and does not need to be said at first , but when you have some trouble in mind , it is not the case .\n",
            "Sentence before tokenization: But we once had a chance to find out .\n",
            "Sentence before tokenization:  , many male manatees made a magical map of Malaysia .\n",
            "Sentence before tokenization: The cleaner is designed to be a premium product .\n",
            "Sentence before tokenization: So today is diary is very short .\n",
            "Sentence before tokenization: Therefore , I can easily calculate the age of mother and the age of father .\n",
            "Sentence before tokenization: When you are sitting down on a chair , put up your right leg and make your foot move clockwise .\n",
            "Sentence before tokenization: However , almost one week has gone without receiving any replacement .\n",
            "Sentence before tokenization: I want to try using this website .\n",
            "Sentence before tokenization: I read it is the coldest winter in many countries in the north .\n",
            "Sentence before tokenization: I really hate he fix car at am to pm on Saturday and Sunday , he make a lot of noise that make me ca nt sleep well .\n",
            "Sentence before tokenization: Please correct my mistakes strictly !\n",
            "Sentence before tokenization: I know I have to write a diary in English steadily in order that my English improves .\n",
            "Sentence before tokenization: She got the result from the private university She did it !\n",
            "Sentence before tokenization: Did you try out this new computer ?\n",
            "Sentence before tokenization: I would like to go to the beach , but I have to work .\n",
            "Sentence before tokenization: Do not let you down .\n",
            "Sentence before tokenization: She is really nice I woul like to try to speak a bit japense with her .\n",
            "Sentence before tokenization: So tired .\n",
            "Sentence before tokenization: I have only few kind of parttern .\n",
            "Sentence before tokenization: Japan faces the rapid aging of the population with an extremely low birthrate .\n",
            "Sentence before tokenization: education course in University and I want to be a teacher .\n",
            "Sentence before tokenization: ?\n",
            "Sentence before tokenization: Is there anyone who knows the effective way to overcome anthrophobia ?\n",
            "Sentence before tokenization: I finished my graduation test on th .\n",
            "Sentence before tokenization: By breaking down conventions , we learned to enjoy independence and responsibility .\n",
            "Sentence before tokenization: I study English idioms in class .\n",
            "Sentence before tokenization: Love Yoga\n",
            "Sentence before tokenization: some required qualities\n",
            "Sentence before tokenization: You ask ?\n",
            "Sentence before tokenization: She is funny ! o We are so into musicals and Zac Efron !\n",
            "Sentence before tokenization: Dear all , \n",
            "Sentence before tokenization: My second son said Maybe I lost it .\n",
            "Sentence before tokenization: I have used it for aproximately a week , I feel it suit for checking feeds , watching iTunesU courses , reading some comics in my bed before going to sleep .\n",
            "Sentence before tokenization: Oh , I should be going now if I do not want to be late for the listening class .\n",
            "Sentence before tokenization: Chinese food has so many cooking techniques , and it is really hard to master them . I can cook too , but only normal dishes , and dumplings . I can not make noodles now , though I love the hand - made noodles so much , but I always make them in bad shape , so I have to practice more \n",
            "Sentence before tokenization: Some people insist that it is a huge waste of educational resources .\n",
            "Sentence before tokenization: Japanese is not a extensively - used language in the world .\n",
            "Sentence before tokenization: Of course I am writing this diary with this keboard .\n",
            "Sentence before tokenization: Actually , I have a friend who mastered it in a few hours , too .\n",
            "Sentence before tokenization: Some native speakers said to me that I did not need to learn slang words . However , I could not agree with that idea completely , because I have come across some occasions when I needed to know slang , just like in the case above .\n",
            "Sentence before tokenization: I have a plan to educate my son .\n",
            "Sentence before tokenization: I came to London and about two and half months have passed in no time .\n",
            "Sentence before tokenization: It is even hard to open my eyes widely .\n",
            "Sentence before tokenization: Pollen allergy\n",
            "Sentence before tokenization: Could you look it on YouTube ?\n",
            "Sentence before tokenization: might apply the custom of transmitting mail after you confirm it again .\n",
            "Sentence before tokenization: I like to translate Finnish song lyrics into English .\n",
            "Sentence before tokenization: Am I OK if only I have my passport and available train tickets ?\n",
            "Sentence before tokenization: It is practically a sampling .\n",
            "Sentence before tokenization: As for Japanese comics , called manga , One peace is the most famous of them all in Japan .\n",
            "Sentence before tokenization: I was interested in the town because I heard the scene of the movie , Ponyo on the Cliff by the Sea is there .\n",
            "Sentence before tokenization: What is your opinion ?\n",
            "Sentence before tokenization: to improve my English\n",
            "Sentence before tokenization: raise feeling\n",
            "Sentence before tokenization: I am majoring in an electronic device , and I want to take the qualification in the field .\n",
            "Sentence before tokenization: My account with points and monthly subscription .\n",
            "Sentence before tokenization: - The show is hour and it includes big quizzes .\n",
            "Sentence before tokenization: By becoming successful and powerful they finally realized that they were good enough and that they could succeed in giving .\n",
            "Sentence before tokenization: We arrived at Malaysia safety .\n",
            "Sentence before tokenization: That is the way it goes .\n",
            "Sentence before tokenization: But I ca nt upload them to the lang - site now and will upload them all together when connected or in the office tomorrow .\n",
            "Sentence before tokenization: And at , the work will start .\n",
            "Sentence before tokenization: I will make a lot of friends if I can speak English .\n",
            "Sentence before tokenization: Nostalgia - I want to know please if this essay can express the feeling of home sickness and the obstacles that person can face in the forgeon countries ?\n",
            "Sentence before tokenization: It seems to sleep\n",
            "Sentence before tokenization: My study\n",
            "Sentence before tokenization: I do not think I will ever really master English .\n",
            "Sentence before tokenization: I like different coffee .\n",
            "Sentence before tokenization: Early morning\n",
            "Sentence before tokenization: In this morning , I get up at seven .\n",
            "Sentence before tokenization: I am always with Nothing can let me down in my heart and never wear a frown even when I am talking to someone upsetting me .\n",
            "Sentence before tokenization: nice foods and drinks at reasonable prices .\n",
            "Sentence before tokenization:  You might say , what is happening ?\n",
            "Sentence before tokenization: I study Japanese language at college .\n",
            "Sentence before tokenization: Although she has most mothersshortcomings which they always nag at , she is still my mother .\n",
            "Sentence before tokenization: He was disappointed with me .\n",
            "Sentence before tokenization: These symptoms are for the first time in my life .\n",
            "Sentence before tokenization: Good night .\n",
            "Sentence before tokenization: This TV program is aired from o ' clock on Saturdays , so my family always watches it together .\n",
            "Sentence before tokenization: Is it delicious ?\n",
            "Sentence before tokenization: She was ten years old and loved singing .\n",
            "Sentence before tokenization: He said we should cancel and go to the seaside .\n",
            "Sentence before tokenization: Today I saw an article saying that if express tolls become free , many people will use cars , and as a result of that greenhouse gas emissions will increase .\n",
            "Sentence before tokenization: Haha Personally I still remember what happens when so - called adults behave that way .\n",
            "Sentence before tokenization: So we choose ' fashion ' as our conversation is subject .\n",
            "Sentence before tokenization: My hobby is table tennis playing every satuday .\n",
            "Sentence before tokenization: We ate so much that we became full .\n",
            "Sentence before tokenization: But he gose to drink to her restaurant .\n",
            "Sentence before tokenization: His English is so fast , so I sometimes make out what he said .\n",
            "Sentence before tokenization: but I am no friend .\n",
            "Sentence before tokenization: . Why ?\n",
            "Sentence before tokenization: We have not played playground equipmet for a long time .\n",
            "Sentence before tokenization: Very hot and humid today .\n",
            "Sentence before tokenization: But anyway , winter vacation is coming , so I better move on and forget that . \n",
            "Sentence before tokenization: Despite of this resistence , I wasted days and about yen .\n",
            "Sentence before tokenization: I like Tennessee Williams ' works and I would like to fully appreciate his works .\n",
            "Sentence before tokenization: I want to study English more .\n",
            "Sentence before tokenization: I have to search for their information this vacation .\n",
            "Sentence before tokenization: I am in the library of my university now .\n",
            "Sentence before tokenization: S since .\n",
            "Sentence before tokenization: After I listened to her questions , I answered her in Japanese while I was keeping painting .\n",
            "Sentence before tokenization: I really thanked him for sparing his valuable time .\n",
            "Sentence before tokenization: Over dinner , he talked about his relatives .\n",
            "Sentence before tokenization: Because the condition of my belly was not good today .\n",
            "Sentence before tokenization: My life is one big rhyme , I try to scheme through it\n",
            "Sentence before tokenization: I do not want to imagine that my teacher is going to blame me about the reason for missing class\n",
            "Sentence before tokenization: It was one of the famous TV show in Taiwan two years ago , especially in session I and II .\n",
            "Sentence before tokenization: He resisted to an brutal regime of North Korea .\n",
            "Sentence before tokenization: With these unique buildings , the village always emit an air of tranquility and peacefulness .\n",
            "Sentence before tokenization: When they are consumed under the same condition , \n",
            "Sentence before tokenization: Hi !\n",
            "Sentence before tokenization: I hope I will be able to master English as quickly as possible with this state - of - the - art technology .\n",
            "Sentence before tokenization: One difficult has gone .\n",
            "Sentence before tokenization: So far , we placed furniture so we could see our daughter easily , but this time we separated the play zone for our daughter and the living zone clearly .\n",
            "Sentence before tokenization: I hope my second language can get better and better .\n",
            "Sentence before tokenization: When it comes to graduation season , please cherish\n",
            "Sentence before tokenization: One of the professors replied to an email , which is very important to the process of GIS .\n",
            "Sentence before tokenization: A lot of Japanese do not like it , either .\n",
            "Sentence before tokenization: I gave up watching avater D .\n",
            "Sentence before tokenization: The most obvious one is that because of advances in technology our standard of living is much improved .\n",
            "Sentence before tokenization: At that time he was particularly vulnerable and needed some extra love .\n",
            "Sentence before tokenization: I had Coming of Age Ceremony last week .\n",
            "Sentence before tokenization: The English pronunciation is difficult .\n",
            "Sentence before tokenization: I have taught him since May , from the beginning .\n",
            "Sentence before tokenization: Many players were practising there .\n",
            "Sentence before tokenization: You ca not .\n",
            "Sentence before tokenization: I chose the former , because I am not a Buddhist .\n",
            "Sentence before tokenization: If you have more ideas about the way to get more correction on Lang - .\n",
            "Sentence before tokenization: I will pass over easily .\n",
            "Sentence before tokenization: I have no thick accent , according to her , but lack language complexity .\n",
            "Sentence before tokenization: The Toeic Score\n",
            "Sentence before tokenization: It was really good .\n",
            "Sentence before tokenization: I do not know how to use do\n",
            "Sentence before tokenization: I have a question regarding the usage of urgent flag in email .\n",
            "Sentence before tokenization: The weather is very strange .\n",
            "Sentence before tokenization: Ofcause I ca not live without rain !But I do not like rain .\n",
            "Sentence before tokenization: Then , he said that is familiar with the fact that Japanese people work overtime , and it is incorrect to describe it as hard work .\n",
            "Sentence before tokenization: My Michigan friends have been making some exciting plans for me .\n",
            "Sentence before tokenization: However , too many people were there and there was less cooling , which causes an electric situation .\n",
            "Sentence before tokenization: And I have three more questions .\n",
            "Sentence before tokenization: Because if I talk with someone , for sure , I ca not have no time to look words in the dictionary .\n",
            "Sentence before tokenization: Instead , we asked a chinese cabinet - maker to make table sets which look like we found in Japan .\n",
            "Sentence before tokenization: Young people in Japan often read them .\n",
            "Sentence before tokenization: These days , I wake up around p .\n",
            "Sentence before tokenization: USC music students listen to musical notes .\n",
            "Sentence before tokenization: When I reached the shop at minutes to , several people were already waiting in a line in front of the shop .\n",
            "Sentence before tokenization: I was very glad and really impressed with his improvement and efforts .\n",
            "Sentence before tokenization: One day , a student climbed a mountain .\n",
            "Sentence before tokenization: I want to acquire English very well and more languages ! !\n",
            "Sentence before tokenization: At that time , I was negative , hopeless , and very weak .\n",
            "Sentence before tokenization: However , while smelling of my dear hometown , I usually feel that this place has passed by without notice during my absence from this place , and that the precious days never come back .\n",
            "Sentence before tokenization: Safe driving does not mean slow driving .\n",
            "Sentence before tokenization: I have been interested in debating .\n",
            "Sentence before tokenization: So her extreme expressions make me nervous , and I really do not like them .\n",
            "Sentence before tokenization: She was always complaining about everything such as drink , food , room , and people .\n",
            "Sentence before tokenization: because of their kindness and patience , I got a lot whether I succeeded or not .\n",
            "Sentence before tokenization: I can not decide whether the video should have been revealed the nation or not .\n",
            "Sentence before tokenization: fun and very reasonable !\n",
            "Sentence before tokenization: So I think I have quite a lot of confidence at that area .\n",
            "Sentence before tokenization: Today , I went there the first time in my life .\n",
            "Sentence before tokenization: our internal communication language from Japanese to English .\n",
            "Sentence before tokenization: it is not thing what I want to do .\n",
            "Sentence before tokenization: At first , I was nervous a little bit .\n",
            "Sentence before tokenization: I can study idiom a lots\n",
            "Sentence before tokenization: so I would fail .\n",
            "Sentence before tokenization: So , I did not expect much from my mom .\n",
            "Sentence before tokenization: Do you know this Japanese anime ?\n",
            "Sentence before tokenization: It sounds good !\n",
            "Sentence before tokenization: the last weekend\n",
            "Sentence before tokenization: After we finished playing , I realized that I had lost the key to the locker where we had stored our things .\n",
            "Sentence before tokenization: Did you know ?\n",
            "Sentence before tokenization: Take this to heart .\n",
            "Sentence before tokenization: Last Thursday\n",
            "Sentence before tokenization: Unsolicited Bulk Email\n",
            "Sentence before tokenization: Long Beach , California , was a really good city .\n",
            "Sentence before tokenization: skillful at Structural Calculation and to the engineer who has broad\n",
            "Sentence before tokenization: That is very violent and gore !\n",
            "Sentence before tokenization: I burst my anger and said , I never say you ca not drink and do not intend to do so , but you should consider a moderate amount of drink ! ! ! , What are you driving at ?\n",
            "Sentence before tokenization: After the age of , they start to speak very well .\n",
            "Sentence before tokenization: Would someone please check my diary entry ?\n",
            "Sentence before tokenization: It is been a while since I accessed the Lang - .\n",
            "Sentence before tokenization: German is very difficult , but I enjoy studying German !\n",
            "Sentence before tokenization: After all , European people thought Japanese football players were second class .\n",
            "Sentence before tokenization: When I was child , I went to pick up some Japanese pampas grasses near my house with my friends and offered them to the full moon .\n",
            "Sentence before tokenization: I look back the day when I was a small child .\n",
            "Sentence before tokenization: Or to make foreign friends ?\n",
            "Sentence before tokenization: I have years ' experience .\n",
            "Sentence before tokenization: Even so , I was ashamed to cry bitterly in front of people in attendance .\n",
            "Sentence before tokenization: After lunch , we took a walk around the park .\n",
            "Sentence before tokenization: I leaned Chinese and English for three years but I almost forgot it , so I want to lean them again .\n",
            "Sentence before tokenization: Some likes Naruto and asked me Naruto is world .\n",
            "Sentence before tokenization: He is wife is a intelligent girl , and he too .\n",
            "Sentence before tokenization: Please accept my best regards .\n",
            "Sentence before tokenization: TONS OF JAPANESE NOSTALGIA CARS FROM THE ' S TO NOW WILL BE GATHERED .\n",
            "Sentence before tokenization: Never , never , never , never give up !\n",
            "Sentence before tokenization: Hi , I order you to correct my diary right now ! ! !\n",
            "Sentence before tokenization: Writes down a castle with my time and piano\n",
            "Sentence before tokenization: If children could not stand up by their own legs , how do they live by themselves after their parents left them alone on this planet ?\n",
            "Sentence before tokenization: It took three hours , but it was necessary for her to spend time at ease .\n",
            "Sentence before tokenization: Used to\n",
            "Sentence before tokenization: So bored life .\n",
            "Sentence before tokenization: There are six in a pack .\n",
            "Sentence before tokenization: And I want to lend my hand to others learning Korean .\n",
            "Sentence before tokenization: And what is more , I see how life should be .\n",
            "Sentence before tokenization: I want to talk about my hobbies .\n",
            "Sentence before tokenization: It says that I am a practical like to build on ideas rather than generate them .\n",
            "Sentence before tokenization: Wecome to cone here .\n",
            "Sentence before tokenization: TEACHER ok , great !\n",
            "Sentence before tokenization: today is my condition is very good !\n",
            "Sentence before tokenization: I will try to write a diary every day to record things happening in my daily life and share it with my net friends here .\n",
            "Sentence before tokenization: I will start studying there from , so there are still years to prepare for it .\n",
            "Sentence before tokenization: Can we just allege that all the students show great interest in such subjects ?\n",
            "Sentence before tokenization: Most of Korean might hate TOEIC .\n",
            "Sentence before tokenization: I heard that the final examination will be conducted by the Ministry of Education starting this term .\n",
            "Sentence before tokenization: Goodbye my lovely winter vacations ! lol\n",
            "Sentence before tokenization: I hit that goggles and my right eye started bleeding .\n",
            "Sentence before tokenization: I think i enter this school a day or two days ago .\n",
            "Sentence before tokenization: However , more I had hard time the more I got satisfaction .\n",
            "Sentence before tokenization: My kids love corns .\n",
            "Sentence before tokenization: But I felt a little hungry now .\n",
            "Sentence before tokenization: Men always want to be a woman is first love - women like to be a man is last romance .\n",
            "Sentence before tokenization: About me\n",
            "Sentence before tokenization: I found something interested\n",
            "Sentence before tokenization: At the beginning of February , she visited ABC organisation where I worked to ask for a place for her vocational placement .\n",
            "Sentence before tokenization: I ca not make out at all .\n",
            "Sentence before tokenization: when i was in colllege , my psychology teacher told me everyone would be prone to got mild depression under loneless and pressure , which is a psychology sickness that is alway ignored due to its mind level .\n",
            "Sentence before tokenization: My father s name is My .\n",
            "Sentence before tokenization: In the wake of the rd day you have left , I look up the dictionary to savvy the heartbreak .\n",
            "Sentence before tokenization: I do not have a lot of money , but I have freetime so much .\n",
            "Sentence before tokenization: So , It is holiday to me .\n",
            "Sentence before tokenization: The verb to book means something like register in this case , right ?\n",
            "Sentence before tokenization: I really like Australia .\n",
            "Sentence before tokenization: Because it has a different rendering engine for each version , it makes different displays with each different version .\n",
            "Sentence before tokenization: This movie is very fun and sometimes feels humanistic .\n",
            "Sentence before tokenization: And we talked to each other so much .\n",
            "Sentence before tokenization: In the country , if someone had a funeral , everyone - without exception - go to the family of the one who died and stay with them , try to help them to get through this , and cook for them , because they would be mourning so they ca not cook for themselves .\n",
            "Sentence before tokenization: I have to buy their performance tickets somehow .\n",
            "Sentence before tokenization: I was born in Japan and I live in Japan now .\n",
            "Sentence before tokenization: So , now I sitting and eating my favorite cerealy , I am like child .\n",
            "Sentence before tokenization: I am , of course , speaking as an amateur .\n",
            "Sentence before tokenization: Please give me some advice .\n",
            "Sentence before tokenization: Make the material to talk with them .\n",
            "Sentence before tokenization: I bought low heel shoes and clothes .\n",
            "Sentence before tokenization: I went to an old friend is house with other friends yesterday .\n",
            "Sentence before tokenization: Olle is the best way to know about jeju island .\n",
            "Sentence before tokenization: I am a little nervous , because I have been at home since my childbirth .\n",
            "Sentence before tokenization: Even an adult sometimes does not understand others ' trouble .\n",
            "Sentence before tokenization: When I was working , I began to suffer , so I ungirded my belt .\n",
            "Sentence before tokenization: Now , we go to different each universities .\n",
            "Sentence before tokenization: Every time we have to do a project , she always does not do anything , just like a queen .\n",
            "Sentence before tokenization: I said my friend , What ! ?\n",
            "Sentence before tokenization: My dream in the future\n",
            "Sentence before tokenization: I was very surprised at his speed and appetite .\n",
            "Sentence before tokenization: I introduce myself .\n",
            "Sentence before tokenization: Outsiders call this place ' the Hawaii of Korea ' .\n",
            "Sentence before tokenization: Then let me know how you like it .\n",
            "Sentence before tokenization: I am sorry about renewing my diary .\n",
            "Sentence before tokenization: In Japan , there are a lot of fast food restaurants around town .\n",
            "Sentence before tokenization: I think it would be safer for you to stay here .\n",
            "Sentence before tokenization: Are there any good ways of sleeping ?\n",
            "Sentence before tokenization: We can learn their culture , thoughts , history , religions and so on that relates to languages at the same time .\n",
            "Sentence before tokenization: Actually I think it is at the beginning , but let me finish .\n",
            "Sentence before tokenization: I admit that i was lazy .\n",
            "Sentence before tokenization: I want to live in NY someday\n",
            "Sentence before tokenization: Hi everyone !\n",
            "Sentence before tokenization: Why I did those things ?\n",
            "Sentence before tokenization: It is a kind of business book , written by a man who had worked in a company , P G .\n",
            "Sentence before tokenization: It does not suffice by one millimeter .\n",
            "Sentence before tokenization: This morning\n",
            "Sentence before tokenization: I will never talk to stranger actively .\n",
            "Sentence before tokenization: People have a custom to clean their house in Japan .\n",
            "Sentence before tokenization: So , I could not have motivation to study English .\n",
            "Sentence before tokenization: Although overcoming shyness needs some time , you can do it .\n",
            "Sentence before tokenization: Do you know ?\n",
            "Sentence before tokenization: I did not understand why I did not like her then .\n",
            "Sentence before tokenization: Her message was very impressive .\n",
            "Sentence before tokenization: Maybe it is already late to learn cooking after married .\n",
            "Sentence before tokenization: I will try .\n",
            "Sentence before tokenization: We ca not purchase the movies and TV programs at present in Japan .\n",
            "Sentence before tokenization: Today I had a meeting with my group leader .\n",
            "Sentence before tokenization: So I want to that the star give me courage .\n",
            "Sentence before tokenization: I hope this situation will never happen again .\n",
            "Sentence before tokenization: Mozart was genius musicians .\n",
            "Sentence before tokenization: Oh no !\n",
            "Sentence before tokenization: However , some Japanese restaurants use lacquered bowls for rice . \n",
            "Sentence before tokenization: Although she is hot ! ! !\n",
            "Sentence before tokenization: People easily get believe the phrase which is written in it and sometimes they do nt accept the other side s opinion .\n",
            "Sentence before tokenization: a short trip\n",
            "Sentence before tokenization: I was really scared because the plug was still in the socket .\n",
            "Sentence before tokenization: But , I think it strange that the team leader is words .\n",
            "Sentence before tokenization: This is the application form for studying abroad .\n",
            "Sentence before tokenization: I am regrettable that most foreigner folk do not know Osaka though the foreigner knows Tokyo .\n",
            "Sentence before tokenization: The students concentrated on the story which is a Croatian story for minutes .\n",
            "Sentence before tokenization: I heard parents buy this small statuet , , yen .\n",
            "Sentence before tokenization: I made up with various work instead of the person .\n",
            "Sentence before tokenization: Today , I am taking the TOEIC .\n",
            "Sentence before tokenization: I am going to work hard on learning Japanese also .\n",
            "Sentence before tokenization: When I was in the seventh grade I heard the word atomic energy for the first time .\n",
            "Sentence before tokenization: I enjoyed drinking beers with my coworkers including unknown people .\n",
            "Sentence before tokenization: I have not found out about the real America yet .\n",
            "Sentence before tokenization: I am sorry to say that my diary today is so boring and miserable .\n",
            "Sentence before tokenization: No one great person experiences only bright sides .\n",
            "Sentence before tokenization: I hope one day I can go to Europe .\n",
            "Sentence before tokenization: When you have loads of unfinished things to do , when , seeing you haggard look because of impossibility to finish in time all your multiple errands , your colleagues answer you by look in which the only question can be seen through Life , is it easy for anyone in this world ? , when , throughout all day at work your free will remains oppressed and only finds its outlet in the evening in the form of some bottles of beer with people as stupid as you , when you come back home , you go and sit down in an armchair your face , your look , your mood , all that is quite known , we are all the same in these moments .\n",
            "Sentence before tokenization: By the way , recently , I lose an opptunity for exercises and I tend to gain weight .\n",
            "Sentence before tokenization: I am wondering if I have been improving my literal comprehension or not .\n",
            "Sentence before tokenization: Not too much but I ca not stand anywhere .\n",
            "Sentence before tokenization: My first broken heart is in militery , she is my first love\n",
            "Sentence before tokenization: How comfortable ! !\n",
            "Sentence before tokenization: Planning and Checking is very important .\n",
            "Sentence before tokenization: On the bus I read a newspaper .\n",
            "Sentence before tokenization: I turned and went out of the bookshop .\n",
            "Sentence before tokenization: How amazing ! !\n",
            "Sentence before tokenization: I was sick and tired of Korean food , and I complained about that to my boss .\n",
            "Sentence before tokenization: Its advantage is full impact when the camera project the field on players gaze .\n",
            "Sentence before tokenization: Am I like him just a brother , or .\n",
            "Sentence before tokenization: What a terrible story !\n",
            "Sentence before tokenization: Do you recall any female ones ?\n",
            "Sentence before tokenization: I hope we can help each other , make progress together !\n",
            "Sentence before tokenization: I met an experienced sales rep recently .\n",
            "Sentence before tokenization: And , Is the word latest used daily life conversation .\n",
            "Sentence before tokenization: A lot of Japanese people , including me , have mixi accounts .\n",
            "Sentence before tokenization: Switch it off .\n",
            "Sentence before tokenization: If it is possible , nobody think not to get a new year is offer .\n",
            "Sentence before tokenization: I am happy , because I have the good friend - \n",
            "Sentence before tokenization: Good movie always gives happy time to any age people , is not it ?\n",
            "Sentence before tokenization: It must be hard for these animals to find foods and to survive in the forests these days .\n",
            "Sentence before tokenization: So I am very tired .\n",
            "Sentence before tokenization: So you can enjoy it .\n",
            "Sentence before tokenization: Because Apple stop to relase iPad in Japan .\n",
            "Sentence before tokenization: I did shopping and others .\n",
            "Sentence before tokenization: I ca not speake English .\n",
            "Sentence before tokenization: We spend a long time to shadowbox and work combinations with a handler .\n",
            "Sentence before tokenization: Mother is Day\n",
            "Sentence before tokenization: how far from starting to study art !\n",
            "Sentence before tokenization: Earnesto !\n",
            "Sentence before tokenization: The atmosphere was fantastic .\n",
            "Sentence before tokenization: hello , I am Lim from Malaysia , I urgently need to improve my english shortly due to English is a major communication tools in my current working environment and I found my english is not good enough and could not totally understand anyone , I feel frustrated and hopeless , so please help me , thank you so much !\n",
            "Sentence before tokenization: The members are around years old , and I am almost as old as they are .\n",
            "Sentence before tokenization: For example , if you order an omelet , they write a shape of heart on it with tomato ketchup .\n",
            "Sentence before tokenization: I often think about the question of what a successful woman is .\n",
            "Sentence before tokenization: But I do not understand science .\n",
            "Sentence before tokenization: native speakers of English .\n",
            "Sentence before tokenization: I ca not understand why they ca not order to protect .\n",
            "Sentence before tokenization: thanks for being help\n",
            "Sentence before tokenization: Poor my son .\n",
            "Sentence before tokenization: Probably , Ramen originated in Japan .\n",
            "Sentence before tokenization: In a nutshell , with the above ideas , such as taking a design course , practice designing posters and other works , and reading many books , I think they would be stepping - stones to reach my goal .\n",
            "Sentence before tokenization: I was surprised that taste changed so much when rice cookers were different .\n",
            "Sentence before tokenization: I do not tend to write so seriously As the report is still not done , I will do stick it out !\n",
            "Sentence before tokenization: That is what I learned from Liz .\n",
            "Sentence before tokenization: He is soo cool ! ! ! ! !\n",
            "Sentence before tokenization: Tomorrow we will have the FIFA WORLD CUP .\n",
            "Sentence before tokenization: A new era of responsibility\n",
            "Sentence before tokenization: And now , the mountain of work is towering sky - high on my desk .\n",
            "Sentence before tokenization: I have not checked Lang - these days .\n",
            "Sentence before tokenization: However , individual - based marriage , so called the western lifestyle , requires us to define our own role in marriage .\n",
            "Sentence before tokenization: I will have a National Examination for certified Domestic travel Service Supervisor on September th .\n",
            "Sentence before tokenization: Actually it was my mother - in - law is birthday .\n",
            "Sentence before tokenization: My neighbor TOTORO\n",
            "Sentence before tokenization: It rained all through the day so I did nt go outside .\n",
            "Sentence before tokenization: It is very tiring .\n",
            "Sentence before tokenization: I think I would rather not say is more fun .\n",
            "Sentence before tokenization: Anyway I am planing to grow my hair , so I did not have my hair cut so much .\n",
            "Sentence before tokenization: Yesterday my English teacher brought a great book ! XD\n",
            "Sentence before tokenization: Originally I wanted to buy a Subaru Outback .\n",
            "Sentence before tokenization: The left one means brightness or brilliance , and the right one does the ideal .\n",
            "Sentence before tokenization: Last bath was cool water .\n",
            "Sentence before tokenization: How did I celebrate my birthday ?\n",
            "Sentence before tokenization: It is important to reconstruct information in pieces .\n",
            "Sentence before tokenization: Because I have to study for exams .\n",
            "Sentence before tokenization: I do not know which bus to take .\n",
            "Sentence before tokenization: Despite Positive Signs , Jobs Still Hard To Find\n",
            "Sentence before tokenization: I met many great friends on here and that encounter has become to support me not only skills but mental .\n",
            "Sentence before tokenization: That is one of the pictures I posted .\n",
            "Sentence before tokenization: To the lake again ?\n",
            "Sentence before tokenization: I realized my computer is memory was full yesterday .\n",
            "Sentence before tokenization: a galley worm !\n",
            "Sentence before tokenization: All the things in this world are always changing and Hope will always wait for you just around the corner .\n",
            "Sentence before tokenization: I will try to go to bed .\n",
            "Sentence before tokenization: Free conversation\n",
            "Sentence before tokenization: My hands are dried and those fingers are getting painful .\n",
            "Sentence before tokenization: Well at the moment I am going to practise my Japanese and practise my song\n",
            "Sentence before tokenization: I wish I had won the lottery .\n",
            "Sentence before tokenization: On another day , I met my friends .\n",
            "Sentence before tokenization: The soup of curry noodles is on sale everywhere .\n",
            "Sentence before tokenization: I went to my parents ' home last week to rehearse for the summer festival .\n",
            "Sentence before tokenization: The ratings went up so much higher\n",
            "Sentence before tokenization: Would you check my questions as to whether or not they make sense and are written in proper English ?\n",
            "Sentence before tokenization: When I arrive in America , if I feel sad , I always listen to this song to inspire me .\n",
            "Sentence before tokenization: I go to station and visit a bookstore .\n",
            "Sentence before tokenization: But their talking speed was so fast and British accent kept me from understanding content of movie\n",
            "Sentence before tokenization: So I have to think in English when I speak English .\n",
            "Sentence before tokenization: She told us it is a famous pub with cheap drinks .\n",
            "Sentence before tokenization: By the tale pain table of life that I could bend\n",
            "Sentence before tokenization: I like it very much !\n",
            "Sentence before tokenization: I just start Lang - for maintaining my English Skills .\n",
            "Sentence before tokenization: It said that emberming was famous in America .\n",
            "Sentence before tokenization: Hawaii is my favorite place .\n",
            "Sentence before tokenization: Cause I did not say anything but he know what I wanted to say .\n",
            "Sentence before tokenization: shopping with my kids\n",
            "Sentence before tokenization: Hello everyone !\n",
            "Sentence before tokenization: How lazy we are !\n",
            "Sentence before tokenization:  A kind of characteristics of characters in games , animes , manga and so on .\n",
            "Sentence before tokenization: - One of my colleagues found the program for us .\n",
            "Sentence before tokenization: i write this article to check whether it can be writen to english billboard .\n",
            "Sentence before tokenization: I have a place where I can write in English , that place is Lang - .\n",
            "Sentence before tokenization: as a quick fix - question\n",
            "Sentence before tokenization: I have got a influenza in the week before last .\n",
            "Sentence before tokenization: I hope the victims can get through this hard time as soon as possible .\n",
            "Sentence before tokenization: I love its texture and the condition of its fat .\n",
            "Sentence before tokenization: Some people thought that a serious nuclear power plant accident could happen somewhere some time and that nuclear power stations should be got of .\n",
            "Sentence before tokenization: I miss Sakura .\n",
            "Sentence before tokenization: I am always tired nowadays .\n",
            "Sentence before tokenization: I like love the world\n",
            "Sentence before tokenization: Both definition and collocation have their own demerits and advantages in studying words .\n",
            "Sentence before tokenization: Be careful after a quake for one month .\n",
            "Sentence before tokenization: I have a huge crush on .\n",
            "Sentence before tokenization: Her family members are very friendly and funny , they are happy together .\n",
            "Sentence before tokenization: I am Robin , you can view my profile before you read this letter .\n",
            "Sentence before tokenization: Maybe you can help me ?\n",
            "Sentence before tokenization: Chinese characters are used in the Japanese language .\n",
            "Sentence before tokenization: Thus , bilingual education tends to be signaled as the cause of lower levels of achievement .\n",
            "Sentence before tokenization: Thus , when children go to school and have a great diversity of teachers , they learn much more than their parents could probably give them .\n",
            "Sentence before tokenization: Should I go out with him ?\n",
            "Sentence before tokenization: You can see and learn many things there , for example , Japanese major characters , how to make anime , the historical valuables related to anime .\n",
            "Sentence before tokenization: Long time no see .\n",
            "Sentence before tokenization: I wonder if I have forgotten it .\n",
            "Sentence before tokenization: This morning I got up at am .\n",
            "Sentence before tokenization: Do you have a rules for health ?\n",
            "Sentence before tokenization: As for Lang - , I just voluntary offer short time for touch up , and accept kind correction .\n",
            "Sentence before tokenization: I just have finished watching my princess .\n",
            "Sentence before tokenization: my diary\n",
            "Sentence before tokenization: I think I will keep this sentence in my mind .\n",
            "Sentence before tokenization: He should a little communicate with the students , know the reason why the student do this Whether he want to catch others attention or something .\n",
            "Sentence before tokenization: There were a lot of tourists around Nikko station .\n",
            "Sentence before tokenization: I could buy the book .\n",
            "Sentence before tokenization: I heave not update my blog for so long -\n",
            "Sentence before tokenization: We went to the night view the first night we arrived in Tokyo .\n",
            "Sentence before tokenization: the wedding planner make a mistake - they both have their wedding in the same date .\n",
            "Sentence before tokenization: Almost performers wore black and costumes , so she stood up in them .\n",
            "Sentence before tokenization: held in daytime in Japan so that many people have to do their own jobs .\n",
            "Sentence before tokenization: They are the pictures which I took at the shopping center located near my house , today .\n",
            "Sentence before tokenization: In my personal point , I m in favor of the former lifestyle , changeful and challenging one .\n",
            "Sentence before tokenization: He used the knowledge learned to describe his room .\n",
            "Sentence before tokenization: happy new year\n",
            "Sentence before tokenization: Thank you all for your corrections !\n",
            "Sentence before tokenization: Yesterday drink party .\n",
            "Sentence before tokenization: Love with symbol Love with symbol Symbol by tattoo Symbol by tattoo Tattoo on lady Tattoo on lady Lady in quarter Lady in quarter Quarter for call Quarter for call Call out name Call out name Name of someone Name of someone Someone under arrest Someone under arrest Arrest over night Arrest over night Night at . Night at . Night romance\n",
            "Sentence before tokenization: The clouds were in different shapes .\n",
            "Sentence before tokenization: You must know about the feeling of loneliness or separation , and it is much stronger when you are alone in a foreign country where you know nobody and you ca not understand what they are saying .\n",
            "Sentence before tokenization: Hey little train !\n",
            "Sentence before tokenization: I ca not determine .\n",
            "Sentence before tokenization: First I worked as a clerk in the shopping center , Westfield . \n",
            "Sentence before tokenization: Becaus I love playing soccer .\n",
            "Sentence before tokenization: But my current weight is kg .\n",
            "Sentence before tokenization: But as you know , I am on the recovery from the depression so I began the job as a temporary worker from last October .\n",
            "Sentence before tokenization: Then someday , you will encounter an opportunity to find a way to live positively in this impermanent world .\n",
            "Sentence before tokenization: Actually this is th .\n",
            "Sentence before tokenization: I am not feeling energy right now .\n",
            "Sentence before tokenization: I am always with Nothing can let me down in my heart and never wear a frown even when I am talking to someone upsetting me .\n",
            "Sentence before tokenization:  Be appreciated for warmth and professional presentation , by both domestic and foreign tourists , \n",
            "Sentence before tokenization: On the fourth day , the rabbit bounced into the convenience store and shouted Shopkeeper , are there any pliers ? \n",
            "Sentence before tokenization: I was , for example , at the Cocteau Twins , The Cure , and Genesis concerts .\n",
            "Sentence before tokenization: I won just once in three games .\n",
            "Sentence before tokenization: First of all , there might have good traffic without waiting too much time so that I do nt have to waste time to commute between home and office .\n",
            "Sentence before tokenization: Sometimes I actually skip my schedule !\n",
            "Sentence before tokenization: I had a really nice day .\n",
            "Sentence before tokenization: Today was .\n",
            "Sentence before tokenization: I wo not explain in detail in this entry , but the BGM is cool .\n",
            "Sentence before tokenization: By the way , I am having a headache .\n",
            "Sentence before tokenization: At the office , she is a manager of a corporation and is always swamped with work .\n",
            "Sentence before tokenization: I got up late this morning .\n",
            "Sentence before tokenization: they were really beautiful .\n",
            "Sentence before tokenization: The teacher explained that come by myself meant come alone and continued to explain like this\n",
            "Sentence before tokenization: Athletic festival for local populace .\n",
            "Sentence before tokenization:  In Japan , all the teachers tell us to say I am fine thank you and you ? lol \n",
            "Sentence before tokenization: Why is it so popular among Japanese people ?\n",
            "Sentence before tokenization: I did not care about what kind of houses I lived in .\n",
            "Sentence before tokenization: I can also enjoy the foreigner is reaction to the movie .\n",
            "Sentence before tokenization: Just enough !\n",
            "Sentence before tokenization: Playing sports is good for students .\n",
            "Sentence before tokenization: Do you like Ninja ?\n",
            "Sentence before tokenization: I will have an important exam at university so I must study hard .\n",
            "Sentence before tokenization: The problem is how much I earn in those places .\n",
            "Sentence before tokenization: I am going to start it after I finish this cake .\n",
            "Sentence before tokenization: I tent to do some exercise in my spare time , not only I can do some things that I interested in , but also I would prefer to make different friends , we have diverse culture and language , which improve our relationship and own language .\n",
            "Sentence before tokenization: relaxing and shopping\n",
            "Sentence before tokenization: I know what I need is to wait and think for a while .\n",
            "Sentence before tokenization: But , his great achievement never died .\n",
            "Sentence before tokenization: This TV program is aired from o ' clock on Saturdays , so my family always watches it together .\n",
            "Sentence before tokenization: Comparison Contrast\n",
            "Sentence before tokenization: ?\n",
            "Sentence before tokenization: Today is a gtamar is class .\n",
            "Sentence before tokenization: So when I start eatnig some snacks , I eat it all .\n",
            "Sentence before tokenization: In fact , he is a tender , a polite , a sweet man who helps with the housework too .\n",
            "Sentence before tokenization: He and his wife are very kind and nice person .\n",
            "Sentence before tokenization: And now I have strong motivation to post here regularly .\n",
            "Sentence before tokenization: Today , When I went to work , I felt that atmosphere of restaurant is really something quiet .\n",
            "Sentence before tokenization: My younger daughter took to my father .\n",
            "Sentence before tokenization: I thought that I would like not to go out from the sauna before him .\n",
            "Sentence before tokenization: I love TVXQ .\n",
            "Sentence before tokenization: Last Sunday , I made a whole of shiffon cake , but the size of the cake was one - half compared to the normal one .\n",
            "Sentence before tokenization: Please correct this sentence .\n",
            "Sentence before tokenization: What do you trust ?\n",
            "Sentence before tokenization: The shower of English\n",
            "Sentence before tokenization: I tried to figure out what the whole sentence meant by checking the word spoon as a verb in my dictionary , hoping to make sense .\n",
            "Sentence before tokenization: I would like to make more .\n",
            "Sentence before tokenization: thank you .\n",
            "Sentence before tokenization: I am writing that first .\n",
            "Sentence before tokenization: For daily life work and rest abnormal I to say that compute early .\n",
            "Sentence before tokenization: We shared fried rice with salty chicken and diced beef with vegetables .\n",
            "Sentence before tokenization: I think she is very sad and goes to the offices .\n",
            "Sentence before tokenization: ?\n",
            "Sentence before tokenization: I really enjoyed my time with them .\n",
            "Sentence before tokenization: Teacher said do not read , it is important to speak with words you can use . \n",
            "Sentence before tokenization: I will never forget , I met at high school with friend and teacher and dear person .\n",
            "Sentence before tokenization: Like me , I am not very patient and sensitive about numbers , but now my work is closely related to numbers . It makes me learn to be much more patient and careful .\n",
            "Sentence before tokenization: There are weeks and months left .\n",
            "Sentence before tokenization: Moreover because of a thing that you do nt want to change !\n",
            "Sentence before tokenization: of these message .\n",
            "Sentence before tokenization: If you hope to exchange Japanese and English with me , \n",
            "Sentence before tokenization: If you work hard , you will spend a good time in your school life and your parents will be please to your growth too .\n",
            "Sentence before tokenization: I do not mean this is just for studying .\n",
            "Sentence before tokenization: At the office , she is a manager of a corporation and is always swamped with work .\n",
            "Sentence before tokenization: I am now desperately hunting for a job .\n",
            "Sentence before tokenization: However many Japanese makers , such as Toyota and Panasonic , are suffering from strong Yen .\n",
            "Sentence before tokenization: I am mentally retarded too .\n",
            "Sentence before tokenization: For example , Akira is a common name .\n",
            "Sentence before tokenization: well , today\n",
            "Sentence before tokenization: I felt kind of isolated even though people in my group were really nice .\n",
            "Sentence before tokenization: I heard it is hard to find a job now in japan .\n",
            "Sentence before tokenization: All Greetings !\n",
            "Sentence before tokenization: The mountain was colored red or yellow .\n",
            "Sentence before tokenization: Not learning ' is against the teacher is goal and is the biggest challenge to me .\n",
            "Sentence before tokenization: This is what I am trying to say\n",
            "Sentence before tokenization: He slept while driving .\n",
            "Sentence before tokenization: It s very helpful for me .\n",
            "Sentence before tokenization: This attraction was to dispose of mosquitos with the gun .\n",
            "Sentence before tokenization: I did not like English .\n",
            "Sentence before tokenization: The actors are maybe American or British .\n",
            "Sentence before tokenization: Mozart was a genius .\n",
            "Sentence before tokenization: But it was a good practice to make a sentence instantly .\n",
            "Sentence before tokenization: About my hometown\n",
            "Sentence before tokenization: Through the thin and dark road , we arrived the top of the mountain .\n",
            "Sentence before tokenization: A fried rice she cooked is very nice .\n",
            "Sentence before tokenization: I hope we can eat other vegetables .\n",
            "Sentence before tokenization: It was successful , but later he got mentally sick and was absent for six months .\n",
            "Sentence before tokenization: It takes about min by walk one way .\n",
            "Sentence before tokenization: I wonder how the scenes were made .\n",
            "Sentence before tokenization: He knows the other car owner .\n",
            "Sentence before tokenization: Nearly all my classmates decided to take it , so finally I took part in it .\n",
            "Sentence before tokenization: This word substitutes for a noun .\n",
            "Sentence before tokenization: thanks very much for your help !\n",
            "Sentence before tokenization: Firstly , I felt unconfident , for I knew that I m common and small person \n",
            "Sentence before tokenization: I have questions for you about some phrases .\n",
            "Sentence before tokenization: My cat loves to hold my Wacom .\n",
            "Sentence before tokenization: My head was very tired because I was thinking about too complicated things .\n",
            "Sentence before tokenization: I wanted to go in PSI from bofore .\n",
            "Sentence before tokenization: Please let me introduce a proverb of native American .\n",
            "Sentence before tokenization: I refilled water into my water bottle because a water server was installed in the market .\n",
            "Sentence before tokenization: It was really delicious .\n",
            "Sentence before tokenization: means smile\n",
            "Sentence before tokenization: I have to study all day .\n",
            "Sentence before tokenization: Since it was the first time for me to go abroad , \n",
            "Sentence before tokenization: I will have a medical examination next week .\n",
            "Sentence before tokenization: See you again !\n",
            "Sentence before tokenization: Deep talking , We raised .\n",
            "Sentence before tokenization: Yesterday , I went to the internet room but I had a short time to play language .\n",
            "Sentence before tokenization: objectively consider about the political and financial issues in Okinawa .\n",
            "Sentence before tokenization: I am so sleeply\n",
            "Sentence before tokenization: Japan will face a serious economic crisis .\n",
            "Sentence before tokenization: She does not know how to cook , to do laundry and to clean rooms because a helper is in her house .\n",
            "Sentence before tokenization: Usually it is rainny , cloudy and cool .\n",
            "Sentence before tokenization: As we don ' t have a child , we do not display them any more .\n",
            "Sentence before tokenization: The sun in the summer\n",
            "Sentence before tokenization: They told us a lot of important things .\n",
            "Sentence before tokenization: Too busy a day .\n",
            "Sentence before tokenization: If I go on a business trip alone , I can not go to a restaurant .\n",
            "Sentence before tokenization: This is my homework , please make corrections \n",
            "Sentence before tokenization: The date to visit him is on thuseday in June third after tomorrow .\n",
            "Sentence before tokenization: how to be forgiven by them ?\n",
            "Sentence before tokenization: Even some people can work at home using a computer or telephone .\n",
            "Sentence before tokenization: Kamehameha is No . from a questionnaire .\n",
            "Sentence before tokenization: I am Japanese .\n",
            "Sentence before tokenization: Do you know the word ' fair trade ' ?\n",
            "Sentence before tokenization: I am cheering on Sweden .\n",
            "Sentence before tokenization: Do you often use that phrase ?\n",
            "Sentence before tokenization: I have confidence to improve both my English and Japanese since I met good teachers .\n",
            "Sentence before tokenization: P S\n",
            "Sentence before tokenization: After I started to focus on painting , my blog started to bother me .\n",
            "Sentence before tokenization: It was from Natalya .\n",
            "Sentence before tokenization: As for this evening , I will have to go to a relative is house because my aunt had passed away the day before yesterday .\n",
            "Sentence before tokenization: Mother , father , sister , brothers .\n",
            "Sentence before tokenization: This will make our cost down and make our life happier , I think .\n",
            "Sentence before tokenization: Last , LOVE zukkyun by soutaiseiriron .\n",
            "Sentence before tokenization: For me , it is not just a waste of money , but a reflection of students ' values .\n",
            "Sentence before tokenization: But I still want to try it .\n",
            "Sentence before tokenization: I decided to have a leisurely weekend and just watch TV all day .\n",
            "Sentence before tokenization: thanx for just reading\n",
            "Sentence before tokenization: Thank you a lot of for last letter .\n",
            "Sentence before tokenization: I want to go out without my heavy clothes .\n",
            "Sentence before tokenization: Teen Girl\n",
            "Sentence before tokenization: I will not give up in half way .\n",
            "Sentence before tokenization: However , thinking is always easier than doing .\n",
            "Sentence before tokenization: Please correct me\n",
            "Sentence before tokenization: I took a German examination today .\n",
            "Sentence before tokenization: That changed my life forever .\n",
            "Sentence before tokenization: I prayed\n",
            "Sentence before tokenization: There were over people in the audience .\n",
            "Sentence before tokenization: I want to talk about my hobbies .\n",
            "Sentence before tokenization: Earthquake in Japan on March th\n",
            "Sentence before tokenization: I m glad you have nt brought me back an in - law from Alberta\n",
            "Sentence before tokenization: But , alas !\n",
            "Sentence before tokenization: Some insects such as ants come into a room through chinks .\n",
            "Sentence before tokenization: and why do I not want to give this ? ? ?\n",
            "Sentence before tokenization: Tomorrow morning I will get up early and go out to run .\n",
            "Sentence before tokenization: I think we ca not avoid taking some risks to enjoy our lives .\n",
            "Sentence before tokenization: And I am going to go to the movietheater to see Night and day with friends tomorrow .\n",
            "Sentence before tokenization: It was not cold but definitely not hot either .\n",
            "Sentence before tokenization: someone will do . I am really happy for you .\n",
            "Sentence before tokenization: I may choose a small one though it has some risks .\n",
            "Sentence before tokenization: I wo not know until I buy them .\n",
            "Sentence before tokenization: but I had to work at my desk , eagerly .\n",
            "Sentence before tokenization: Even so , I was able to get the gist and enjoyed it .\n",
            "Sentence before tokenization: The relation of self and friends is not make use of ehch other .\n",
            "Sentence before tokenization: A nickname is bean in English .\n",
            "Sentence before tokenization: I like to go there because I can shift mood and I can be comfrortable .\n",
            "Sentence before tokenization: I talk to him the reason that Korea educational poliscy have problem that focus on the grammer not lisning and speaking before .\n",
            "Sentence before tokenization: Great friends\n",
            "Sentence before tokenization: This is one of the reason why the toss of a coin is nt common .\n",
            "Sentence before tokenization: Getting SUSHI vinegar\n",
            "Sentence before tokenization: The subtitle of this book is Simple ways to keep the little things from taking over your life .\n",
            "Sentence before tokenization: Having a cold\n",
            "Sentence before tokenization: The story is the single man who is years old living with girl who years old .\n",
            "Sentence before tokenization: I run in the night .\n",
            "Sentence before tokenization: Do not worry .\n",
            "Sentence before tokenization: He said me If you really really want it , go , but I am not sure I can wait for you \n",
            "Sentence before tokenization: If you get lost , ring me !\n",
            "Sentence before tokenization: However , a teacher who heard a song admitted that two people went for second selection just after that .\n",
            "Sentence before tokenization: The Toeic Score\n",
            "Sentence before tokenization: I hope to improve my english here .\n",
            "Sentence before tokenization: dreaming their success .\n",
            "Sentence before tokenization: There are so many things to do .\n",
            "Sentence before tokenization: I hope friends could help me .\n",
            "Sentence before tokenization: But I must go to school to study neurological disorder now .\n",
            "Sentence before tokenization: I checked the weather forecast on my mobile phone yesterday and it was interesting that it will be like a sauna tomorrow !\n",
            "Sentence before tokenization: For example , the animation South Park . It is an animation full of bad language .\n",
            "Sentence before tokenization: by my grandmother when I was born .\n",
            "Sentence before tokenization: My hobby is reading books .\n",
            "Sentence before tokenization: all the time .\n",
            "Sentence before tokenization: In high school , I can enjoy being myself with my friends , and I can express my true me .\n",
            "Sentence before tokenization: I was disappointed when Charlie could not get the Golden Ticket but I jumped up to be glad in my mind when he got the last one after later .\n",
            "Sentence before tokenization: So I felt that Apple is very strong .\n",
            "Sentence before tokenization: Otherwise , I did a free conversation with all of the class members and my teacher for about twenty minutes .\n",
            "Sentence before tokenization: I must be mistaken about something .\n",
            "Sentence before tokenization: What does this mean ?\n",
            "Sentence before tokenization: Anyways , I am satisfied that I could learn the direction .\n",
            "Sentence before tokenization: Oh my holiday will be over but i feel this summer is too normal .\n",
            "Sentence before tokenization: Most of all the time , we used electronic dictionary and spoke awful English .\n",
            "Sentence before tokenization: And if you guys can help me , I want to know more about the verbs .\n",
            "Sentence before tokenization: If I refuse it in Chinese , it will not be as powerful as in Taiwanese , it is rude though .\n",
            "Sentence before tokenization: So I asked her to meet on Christmas .\n",
            "Sentence before tokenization: The students concentrated the story which is Croatian story for minutes .\n",
            "Sentence before tokenization: The last time I took TOElC TEST was July , about two years ago .\n",
            "Sentence before tokenization: Because it was small and it was not in the house .\n",
            "Sentence before tokenization: We are going too far if we draw some conclusion that Chinese education must be changed after a comparison between Chinese educational system and the American one .\n",
            "Sentence before tokenization: But current weights are kg .\n",
            "Sentence before tokenization: Recently , i was busy with a project .\n",
            "Sentence before tokenization: F\n",
            "Sentence before tokenization: I would like to introduce myself briefly .\n",
            "Sentence before tokenization: He usually complains to me that if he had a time machine , he would remind himself to be a scientist rather than be a guitar player .\n",
            "Sentence before tokenization: free bus\n",
            "Sentence before tokenization: I came back to London last Sunday .\n",
            "Sentence before tokenization: But the box of many books was too hard to carry for us .\n",
            "Sentence before tokenization: It was working until the afternoon .\n",
            "Sentence before tokenization: He hitted drum with full of smile .\n",
            "Sentence before tokenization: My first impression of America\n",
            "Sentence before tokenization: There were many people .\n",
            "Sentence before tokenization: Completely !\n",
            "Sentence before tokenization: The weather is very strange .\n",
            "Sentence before tokenization: Though I never go to a fitness gym , I will start training at home .\n",
            "Sentence before tokenization: I started to learn lang - today .\n",
            "Sentence before tokenization: I thought it was a little unfair for me besause I always the first one to answer the questions .\n",
            "Sentence before tokenization: Do you finish it ?\n",
            "Sentence before tokenization: Usually i use casually Japanese .\n",
            "Sentence before tokenization: Learning English\n",
            "Sentence before tokenization: By the way , I like my mother cooking lunch box \n",
            "Sentence before tokenization: After all , I chose the one which has a picture of some famous animals in Australia such as koala , kangaroo , and wombat .\n",
            "Sentence before tokenization: And you get a good return .\n",
            "Sentence before tokenization: I started studying English about two months ago .\n",
            "Sentence before tokenization: B But you need to repay the money after you get your salary .\n",
            "Sentence before tokenization: And your email is almost perfect .\n",
            "Sentence before tokenization: In the dent in the middle of the rock , there are two people walking .\n",
            "Sentence before tokenization: It seems that these wire hangers that crows collect and put on utility poles cause a short and eventually result in blackouts .\n",
            "Sentence before tokenization: So I decided to buy a large size of food carrier to test my amazing idea .\n",
            "Sentence before tokenization: I saw a lot of deers .\n",
            "Sentence before tokenization: I am currently attending an international school .\n",
            "Sentence before tokenization: Secondary , buying those products will become a presser of financial system of houses .\n",
            "Sentence before tokenization: I listened to his victory speech on YouTube before and I was impressed too .\n",
            "Sentence before tokenization: I really do not know how to handle these kids or their weird ideas that make bad influence on their class .\n",
            "Sentence before tokenization: I am watching the rain through the window , and speaks to myself .\n",
            "Sentence before tokenization: Go home\n",
            "Sentence before tokenization: I am , of course , speaking as an amateur .\n",
            "Sentence before tokenization: In connection with it , in agriculture transgenic agricultural technologies have been begun to be used .\n",
            "Sentence before tokenization: Is your country a season of summer ?\n",
            "Sentence before tokenization: In , when I traveled in U .\n",
            "Sentence before tokenization: I felt strange but funny because teacher was closer than usual , and we can talk morefrankly in classroom .\n",
            "Sentence before tokenization: She did not look spiritless , so I and other friends gave her a lift .\n",
            "Sentence before tokenization: The exception has to be\n",
            "Sentence before tokenization: But I ca nt upload them to lang - site now and will upload them all together when connected or in the office tomorrow .\n",
            "Sentence before tokenization: I wish the handouts were made automatically .\n",
            "Sentence before tokenization: Anyway , it is nice to be here , though I guess I have to try my best to keep up the practice , writing a short diary or something else .\n",
            "Sentence before tokenization: I logged in Second Life to study English .\n",
            "Sentence before tokenization: I will write in Korean .\n",
            "Sentence before tokenization: Chocolate Disco is a very pretty song\n",
            "Sentence before tokenization: It is one of the Chinese noodles in Japan .\n",
            "Sentence before tokenization: Question\n",
            "Sentence before tokenization: The wind is very strong and it is raining . The temperature is also very low .\n",
            "Sentence before tokenization: I do different things that they want .\n",
            "Sentence before tokenization: I often drink the alcohol to relax after studying for a long time .\n",
            "Sentence before tokenization: See you again !\n",
            "Sentence before tokenization: It sounds normal .\n",
            "Sentence before tokenization: Since I was born , I have a different life form other people .\n",
            "Sentence before tokenization: Far from itThey are famous Catholic laity .\n",
            "Sentence before tokenization: Aftershock has still been keeping .\n",
            "Sentence before tokenization:  By the way , sorry to change the subject suddenly but , today I went to an aquarium with my GF and saw this message that had really confused me .\n",
            "Sentence before tokenization: I am eating hot noodles for breakfast .\n",
            "Sentence before tokenization: If I were in this situation , I would choose the piano version of Faure is impromptu No . in D flat major , which was written in .\n",
            "Sentence before tokenization: Sudden text\n",
            "Sentence before tokenization: Brand jeans and shirts in Japan are .\n",
            "Sentence before tokenization: I am the monkey you saved this afternoon and I have come here to repay your kindness\n",
            "Sentence before tokenization: I have a lot of dreams , they never come true . My lazy is a very big problem .\n",
            "Sentence before tokenization: That means this album is well constructed like a good full - course meal .\n",
            "Sentence before tokenization: that are still practiced today , much to the intrigue and wonderment of its audience .\n",
            "Sentence before tokenization: - Sweet potatoes one of my friends gave me a few days ago .\n",
            "Sentence before tokenization: I will have to come here often .\n",
            "Sentence before tokenization: It went to the cafe named Maruge with the friend yesterday .\n",
            "Sentence before tokenization: I called a city office and asked if they had my bicycle .\n",
            "Sentence before tokenization: In the context of the current healthcare reform , I want to know how this point is discussed .\n",
            "Sentence before tokenization: As you know , in companies , there are very many workers , and we can call them co - workers except you .\n",
            "Sentence before tokenization: d Which languages do you like ?\n",
            "Sentence before tokenization: It is been very cool for the last few days , though it was rather hot until only a while ago .\n",
            "Sentence before tokenization: - or on another open air\n",
            "Sentence before tokenization: in English\n",
            "Sentence before tokenization: I ca not think that I can speak English well , on the other hand , I can get a nerve .\n",
            "Sentence before tokenization: There is no end of interesting conversation .\n",
            "Sentence before tokenization: The match was cancelled because most of the members a match without a standard court .\n",
            "Sentence before tokenization: I will be good English speaker even though I can not speak Englsh .\n",
            "Sentence before tokenization: After I ate lunch , I went to change my shoes heels .\n",
            "Sentence before tokenization: it was good .\n",
            "Sentence before tokenization: I have one thing I want to do today .\n",
            "Sentence before tokenization: It is colorful and beautiful .\n",
            "Sentence before tokenization: I went shopping with my husband to our favorite store , BARNEYS NEW YORK in Shinjyuku .\n",
            "Sentence before tokenization: P . S\n",
            "Sentence before tokenization: We come across many English words in Japanese cartoons , video games and lyrics of songs .\n",
            "Sentence before tokenization: It was working until the afternoon .\n",
            "Sentence before tokenization: Hair cut\n",
            "Sentence before tokenization: By the time my grandpa died , most of them had not actually been practiced so often .\n",
            "Sentence before tokenization: Japanese are eager to do things on time .\n",
            "Sentence before tokenization: I think that flu is someone .\n",
            "Sentence before tokenization: The day before departure we changed rubles on lirs at the currency exchange and bought souvenirs for our relatives .\n",
            "Sentence before tokenization: Way to go , mother !\n",
            "Sentence before tokenization: If they say they want to live large , \n",
            "Sentence before tokenization: It is so crazy to go home at p .m . and wake up at a .m . , \n",
            "Sentence before tokenization: How about these expressions ? Please correct\n",
            "Sentence before tokenization: His novels ' vocabulary is my limitation , and I need a lot of time to write in English .\n",
            "Sentence before tokenization: So I am writing this entry now .\n",
            "Sentence before tokenization: english paragraph about Checkov is The Bet\n",
            "Sentence before tokenization: Most of us eager to have a romantic love just like a beautiful princess meets a handsome prince .\n",
            "Sentence before tokenization: I start quickly becoming your part of past but in that instant , I get to share your present , and YOU get to share mine and THAT is the greatest present of all .\n",
            "Sentence before tokenization: I am so sweaty now .\n",
            "Sentence before tokenization: The data master hoped he could have a nice sleep tonight .\n",
            "Sentence before tokenization: I was very glad and really impressed with his improvement and efforts .\n",
            "Sentence before tokenization: What s your dream ?\n",
            "Sentence before tokenization: Next , I want to show you how I met Yosakoi .\n",
            "Sentence before tokenization: Coffee makes me refreshed , milk tea makes me conformed , green tea makes me relaxed .\n",
            "Sentence before tokenization: I like travelling . If you travel to my home , I will be very happy to show you around !\n",
            "Sentence before tokenization: In my opinion , DALADALA is the worst transportation in the world .\n",
            "Sentence before tokenization: What do I have to wear ?\n",
            "Sentence before tokenization: we is going to make potofu .\n",
            "Sentence before tokenization: While I was configuring WMP , I noticed that I can listen to internet radio via WMP .\n",
            "Sentence before tokenization: I felt I really knew his admirable personal character . If a natural born educator exists , he is exactly that .\n",
            "Sentence before tokenization: The music\n",
            "Sentence before tokenization: I was surprised that there are decoies of frant in lang - .\n",
            "Sentence before tokenization: But I have to do it , because I ca not graduate from my school .\n",
            "Sentence before tokenization: I had the worst expierence of my life on new year is day .\n",
            "Sentence before tokenization: I have to research to get a Master is degree .\n",
            "Sentence before tokenization: I enclose my CV .\n",
            "Sentence before tokenization: Do You like J - rock Visual Key ?\n",
            "Sentence before tokenization: Sometimes you get what you are not interested in .\n",
            "Sentence before tokenization: I corrected some Japanese entries written by others for the first time .\n",
            "Sentence before tokenization: Today , we spoke about space .\n",
            "Sentence before tokenization: While I was riding it , something fell down on around my knee .\n",
            "Sentence before tokenization: I always say to the teacher ' May I cancell the next lesson ? ' .\n",
            "Sentence before tokenization: The sub - points will contain a parallel structure to each other since they will all deal with the question how Laforgue s character , his physical appearance , and his relation to religious belief , God , the Savages and Daniel Davost change at the different stages of his mission .\n",
            "Sentence before tokenization: Boston Celtics got off to a good start this season .\n",
            "Sentence before tokenization: It is a short reply , It make our conversation smoothly .\n",
            "Sentence before tokenization: Is that money ? Honour ? Social position ?\n",
            "Sentence before tokenization: June\n",
            "Sentence before tokenization: My old friend called me and said let is me help her niece s work in Chinese .\n",
            "Sentence before tokenization: listening , speaking , reading , and writing skills .\n",
            "Sentence before tokenization: Happiness day\n",
            "Sentence before tokenization: I saw the trailer on Youtube a little while ago , and I found that it was so scary , like a horror movie .\n",
            "Sentence before tokenization: So , I m tired . Besides , I am sleepy .\n",
            "Sentence before tokenization: For example , even after a huge earthquake happened , I have never heard people in the area complain about a terrible daily life .\n",
            "Sentence before tokenization: The woman loves him deep , but the man is not at all , \n",
            "Sentence before tokenization: But I think I have a lot of problem to improve .\n",
            "Sentence before tokenization: It s dark and a little creepy on the mound now .\n",
            "Sentence before tokenization: It was very exciting .\n",
            "Sentence before tokenization: Taking into account of all factors I give above , we may safely draw a conclusion that improving school is not the most important factor in successful development of a country .\n",
            "Sentence before tokenization: They will eat nothing since becoming images .\n",
            "Sentence before tokenization: It seems a great place to make friends with people from worldwide and to improve my language skill .\n",
            "Sentence before tokenization: These techniques are very important and I was amazed .\n",
            "Sentence before tokenization: So my major is not related to food my major is law , I do not have enough knowledge about food .\n",
            "Sentence before tokenization: The Byzantine Emperor Basil was busy with the campaign to subjugate the Bulgarians .\n",
            "Sentence before tokenization: This is my rating absolutely charming !\n",
            "Sentence before tokenization: Please consider that we are living in this flat and using the facilities every day .\n",
            "Sentence before tokenization: I like it class because the teacher is a really funny class .\n",
            "Sentence before tokenization: Being a very smart person and talented writer , Voinovich predicted too accurately what way Russian post - soviet society tended to choose .\n",
            "Sentence before tokenization:  NOTE everyone singular subject , so you must use singular verb has .\n",
            "Sentence before tokenization: I do not remember how many times I mentioned it , but again it is high time I focused much more on input training .\n",
            "Sentence before tokenization: I recommend you to eat Sushi there .\n",
            "Sentence before tokenization: in hours and half - flight .\n",
            "Sentence before tokenization: By the way , I have changed my work time .\n",
            "Sentence before tokenization: Waiting time chatted for a long time .\n",
            "Sentence before tokenization: for college , I could play it .\n",
            "Sentence before tokenization: Poor My Friend John\n",
            "Sentence before tokenization: What is it ?\n",
            "Sentence before tokenization: I learned the words about ' the feelings of excitement and delight ' today .\n",
            "Sentence before tokenization: Hi , Lang - ! !\n",
            "Sentence before tokenization: China is from Chin .\n",
            "Sentence before tokenization: Even though I was really lazy I went there .\n",
            "Sentence before tokenization: Just google or search on Youtube .\n",
            "Sentence before tokenization: So I have to separate completely my things and work .\n",
            "Sentence before tokenization: I am going to go sightseeing in Korea with my cousin .\n",
            "Sentence before tokenization: They can feel our love and patience .\n",
            "Sentence before tokenization: I really appreciate her help .\n",
            "Sentence before tokenization: He had not been playing with his best friend Campanella , who was popular among his classmates , for a long time .\n",
            "Sentence before tokenization: please , help me , thanks a lot \n",
            "Sentence before tokenization: Should I say let me faint or make me faint ?\n",
            "Sentence before tokenization: So I am very proud to write in English .\n",
            "Sentence before tokenization: But if I were forced to be in exactly the same situation like the day when I could not turn in my homework , I am still not sure I would not mumble to myself .\n",
            "Sentence before tokenization: The shelter is executive started to narrate the history , circumstance , spirit and goal of the shelter .\n",
            "Sentence before tokenization: Do you often take photos ?\n",
            "Sentence before tokenization: I found out that after the installation of the sound card .\n",
            "Sentence before tokenization: see ya !\n",
            "Sentence before tokenization: I have already bought a London travel guide .\n",
            "Sentence before tokenization: how about your country ? ?\n",
            "Sentence before tokenization: The reason is that I am working with people who can use only English for any communication .\n",
            "Sentence before tokenization: This is just my impression , so I do not know in real life .\n",
            "Sentence before tokenization: Japanese society is rapidly aging .\n",
            "Sentence before tokenization: I try to writing mail in office .\n",
            "Sentence before tokenization: Thus , adults should encourage them to have opportunities to read good materials .\n",
            "Sentence before tokenization: I decided to study Japanese at that time but I felt my Japanese ability was not better than English .\n",
            "Sentence before tokenization: And I also study English and Italian , but I do nt have confident with my communication skill of these because , I have never experienced homestay or studying abroad .\n",
            "Sentence before tokenization: By the way please collect my English and teach English .\n",
            "Sentence before tokenization: I really overwhelmed by it has so many elocution and infinity branches .\n",
            "Sentence before tokenization: So the decline of this rate in most developed countries has been and will be an unavoidable reality and agrees with the laws of progress of society .\n",
            "Sentence before tokenization: I am Hanka .\n",
            "Sentence before tokenization: Today I have a party to go to !\n",
            "Sentence before tokenization: Where is the best city in China ?\n",
            "Sentence before tokenization: I want to be tired , not to have a good sleep , read a work pad in the morning .\n",
            "Sentence before tokenization: Now , you can see the blue sky among many clouds .\n",
            "Sentence before tokenization: After that , I cooked a meal of Korean food .\n",
            "Sentence before tokenization: It was because Americans looked more open and more enjoying conversations than Japanese .\n",
            "Sentence before tokenization: I could not talk to people by myself .\n",
            "Sentence before tokenization: This song has such a beautiful melody !\n",
            "Sentence before tokenization: Today , I modeled for my older sister .\n",
            "Sentence before tokenization: We kept a promise to do Karaoke on Skype tomorrow again .\n",
            "Sentence before tokenization: David put his hurt into piano .\n",
            "Sentence before tokenization: I am a company employee who is years old .\n",
            "Sentence before tokenization: Is not it a little funny ?\n",
            "Sentence before tokenization: I feel a little better now .\n",
            "Sentence before tokenization: Have a nice day !\n",
            "Sentence before tokenization: The third generation will be better than the second generation .\n",
            "Sentence before tokenization: I was so jealous of them .\n",
            "Sentence before tokenization: I am writing my first diary to let you know how useful this service is .\n",
            "Sentence before tokenization: The First Dairy !\n",
            "Sentence before tokenization: Oh I wrote just a part of my huge experience .\n",
            "Sentence before tokenization: However , I want to live in tokyo someday ! !\n",
            "Sentence before tokenization: Should I go for a subject major which I am pretty fond of , but I am uncertain whether I have real talent for that and my favourite subject is not always that popular , so I really have to take my future jobs into account .\n",
            "Sentence before tokenization: If we want to earn money , I have to make a company , and we have to do better that machines if we want to get job .\n",
            "Sentence before tokenization: I am going to tell you what I have done today .\n",
            "Sentence before tokenization: But if I were forced to be in exactly the same situation as the day when I could not turn in my homework , I am still not sure I would not mumble to myself .\n",
            "Sentence before tokenization: But , I yerned to learn english .\n",
            "Sentence before tokenization: I have practiced juggling for years .\n",
            "Sentence before tokenization: the cheap pray\n",
            "Sentence before tokenization: Also , in the world , actions driving nuclear electric - power policy seems to certainly slow down .\n",
            "Sentence before tokenization: She gave me a line in Japanese and asked me to translate it into a natural English .\n",
            "Sentence before tokenization: Yesterday s run was pretty special , though I jog daily in the riverside park .\n",
            "Sentence before tokenization: I should said let me faint or make me faint ?\n",
            "Sentence before tokenization: Because , the patterns of those sentences are very similar and limited .\n",
            "Sentence before tokenization: but I do not know our product well done .\n",
            "Sentence before tokenization: I am dreaming to join the Volunteer to save Tasmanian Devil one day .\n",
            "Sentence before tokenization: Actually , it is not for studying English .\n",
            "Sentence before tokenization: A friend of mine writes a long journal every day .\n",
            "Sentence before tokenization: When I saw the movie I thought war would never happen again .\n",
            "Sentence before tokenization: Hard worker is life\n",
            "Sentence before tokenization: tips I can share with everyone who wants to take back the control\n",
            "Sentence before tokenization: I hope it was interesting for you to read it .\n",
            "Sentence before tokenization: I have a Nokia N and the Joiku application .\n",
            "Sentence before tokenization: I m exhausted !\n",
            "Sentence before tokenization: He did not say anything .\n",
            "Sentence before tokenization: Copying is too easy , rather than buying CDs .\n",
            "Sentence before tokenization: How are you .\n",
            "Sentence before tokenization: Now , it sounds like this to speak American English fluently with a strong accent and to pass the CPE exam in the last term of this year .\n",
            "Sentence before tokenization: Do you think she is pretty ?\n",
            "Sentence before tokenization: Good night .\n",
            "Sentence before tokenization: As soon as I arrived there , I started confirming whether they were living safe and sound or not , due to their inabilities to fly with their own wings as they would like .\n",
            "Sentence before tokenization: Please correct me .\n",
            "Sentence before tokenization: In order to make hot beer , I only heat up black beer .\n",
            "Sentence before tokenization: These advantageous are critical to train a successful Media Informatics researcher because Media Informatics requires both advanced facilities and support of industries .\n",
            "Sentence before tokenization: We bought a whole cake for her .\n",
            "Sentence before tokenization: Hi , Lang - ! !\n",
            "Sentence before tokenization:  - England Premier League is ended last week , today is the first weekend which is no Premier League match to watch , so poor . \n",
            "Sentence before tokenization: I am always glad to see that he makes me smile in a variety of ways .\n",
            "Sentence before tokenization: I would really like to pass ! !\n",
            "Sentence before tokenization: nd class\n",
            "Sentence before tokenization: I have been wanting to try kayaking there .\n",
            "Sentence before tokenization: Today , The Lost Ship in the Sky is on in China .\n",
            "Sentence before tokenization: Second , I do a push - up as the exercise of the upper part of the body .\n",
            "Sentence before tokenization: It is a rose being penetrated by a bullet .\n",
            "Sentence before tokenization: I finished the report .\n",
            "Sentence before tokenization: because I want to save money .\n",
            "Sentence before tokenization: But reading does not discuss about this .\n",
            "Sentence before tokenization: I do not know if the English language education in Japan is good , but it is not so easy to seek the best way to teach English for Japanese children .\n",
            "Sentence before tokenization: we discussed our futures and dreams .\n",
            "Sentence before tokenization: Today I went to church\n",
            "Sentence before tokenization: I will have an important exam at university , so I must study hard .\n",
            "Sentence before tokenization:  Many families have evacuated especially foreign residents - because embassies have advised them to move from Tokyo Many embassies and their houses are located near my office , and the nearest station from my house has an express to airports , so\n",
            "Sentence before tokenization: I did not know that yet .\n",
            "Sentence before tokenization: As if .\n",
            "Sentence before tokenization: New text book\n",
            "Sentence before tokenization: Admittedly , it is students ' inborn responsibility to study , and students should not ignore the importance of knowledge .\n",
            "Sentence before tokenization: They are older than me , just like my uncle , aunt and grandmother .\n",
            "Sentence before tokenization: Now , I have three extra Windows and no one wants to buy them from me because they know they can get a student discount .\n",
            "Sentence before tokenization: What do you think about Japan ?\n",
            "Sentence before tokenization: Yesterday was a drink party .\n",
            "Sentence before tokenization: two bleachers , a toilet detergent , an anti - insect spray , an eye lotion , etc .\n",
            "Sentence before tokenization: After I came home , \n",
            "Sentence before tokenization: We have three children .\n",
            "Sentence before tokenization:  days ago , I play with my friend is dog beside a table .\n",
            "Sentence before tokenization: That was easy .\n",
            "Sentence before tokenization: I have just joined and read some entries .\n",
            "Sentence before tokenization: If I had lost only one point , I could not have passed .\n",
            "Sentence before tokenization: You can check your departure , destination and time on the timetable .\n",
            "Sentence before tokenization: Below is the narration I made .\n",
            "Sentence before tokenization: Introducing myself\n",
            "Sentence before tokenization: Figure out what you are very good at doing - delegate or outsource the rest .\n",
            "Sentence before tokenization: Happy Valentine day !\n",
            "Sentence before tokenization: She said that she would like to abandon her job .\n",
            "Sentence before tokenization: Because I like One Piece so much , I still like this version .\n",
            "Sentence before tokenization: He know each other the car owner .\n",
            "Sentence before tokenization: I received some cold compresses to heal the bruise from my doctor .\n",
            "Sentence before tokenization: I do love cleaning others ' ears as well , but it is more like exciting .\n",
            "Sentence before tokenization: And I am satisfied with her ward .\n",
            "Sentence before tokenization: In fact , it is one of the most important tools all over the world .\n",
            "Sentence before tokenization: So I have to practice piano tomorrow .\n",
            "Sentence before tokenization: Digital Camera ! ! ! ! ! ! ! ! !\n",
            "Sentence before tokenization: The film shows that the beauty of the soul is greater than the man is strength .\n",
            "Sentence before tokenization: People don t think they might be infected .\n",
            "Sentence before tokenization: I sang , jumped , danceed and was tired !ahaha !\n",
            "Sentence before tokenization: When I was child , my mother gave me three chances .\n",
            "Sentence before tokenization: It is a miracle .\n",
            "Sentence before tokenization: We met here after years .\n",
            "Sentence before tokenization: Will he catch a worse cold than us from now ?\n",
            "Sentence before tokenization: believe it or not , I never believe it .\n",
            "Sentence before tokenization: Recently I often listened to this song on TV .\n",
            "Sentence before tokenization: They rolled away from the raft to the river bank running on debris and driftwood floating in the river .\n",
            "Sentence before tokenization: I said to him I did nt want to have a baby then .\n",
            "Sentence before tokenization: I could not get off the train .\n",
            "Sentence before tokenization:  Togo is players were not only people , two soldiers were there too \n",
            "Sentence before tokenization: can you go shopping with me ?\n",
            "Sentence before tokenization: And then an emergency announcement from an emergency center started .\n",
            "Sentence before tokenization: Skipped a study\n",
            "Sentence before tokenization: The subject\n",
            "Sentence before tokenization: The time between us for talking became less and less .\n",
            "Sentence before tokenization: The copyright of the paper published Can I set ?\n",
            "Sentence before tokenization: Although equity is not traded by its fundamental value recently , \n",
            "Sentence before tokenization: This CM song is I have got a rock ' n ' roll heart .\n",
            "Sentence before tokenization: I hope someday I will visit a lot of countries where I have never been .\n",
            "Sentence before tokenization: As obtaining a lot every day , I enjoy this feeling \n",
            "Sentence before tokenization: It was really exciting ! And then I made a song by ad - lib .\n",
            "Sentence before tokenization: But I felt tired\n",
            "Sentence before tokenization: We are not comedians .\n",
            "Sentence before tokenization: Then I came back home seeing shining cherry blossoms again .\n",
            "Sentence before tokenization: We SPEAK ENGLISH with these Chinese students .\n",
            "Sentence before tokenization: Secondly , they can spend more time with their family , they can understand the importance of family .\n",
            "Sentence before tokenization: After the talk , she changed the rice ball with his persimmon seed .\n",
            "Sentence before tokenization: But we were worry .\n",
            "Sentence before tokenization: I went to the summer festival yesterday .\n",
            "Sentence before tokenization: As soon as I finish my class , I will go to the movie theater near her house .\n",
            "Sentence before tokenization: He watched them all on his television screen .\n",
            "Sentence before tokenization: Thank you for reading .\n",
            "Sentence before tokenization: After all , my husband and I do not drink beer , but his people at the office send us beer , so we gave them to my son .\n",
            "Sentence before tokenization: So I go home and play videogames or read comics !\n",
            "Sentence before tokenization: I think it is crazy but I imagine the sights , it is a little pretty !\n",
            "Sentence before tokenization: People in Canada are usually helpful and take hold of the door so as not to close suddenly .\n",
            "Sentence before tokenization: In addition to this fund , public funds from the Federal Government and the states shall be added when appropriate , together with the funds for capacity - building programs .\n",
            "Sentence before tokenization: what are they about to do ?\n",
            "Sentence before tokenization: As for me , I do nt agree both ideas completely .\n",
            "Sentence before tokenization: It is difficult for me to talk everything in English in minutes .\n",
            "Sentence before tokenization: look stunned .\n",
            "Sentence before tokenization: I watched the movie last night .\n",
            "Sentence before tokenization: I heard an English Class which is just for Chinese , not for Korean .\n",
            "Sentence before tokenization: I think my parents will give me a new music player today so I am excited to go home today .\n",
            "Sentence before tokenization: The simplest is the best .\n",
            "Sentence before tokenization: Although I have to study English harder to reach my full potential , \n",
            "Sentence before tokenization: When I go shopping with my husband , he usually gets irritated , probably because I take a long time and he does not like shopping very much .\n",
            "Sentence before tokenization: May dancing lions bring you health and good luck !\n",
            "Sentence before tokenization: I think it is more persuading than old one .\n",
            "Sentence before tokenization: Life is like a journey , you can lose one is way and you do not know the next steps .\n",
            "Sentence before tokenization: Apart from improving my english , I would love to speak japanese .\n",
            "Sentence before tokenization: This is my first diary .\n",
            "Sentence before tokenization: It is a kind of traditional custom in Japan .\n",
            "Sentence before tokenization: It seems there were various circumstances behind it .\n",
            "Sentence before tokenization: We played games , and we were prize .\n",
            "Sentence before tokenization: Surprisingly it is look like art .\n",
            "Sentence before tokenization: This entry is not for commercial use .\n",
            "Sentence before tokenization: Each of these songs are very wonderful .\n",
            "Sentence before tokenization: I am interested .\n",
            "Sentence before tokenization: That is why you have to think twice about buying a computer or a mobile phone for your child or not , because it definitely will cause problems for his health .\n",
            "Sentence before tokenization: Finally I got a driver is license here in California .\n",
            "Sentence before tokenization: Finally he had to go to hospital and was asked for a operation .\n",
            "Sentence before tokenization: She has received great respect and love from Japanese citizens as a Judo star .\n",
            "Sentence before tokenization: not problem problem problem NO PROBLEM\n",
            "Sentence before tokenization: I wish I was richman\n",
            "Sentence before tokenization: That is all .\n",
            "Sentence before tokenization: It is interesting .\n",
            "Sentence before tokenization: Admittedly , there are some positive influences if public transport is free .\n",
            "Sentence before tokenization: The government denies participation in the plan for the attack .\n",
            "Sentence before tokenization: I know I am going to be busy when I get back to work , so I want to enjoy my time with my baby .\n",
            "Sentence before tokenization: Would you rather bully someone or act in bad faith ?\n",
            "Sentence before tokenization: That is why I am travelling to the States this year .\n",
            "Sentence before tokenization: I thoght it is too dificult to cook but it is not difficult , beyond expectation .\n",
            "Sentence before tokenization: Someone told me he would come late with the ABET teacher .\n",
            "Sentence before tokenization: I really want to get score .\n",
            "Sentence before tokenization: People on this stage are good at presentation .\n",
            "Sentence before tokenization: Although this is my own view , stress is a very important sensor that tells me the existence of potential risk .\n",
            "Sentence before tokenization: Even so , you ca not believe that you will learn grammar too while you are reading .\n",
            "Sentence before tokenization: Great performer .\n",
            "Sentence before tokenization: He already does not like a mathematics which is getting difficult day by day .\n",
            "Sentence before tokenization: His wife is an intelligent girl , and he is too .\n",
            "Sentence before tokenization: and actually i was sleeping at that class\n",
            "Sentence before tokenization: It was a sunny day .\n",
            "Sentence before tokenization: Tom was also frustrated and had no idea what went wrong .\n",
            "Sentence before tokenization: So he had no choice but to go to the camp even though he was a doctor .\n",
            "Sentence before tokenization: When stirs fry system this vegetable , wants the strong fire to be intensive .\n",
            "Sentence before tokenization: Because I am taking an IELTS test tomorrow .\n",
            "Sentence before tokenization: In the past I went to sleep at , but after the child was born , I went to sleep earlier .\n",
            "Sentence before tokenization: I am going to tell you .\n",
            "Sentence before tokenization: My son was born on Feb .\n",
            "Sentence before tokenization: Have a good night .\n",
            "Sentence before tokenization: I can make a lot of friends through free activities .\n",
            "Sentence before tokenization: Crafts in Japan are such expensive things to do .\n",
            "Sentence before tokenization: By the way , I am going to Japan three weeks from now .\n",
            "Sentence before tokenization: What a very hard business trip it is !\n",
            "Sentence before tokenization: Because I don t know whether the sentence is right or wrong .\n",
            "Sentence before tokenization: But Twilight is different .\n",
            "Sentence before tokenization: She gave a touching speech today !\n",
            "Sentence before tokenization: Is it sound exaggerated ?\n",
            "Sentence before tokenization: The lecture also showed the influences of global warming .\n",
            "Sentence before tokenization: I had made some friends who always openly share with me since I had entered this website , there is nothing but being deeply grateful .\n",
            "Sentence before tokenization: As for the sedan , although its sales were growing until , the sales decreased since then .\n",
            "Sentence before tokenization: They are too graphic for the generally ungraphic English emoticons to be used suitably in combination .\n",
            "Sentence before tokenization: I ca not get him out of my head !\n",
            "Sentence before tokenization: He asked me How about your research ? .\n",
            "Sentence before tokenization: She worked together me for years .\n",
            "Sentence before tokenization: I will write very hardly every day from now on .\n",
            "Sentence before tokenization: I took some pics , and posted two of them here .\n",
            "Sentence before tokenization: He always makes use of his time better .\n",
            "Sentence before tokenization: Some nurses intermittently prompted her to take a deep breath again and again .\n",
            "Sentence before tokenization: And in this case , it is pretty much the same as that is in English .\n",
            "Sentence before tokenization: I am in luck today .\n",
            "Sentence before tokenization: I think I would like to continue to keep a diary .\n",
            "Sentence before tokenization: I would like learning english , could you help me ? my MSN is masusie hotmail .\n",
            "Sentence before tokenization: Even though I am busy , I still want to write about my feelings .\n",
            "Sentence before tokenization: As a matter of course , we talk on Skype every day .\n",
            "Sentence before tokenization: Do you know what this picture is ?\n",
            "Sentence before tokenization: In other words , all you have to pay in the first place are deposit and rent .\n",
            "Sentence before tokenization: Yesterday I do not have power to play with my kids , I was laying all day long .\n",
            "Sentence before tokenization: since he always changes what he already directed , especailly when his bosses order him to make different\n",
            "Sentence before tokenization: The bread contained many sorts of rice .\n",
            "Sentence before tokenization: Here is my writing below .\n",
            "Sentence before tokenization: I am sorry for hiding this .\n",
            "Sentence before tokenization: I decided to have leisurely weekend and just watch TV all day .\n",
            "Sentence before tokenization: and to try to pretend I am OK .\n",
            "Sentence before tokenization: Although it was already four days ago , I still feel like writing it down loyally just like a child .\n",
            "Sentence before tokenization: I am always serious ! ! !\n",
            "Sentence before tokenization: Moreover she encourage us to appreciate every staff in our daily life , do nt hesitate to enter a luxury store though we could nt afford it .\n",
            "Sentence before tokenization: here in brazil\n",
            "Sentence before tokenization: I feel like buying it as soon as possible .\n",
            "Sentence before tokenization: Maybe that is because I am about to have a big exam in few months .\n",
            "Sentence before tokenization: But something is so confusing .\n",
            "Sentence before tokenization: The reason why I got this job was I wanted to design .\n",
            "Sentence before tokenization: In a man is younger years , he is much more self - absorbed and unaware of the needs of others .\n",
            "Sentence before tokenization: Tomorrw , There are practice games .\n",
            "Sentence before tokenization: Which do you prefer and why ?\n",
            "Sentence before tokenization: I took a Chief Telecommunications engineer exam today .\n",
            "Sentence before tokenization: After a while , when she begins to appreciate me for listening , then , even if I was partially responsible for her discomfort , she becomes very grateful , accepting , and loving .\n",
            "Sentence before tokenization: Secondly , immunization is not expensive because the government support the cost for citizen .\n",
            "Sentence before tokenization: Baseball of your country ?\n",
            "Sentence before tokenization: That is why I did not log in for such a long time .\n",
            "Sentence before tokenization: A telephone ring in the room told us the end of the day .\n",
            "Sentence before tokenization: Hello everyone !\n",
            "Sentence before tokenization: A or Australia , I would learn English lot\n",
            "Sentence before tokenization: so my sisters and me went to her place and sent the mooncakes to her and wish her happy festivals !\n",
            "Sentence before tokenization: My wife did not like it there at first , because the place is far from a station and she could not drive a car at the time .\n",
            "Sentence before tokenization: I probablly understand Past Perfect Continuous which I mentioned in the latest diary Thank you for everyone\n",
            "Sentence before tokenization: Make the material to talk with them .\n",
            "Sentence before tokenization: I think that the only way to learn a language for real is by using it with people who speak it every day . That is why I would really like to have some English and American friends who can help me to achieve my goal .\n",
            "Sentence before tokenization: Do you have any birthdays that you ca not forget ?\n",
            "Sentence before tokenization: hi ! !\n",
            "Sentence before tokenization: Stuff is going to come home tomorrow\n",
            "Sentence before tokenization: There was nothing to do today . Our multifunction test - bed was broken yesterday .\n",
            "Sentence before tokenization: I am going to take the TOEIC test on st December .\n",
            "Sentence before tokenization: For the reason that the police worked on Sunday .\n",
            "Sentence before tokenization: to the Earth .\n",
            "Sentence before tokenization: There was hardly any kerosene left in the tank .\n",
            "Sentence before tokenization: One day , Montague is only son Romeo was encouraged by friends to attend the fancy dress party held at the Caplet home .\n",
            "Sentence before tokenization: I have never brought an umbrella with me in London , a coat and a hat were more than enough since most of times rain was just lovely little spray drops , instead in Italy you have to cover yourself because rain here is really wet !\n",
            "Sentence before tokenization: It was so delicious ! !\n",
            "Sentence before tokenization: Sports is very important health maintenance .\n",
            "Sentence before tokenization: Her family members are very friendly and funny , they are happy together .\n",
            "Sentence before tokenization: Yesterday , I introduced you to a logical puzzle .\n",
            "Sentence before tokenization: Last night , I tossed and turned since I sneezed all the night .\n",
            "Sentence before tokenization: Trust me ! !\n",
            "Sentence before tokenization: Laba Rice Porridge Festival\n",
            "Sentence before tokenization: My Dream\n",
            "Sentence before tokenization: Thanks to that , my English grade became better .\n",
            "Sentence before tokenization: On the Pacific side and on the Sea of Japan side\n",
            "Sentence before tokenization: Why was not I get over soon ?\n",
            "Sentence before tokenization: I am in Australia to study English as an exchange student for a year .\n",
            "Sentence before tokenization: I do not like these wheather .\n",
            "Sentence before tokenization: You can learn rules .\n",
            "Sentence before tokenization: Help me .\n",
            "Sentence before tokenization: I am joining English Lunch , English class teachers and students have a chat over lunch at college .\n",
            "Sentence before tokenization: The Chairmanship or Participation in the Scientific and Academic Commissions or Collegiate Institutions .\n",
            "Sentence before tokenization: three - day weekend\n",
            "Sentence before tokenization: I ca not take a balance of private time and working .\n",
            "Sentence before tokenization: Hope you have a nice weekend .\n",
            "Sentence before tokenization: They often use the word ' reckon ' for ' think ' .\n",
            "Sentence before tokenization: Ideal Home\n",
            "Sentence before tokenization: What should I do ?\n",
            "Sentence before tokenization: In those days all I wanted was just to know a few words so that to say just a few sentences in class .\n",
            "Sentence before tokenization: But yesterday , when I had the th class , I found our class was getting interesting .\n",
            "Sentence before tokenization: Next I used some kitchen towels to wipe it off the window completely .\n",
            "Sentence before tokenization: but for me it is really cool .\n",
            "Sentence before tokenization: But today , I could not stay focused on studying .\n",
            "Sentence before tokenization: After swimming , I got sunburned .\n",
            "Sentence before tokenization: Is this a wrong answer ?\n",
            "Sentence before tokenization: If you do not mind , could you exchange e - mail with me ?\n",
            "Sentence before tokenization: The other day , I went to the camera shop to apply for my passport .\n",
            "Sentence before tokenization: First of all\n",
            "Sentence before tokenization: I wish we have cool summer in this year .\n",
            "Sentence before tokenization: This is Homecoming for all luminous beings .\n",
            "Sentence before tokenization: I am a little sentimental .\n",
            "Sentence before tokenization: I did not skip out on the learning English .\n",
            "Sentence before tokenization: Because of that , it seemed like my current boss evaluated me only for the period of working with him .\n",
            "Sentence before tokenization: Should I use decrease instead of get low ?\n",
            "Sentence before tokenization: Question o you agree or disagree with the following statement ?\n",
            "Sentence before tokenization: This homework is difficult to me .\n",
            "Sentence before tokenization: He felt good .\n",
            "Sentence before tokenization: I get transferred every three or four years .\n",
            "Sentence before tokenization: The culture is very dynamic .\n",
            "Sentence before tokenization: Now the biggest dangers are the effects of nuclear plants and a few foods !\n",
            "Sentence before tokenization: However , after I watched it , the impression changed totally .\n",
            "Sentence before tokenization: In her opinion , Americans today are worried about the economy and children .\n",
            "Sentence before tokenization: They were friends of my daughter is who live in same apartment .\n",
            "Sentence before tokenization: This movie has CG and is dubbed in some parts , so I chose the movie .\n",
            "Sentence before tokenization: It is a rainy day in Tokyo .\n",
            "Sentence before tokenization: Anyway this is a first time my horse become a breeding horse , today is a happy day .\n",
            "Sentence before tokenization: Please say to me good luck miiya ! ! ! or take it easy miiya ! ! !\n",
            "Sentence before tokenization: Small talk from neighbours is also interesting for me .\n",
            "Sentence before tokenization: I was repentant for falling in love .\n",
            "Sentence before tokenization: our internal communication language from Japanese to English .\n",
            "Sentence before tokenization: A book on articles gives an example , \n",
            "Sentence before tokenization: I watched TV shows , and slept .\n",
            "Sentence before tokenization: Concerning the latter half , I want to know if the following phrases are correct wrong not good for it .\n",
            "Sentence before tokenization: I want to write about my father later again .\n",
            "Sentence before tokenization: Give it a try\n",
            "Sentence before tokenization: So I buy them a lot .\n",
            "Sentence before tokenization: I am a student at a language school in the USA .\n",
            "Sentence before tokenization: Currently , Tokyo has fair weather , and they say the typhoon will come to Tokyo this week .\n",
            "Sentence before tokenization: So it occurs that going - abroad students did nt acquire knowledge .\n",
            "Sentence before tokenization: but my weight still remains to be the same .\n",
            "Sentence before tokenization: I was messed up for a long time .\n",
            "Sentence before tokenization: This is a serious problem for the country with a labor shortage .\n",
            "Sentence before tokenization: As I have been there several times , I went on this trip for my friendscompanionship rather than the trip itself .\n",
            "Sentence before tokenization: I decided that I would go back to my parents ' house , which is not so far from my apartment , just inconveniently located .\n",
            "Sentence before tokenization: Hi I am a Japanese person .\n",
            "Sentence before tokenization: Please admit your country honestly , nobody would despise you !\n",
            "Sentence before tokenization: Does the sentence No . imply she actually drive a car ?\n",
            "Sentence before tokenization: Anyway , it was a good experience .\n",
            "Sentence before tokenization: My daughter was born\n",
            "Sentence before tokenization: I just saw a rat big like as a cow\n",
            "Sentence before tokenization: Anyway , that point is not what I want to mention in this post .\n",
            "Sentence before tokenization: Or any other style become popular ?\n",
            "Sentence before tokenization: B Sure .\n",
            "Sentence before tokenization: The primary reason of this entry I wrote is due to an interview for seeking employment last two weeks ago .\n",
            "Sentence before tokenization: And I am doing an experiment .\n",
            "Sentence before tokenization:  If you have eaten that , you will plump . , I said while laughing .\n",
            "Sentence before tokenization: I wish I want to have next chance to go museum .\n",
            "Sentence before tokenization: Today is hot , too .\n",
            "Sentence before tokenization: I will decide which school I will go to after this visit .\n",
            "Sentence before tokenization: At school , work , home , family , community , \n",
            "Sentence before tokenization: When did you meet him where ?\n",
            "Sentence before tokenization: Gas tax double taxation and contradicted Tonnage Tax .\n",
            "Sentence before tokenization: Their motivation gave me a good impression .\n",
            "Sentence before tokenization: Any comics have scenes that hero grow .\n",
            "Sentence before tokenization: Next I used some kitchen towel to wipe it off the window completely .\n",
            "Sentence before tokenization: Then why did such differences come to happen ?\n",
            "Sentence before tokenization: I am a university student and I study Law .\n",
            "Sentence before tokenization: every day .\n",
            "Sentence before tokenization: S Salesperson D enise\n",
            "Sentence before tokenization: The plan is drop .\n",
            "Sentence before tokenization: I do not want to do my homeworks again for today .\n",
            "Sentence before tokenization: That is what we do .\n",
            "Sentence before tokenization: Through this precious experience in the UK , I want to get an adequate grounding in English skills , which is necessary for English teachers .\n",
            "Sentence before tokenization: I tried to catch the wave .\n",
            "Sentence before tokenization: And finally Scarlett was moved by him .\n",
            "Sentence before tokenization: I have to brace up more .\n",
            "Sentence before tokenization: Good night !\n",
            "Sentence before tokenization: A meaning of the word I knew was pressure .\n",
            "Sentence before tokenization: I wonder if it is Japanese original , or do any countries have such a race ?\n",
            "Sentence before tokenization: So I lately see lots of movies at home daylight .\n",
            "Sentence before tokenization: The monster parent is an evil person who offends their child is school because of some false charge in Japan .\n",
            "Sentence before tokenization: But after a few days , we found out she had never had a boyfriend .\n",
            "Sentence before tokenization: I hope I persevere in this .\n",
            "Sentence before tokenization: It is attached at my mouth every class .\n",
            "Sentence before tokenization: My - line diary\n",
            "Sentence before tokenization: When I lie on the bed .\n",
            "Sentence before tokenization: So I am just relaxing in my room .\n",
            "Sentence before tokenization: Today , I ' d like to introduce an English proverb .\n",
            "Sentence before tokenization: I had written a bit more for this part , but I thought it was getting too long .\n",
            "Sentence before tokenization: I have my English class for minutes , \n",
            "Sentence before tokenization: My English instructor on that day was from France .\n",
            "Sentence before tokenization: A place where I live now did nt have big damage from earthquake .\n",
            "Sentence before tokenization: but , I like raining much more .\n",
            "Sentence before tokenization: Now I know that high school boys are childish and foolish , \n",
            "Sentence before tokenization: I am so sleepy now that my brain has turned to concrete . zzz\n",
            "Sentence before tokenization:  Anyway , it became rainy weather on the way so we wore our rainy coats riding on the bicycle .\n",
            "Sentence before tokenization: I was crying in concert listening songs , though my son did nt know about that .\n",
            "Sentence before tokenization: It is really bad .\n",
            "Sentence before tokenization: One Piece\n",
            "Sentence before tokenization: I could not write an entry because I got home at midnight .\n",
            "Sentence before tokenization: Then I hit my toe at his knee and got hurt myself .\n",
            "Sentence before tokenization: This drug store , they sell a variety of things , not only medicine but also snacks , cosme , dairy products and so on .\n",
            "Sentence before tokenization: It is .\n",
            "Sentence before tokenization: There are a lot of coffee shops in Japan , especially city part .\n",
            "Sentence before tokenization: I want to take the good point , so I study them hard !\n",
            "Sentence before tokenization: It is Basic Life Support , which is called BLS .\n",
            "Sentence before tokenization: his students , how a teacher leads his students to seek out methods of study .\n",
            "Sentence before tokenization: Then I realized there are so many Mother Goose in novels and movies .\n",
            "Sentence before tokenization: Anyway , the midterm examination will start from this June nd .\n",
            "Sentence before tokenization: I want to sleep more more more .\n",
            "Sentence before tokenization: It is cold most recently .\n",
            "Sentence before tokenization: I read an article about Seok - min Yoon .\n",
            "Sentence before tokenization: I think I learned more than I taught , and one of the things I learned is how hard it can be to study English .\n",
            "Sentence before tokenization: Thank you for reading my daiary .\n",
            "Sentence before tokenization: I hope some one who get my gift of card are interested in unicef by my things .\n",
            "Sentence before tokenization: Which one is the more polite expression ?\n",
            "Sentence before tokenization: The clutch wire of the bike was snapped .\n",
            "Sentence before tokenization: Meanwhile , they are still learning how to face some subjects in their life .\n",
            "Sentence before tokenization: Hello everyone .\n",
            "Sentence before tokenization: Tell Me Someone\n",
            "Sentence before tokenization: He angried to death .\n",
            "Sentence before tokenization: Although , I ca nt travel so many times because I am student , but I like to travel .\n",
            "Sentence before tokenization: My pet\n",
            "Sentence before tokenization: I am writing this blog from my iPhone today .\n",
            "Sentence before tokenization: This price was only ! ! !\n",
            "Sentence before tokenization: I have a dream for them .\n",
            "Sentence before tokenization: I like it very much , and it is easy to make it .\n",
            "Sentence before tokenization: Where is this place ?\n",
            "Sentence before tokenization: Since then , he has never eaten hamburgers .\n",
            "Sentence before tokenization: Do you know Sakura flower ?\n",
            "Sentence before tokenization: Thank you for your reply and the articles .\n",
            "Sentence before tokenization: I went to my Chinese friends ' birthday party .\n",
            "Sentence before tokenization: I was really surprised by the potential we had and how strong we are when working as a team .\n",
            "Sentence before tokenization: If you want to get the same results with less push ups as you would if you did them or times , you have to have your hands at about neck width .\n",
            "Sentence before tokenization: In last month my work was so hard for me .\n",
            "Sentence before tokenization: It is in Japan .\n",
            "Sentence before tokenization: Thank you so much for your help !\n",
            "Sentence before tokenization: I was taking heavy luggage , \n",
            "Sentence before tokenization: six , Both of us did not take any house key .\n",
            "Sentence before tokenization: Things are always be what they ought to be , it wo not change cause of your worry , god works .\n",
            "Sentence before tokenization: I guess my Jewish friend has been talking about me to her .\n",
            "Sentence before tokenization: The most obvious one is promoting international trade .\n",
            "Sentence before tokenization: Can I calm down for couples of minutes ?\n",
            "Sentence before tokenization: But it also showed the world is coming to an end by .\n",
            "Sentence before tokenization: Today , Idrank beer cups .\n",
            "Sentence before tokenization: So I spend most of my time at home .\n",
            "Sentence before tokenization: My favorite artists are Sum , the Offspring , Zebra Head , and School Boy Humor .\n",
            "Sentence before tokenization: Buck is a strong , smart dog .\n",
            "Sentence before tokenization: Thank you for your help !\n",
            "Sentence before tokenization: Many types of the people were created in this world .\n",
            "Sentence before tokenization: Big Earthquake in China\n",
            "Sentence before tokenization: In other words , only to read e - books , we can contribute to environmental protection .\n",
            "Sentence before tokenization: That is the low of salaryman .\n",
            "Sentence before tokenization: both of them train so hard , \n",
            "Sentence before tokenization: but the earthquake is still going on .\n",
            "Sentence before tokenization: They are the same , because they are living things , too .\n",
            "Sentence before tokenization: Some friends asked me what had happened and what made me cut my hair , and I answered that I was broken - hearted .\n",
            "Sentence before tokenization: I am perplexed now , Since I do not know how to surpass myself .\n",
            "Sentence before tokenization: This is my first diary .\n",
            "Sentence before tokenization: I received a mail from my team member of my previous office .\n",
            "Sentence before tokenization: So I was looking forward to going to a dog race again .\n",
            "Sentence before tokenization: I was a little embarrassed because I could not notice that .\n",
            "Sentence before tokenization: Anyway , I drank too much \n",
            "Sentence before tokenization: The cool part was the artist spelled it Spoony .\n",
            "Sentence before tokenization: To tell the truth I have worked in a super market , \n",
            "Sentence before tokenization: But it is actually just the fact of worshiping invisible forces that are said to inhabit nature .\n",
            "Sentence before tokenization: Now , I have three extra Windows and no one wants to buy them from me because they know they can get a student discount .\n",
            "Sentence before tokenization: Anyhow , please enjoy the song .\n",
            "Sentence before tokenization: I used my brains too much .\n",
            "Sentence before tokenization: Do not take it seriously .\n",
            "Sentence before tokenization: Because I am a little tired , I will take a break .\n",
            "Sentence before tokenization: I know right ?\n",
            "Sentence before tokenization: Now it is December .\n",
            "Sentence before tokenization: I miss Minnesota .\n",
            "Sentence before tokenization: I eat all the food is very good .\n",
            "Sentence before tokenization: I fear my disease got worse because of taking unusual actions .\n",
            "Sentence before tokenization: I am unbelievable and where do my feelings go now ?\n",
            "Sentence before tokenization: G Yes\n",
            "Sentence before tokenization: I love this site , and I want to make friends through this way .\n",
            "Sentence before tokenization: There are cream - filled pastries .\n",
            "Sentence before tokenization: He said we shoud cancel to go to sea .\n",
            "Sentence before tokenization: Of course it was a Japanese edition .\n",
            "Sentence before tokenization: On balance , when it comes to luxuries and conveniences in life , we have to think twice before voting for or against their functions .\n",
            "Sentence before tokenization: After the goal of the marathon , we went to a hot spa and enjoyed it .\n",
            "Sentence before tokenization: I enjoyed music very much , while I was preparing a Sunday breakfast .\n",
            "Sentence before tokenization: So we went to futon soon .\n",
            "Sentence before tokenization: It was very difficult .\n",
            "Sentence before tokenization: I took loads of pictures in Canada and NY , so the website is helpful to me ! ! !\n",
            "Sentence before tokenization: I do not have any more space in the May frame , but yesterday , one girl who was born in May came and she said she wanted to enter the class .\n",
            "Sentence before tokenization: If you find any error in words , grammar or logic , please correct it .\n",
            "Sentence before tokenization: This is a DVD for shadowing .\n",
            "Sentence before tokenization: Tony Blair\n",
            "Sentence before tokenization: I teach math , arithmetic , science and Japanese to the students from elementary school to high school .\n",
            "Sentence before tokenization: Now I want to tell you guys my ' weird dream ' I had a few days ago .\n",
            "Sentence before tokenization: I think it s difficult to have a habit , and come here to write every day .\n",
            "Sentence before tokenization: Please tell him I can not come at pm at Gate .\n",
            "Sentence before tokenization: so I am trying to be a more intelligent , smart person\n",
            "Sentence before tokenization: This is a very convenient expression , but I do nt think there is a Japanese counterpart .\n",
            "Sentence before tokenization: Before going to the Philippines , I am going to stay in Singapore for days to sightsee the one of the most famous attractive country in the world .\n",
            "Sentence before tokenization: Mac is .\n",
            "Sentence before tokenization: She said you have forgotten your driver is license .\n",
            "Sentence before tokenization: I m not sure if it is useful or not .\n",
            "Sentence before tokenization: This will give me the power to study from tomorrow .\n",
            "Sentence before tokenization: They were lighthearted but a little pushy to Japanese .\n",
            "Sentence before tokenization: This is the first time .\n",
            "Sentence before tokenization: Dear Sir or Madam , \n",
            "Sentence before tokenization: Please tell me how to learn English best .\n",
            "Sentence before tokenization: I want to look on the next .\n",
            "Sentence before tokenization: Mt , Aso is the national Park and natuer is very beautiful .\n",
            "Sentence before tokenization: Today , I modeled for my older sister .\n",
            "Sentence before tokenization: I am Aki .\n",
            "Sentence before tokenization: I am back\n",
            "Sentence before tokenization: The new - born person registers\n",
            "Sentence before tokenization: I end up intermediate examination but it still go out homework .\n",
            "Sentence before tokenization: I love dogs !\n",
            "Sentence before tokenization: Without enough exercises , the function of our organs is likely to degenerate , which is the main cause of healthy issues .\n",
            "Sentence before tokenization: CONGRATULATION IS EQUIVALENT TO JOB\n",
            "Sentence before tokenization: I know that it can connect with a real space as architect in junior high school , and I was admitted to Department of Architecture , Chiba University .\n",
            "Sentence before tokenization: The nurse was really helpful .\n",
            "Sentence before tokenization: All you have to do is be less formal and reply even to negative comments - but not censor them .\n",
            "Sentence before tokenization: It is what it is similar to social network Facebook\n",
            "Sentence before tokenization: I am looking forward to seeing the new Harry Potter movie .\n",
            "Sentence before tokenization: I love my mom , but I never say I love you to her , because I think love should be in the heart , not in the words .\n",
            "Sentence before tokenization: Today I cooked french fries .\n",
            "Sentence before tokenization: My English skill is not good , so please tell me if my English is not good .\n",
            "Sentence before tokenization: How should I do ?\n",
            "Sentence before tokenization: I just got back from work now .\n",
            "Sentence before tokenization: First I worked as clerk in shopping center Westfield .\n",
            "Sentence before tokenization: In the program Japanese Sumo is booming at Tel Aviv of Israel is capital .\n",
            "Sentence before tokenization: How wonderful !\n",
            "Sentence before tokenization: That is a kind of how to say thank you .\n",
            "Sentence before tokenization: I am not opposite that good and moderate scale processes or policies are necessary for doing a safe and effective business .\n",
            "Sentence before tokenization: I finished all of my work for this weekdays .\n",
            "Sentence before tokenization: I decided to eat in tonight .\n",
            "Sentence before tokenization: It is much more difficult to say what I want to immediately in English than I had expected .\n",
            "Sentence before tokenization: Many research studies have been carried out on this topic .\n",
            "Sentence before tokenization: One boy told us If I were rich , I would give all the street children food , clothes , medicine , shelter , love . If a child on the street has nothing but is willing to share , why are we who have everything still so greedy ?\n",
            "Sentence before tokenization: I imagined how fun it would be to play these puppets with my daughter , although she is still two months old .\n",
            "Sentence before tokenization: Anyway , I am very proud of all of you !\n",
            "Sentence before tokenization: Words my mother said to me in the morning\n",
            "Sentence before tokenization: I was really inspired by people , fashion , and a feeling like something was going to happen here during my visit to NY last year .\n",
            "Sentence before tokenization: Take a bath soon !\n",
            "Sentence before tokenization: Meeting them and talking with them give me knowledge of the campus .\n",
            "Sentence before tokenization: Am I too naive or too ignorant ?\n",
            "Sentence before tokenization: I would like to learn English and also learn how to teach Japanese in English .\n",
            "Sentence before tokenization: - Based on life histories of Chinese women living in Tokyo and Yokohama in Japan\n",
            "Sentence before tokenization: Economics is needed to some maths knowledge .\n",
            "Sentence before tokenization: To tell the truth , I usually study and work to prepare for my plans .\n",
            "Sentence before tokenization: Human beings have polluted the environment seriously .\n",
            "Sentence before tokenization: Sometimes they neglect work and school .\n",
            "Sentence before tokenization: It was impressive concert .\n",
            "Sentence before tokenization: Some of my friends said that English is easier than German , and they are German , too !\n",
            "Sentence before tokenization: So I want to try to write what I think .\n",
            "Sentence before tokenization: Does this sound OK ?\n",
            "Sentence before tokenization: Restaurant is a temple , and food is an object of art .\n",
            "Sentence before tokenization: My weekend\n",
            "Sentence before tokenization: This friday the chinese and international students culture exchange\n",
            "Sentence before tokenization: I am going to continue to study English ! !\n",
            "Sentence before tokenization: tennis match\n",
            "Sentence before tokenization: We started work in the same year .\n",
            "Sentence before tokenization: I said to my teacher that I would left my sheet music at home , but it did not work \n",
            "Sentence before tokenization: Actually , I had decided to go to Sri Lanka in Nov .\n",
            "Sentence before tokenization: This is my essay for the interview .\n",
            "Sentence before tokenization: I watched a variety show .\n",
            "Sentence before tokenization: so very uplifting to see their dance\n",
            "Sentence before tokenization: I do like his works .\n",
            "Sentence before tokenization: Factory Study Tour TWO\n",
            "Sentence before tokenization: This song is so beautiful melody !\n",
            "Sentence before tokenization: Japanese plum flower is blooming\n",
            "Sentence before tokenization: It is a pleasure to see all of you .\n",
            "Sentence before tokenization: It is the role of the rich to extend help to someone who suffers from poverty .\n",
            "Sentence before tokenization: I mean on my birthday , just me , watching some movies , eating Oreos .\n",
            "Sentence before tokenization: Children profit .\n",
            "Sentence before tokenization: Sense of accomplishment\n",
            "Sentence before tokenization: That sounds like a lot of fun .\n",
            "Sentence before tokenization: I suppose there are several reasons why I failed in studying my English skill by myself .\n",
            "Sentence before tokenization: It may show that I have still been affected by the fluctuating weather so far .\n",
            "Sentence before tokenization: Eco Blue gill\n",
            "Sentence before tokenization: Commuting first day\n",
            "Sentence before tokenization: Hello everybody\n",
            "Sentence before tokenization: Paper is out !\n",
            "Sentence before tokenization: I hope I can learn more correct Enlish form here .\n",
            "Sentence before tokenization: Usually , east asian peoples look like young .\n",
            "Sentence before tokenization: I will be creating two videos .\n",
            "Sentence before tokenization: I just like it .\n",
            "Sentence before tokenization: I would like to describe it is flavour is similar to milk and soda\n",
            "Sentence before tokenization: That is all .\n",
            "Sentence before tokenization: Because other people said I am getting better and better .\n",
            "Sentence before tokenization: To be sure , I do not think that only five months make me speak English .\n",
            "Sentence before tokenization: But how can I do that ?\n",
            "Sentence before tokenization: I read an economist is opinion in a paper that said Big companies should set up a day - care center for children . The same paper said Itochu , a famous trading company , set up the day - care center .\n",
            "Sentence before tokenization: I feel that I really lucky have such a great boarding house is friend like them .\n",
            "Sentence before tokenization: Nevertheless , student health center does not have enough space room for treatment .\n",
            "Sentence before tokenization: As I am not young , I could not be running for a long time .\n",
            "Sentence before tokenization: And I ate baked chickens while I was drinking alcohol .\n",
            "Sentence before tokenization: But I could not recognise the difference in their accents .\n",
            "Sentence before tokenization: She wrote a today entry in Korean .\n",
            "Sentence before tokenization: Having read the book so anything that I would gradually like to see my hero doenmoseupeul .\n",
            "Sentence before tokenization: Western man needed Eastern girl to stay alone and have space with him .\n",
            "Sentence before tokenization: In the past , I saw this movie and read it in Japanese , but now it is paperback .\n",
            "Sentence before tokenization: We will be back in NY on the th .\n",
            "Sentence before tokenization: Once I see such a picture telling power of nature , I kind of feel we humanbeings have to protect nature even though I do not say such a stuff .\n",
            "Sentence before tokenization: To sum up , I would like to study applied statistics in America after getting my Ph .\n",
            "Sentence before tokenization: Oh God , no more stress to me , ok ?\n",
            "Sentence before tokenization: It was the same DVD as I had watched two months ago .\n",
            "Sentence before tokenization: I drew a wallet out of my pocket and put it on the rack .\n",
            "Sentence before tokenization: The Japanese government is starting a new business style , super cool biz .\n",
            "Sentence before tokenization: I saw his figure running in the night through the window .\n",
            "Sentence before tokenization: everything is ok !\n",
            "Sentence before tokenization: It is o ' clock now .\n",
            "Sentence before tokenization: Yesterday new refrigeator came to my house !\n",
            "Sentence before tokenization: Anyway , they would appeal to Japanese people sooner or later .\n",
            "Sentence before tokenization: How do you say this in English ?\n",
            "Sentence before tokenization: It is very simple to cook .\n",
            "Sentence before tokenization: Like Exhausted Sumo Wrestlers\n",
            "Sentence before tokenization: I am still child .\n",
            "Sentence before tokenization: Your reply to my nd .\n",
            "Sentence before tokenization: Respects help us to support good relations with our friends and family .\n",
            "Sentence before tokenization: I went to bed at and I woke up at the next day !\n",
            "Sentence before tokenization: Now I do not need wear glasses , wash contact lenses , or buy lense - care stuff .\n",
            "Sentence before tokenization: I watched TV shows , and slept .\n",
            "Sentence before tokenization: I drew a winning number for the participation a long time ago .\n",
            "Sentence before tokenization: I am going to a live on Saturday .\n",
            "Sentence before tokenization: I bought a windbreaker at Sports Authority which is near my house .\n",
            "Sentence before tokenization: so I am not comfortable with my English little .\n",
            "Sentence before tokenization: I can easily receive other is .\n",
            "Sentence before tokenization: I was glad to hear that .\n",
            "Sentence before tokenization: Today , I want to write about my hobby overseas travel .\n",
            "Sentence before tokenization: but we do not want to spend so much money .\n",
            "Sentence before tokenization: tacos is famous in Okinawa .\n",
            "Sentence before tokenization: I have not been there , so I want to go .\n",
            "Sentence before tokenization: Anyways , I had got tired so much on reaching home .\n",
            "Sentence before tokenization: I apologised to them .\n",
            "Sentence before tokenization: She said in the video , such as , like the one where I am like , mmm . There was another one where I was like , Mmm . And then there was the one where I held up a sign .\n",
            "Sentence before tokenization: But , that day , it was the first day of a year .\n",
            "Sentence before tokenization: Indiscriminate murder\n",
            "Sentence before tokenization: Recentry , Tokyo is fair wether , and they say the typhoon come to Tokyo this week .\n",
            "Sentence before tokenization: But I could not recognise the difference of their accent .\n",
            "Sentence before tokenization: Have a nice holiday ! !\n",
            "Sentence before tokenization: Google has launched a new payment system that allows users to subscribe to online content for a commission fee .\n",
            "Sentence before tokenization: He is my hero .\n",
            "Sentence before tokenization: I want to see that face this year too .\n",
            "Sentence before tokenization: So my wife prepared some food .\n",
            "Sentence before tokenization: The kites fight each other in the sky and the losers fall .\n",
            "Sentence before tokenization: the parents complained about unclearness of imparting .\n",
            "Sentence before tokenization: Today is Easter\n",
            "Sentence before tokenization:  You ca not do without it , right ?\n",
            "Sentence before tokenization: I have just called to Japan and .\n",
            "Sentence before tokenization: I am a designer of appliances .\n",
            "Sentence before tokenization: Yesterday I found out some shocked truth from him .\n",
            "Sentence before tokenization: If I earn enough money , I also want to leave this county .\n",
            "Sentence before tokenization: I still feel awful today .\n",
            "Sentence before tokenization: I am sorry , but I am looking forward to the next Skype .\n",
            "Sentence before tokenization: They enjoyed talking in English , and laugh many times .\n",
            "Sentence before tokenization: I am listening to a song which is about a couple .\n",
            "Sentence before tokenization: Hello , my friends .\n",
            "Sentence before tokenization: I do not know exactly when Chinese characters came to Korea .\n",
            "Sentence before tokenization: My reading skill is very well , but I can not do writing in English .\n",
            "Sentence before tokenization: This can be seen in many aspects of society , such as the political system , traffic regulations , language and so on .\n",
            "Sentence before tokenization: JFK museum\n",
            "Sentence before tokenization: I took a photo which they jumped at the church .\n",
            "Sentence before tokenization: I think that , of course , if I try hard day by day , I will make my dream come true .\n",
            "Sentence before tokenization: But sometimes I can not follow cultural diffrences between holland and Japan , especially being naked in public such as a street and a park .\n",
            "Sentence before tokenization: Today I had a bad and a good thing .\n",
            "Sentence before tokenization: I was very relaxed .\n",
            "Sentence before tokenization: I joined the tennis club at junior high school and high school .\n",
            "Sentence before tokenization: And I ca not speak English fluently like other students but I want to give a good speech someday .\n",
            "Sentence before tokenization: In addition , recently some mama bicycle have a head guard on the front basket , its head guard can be adjusted flexibelly according to the growth level of the children .\n",
            "Sentence before tokenization: I am years old and I have a wife and a daughter who is year old .\n",
            "Sentence before tokenization: And the future looks brighter .\n",
            "Sentence before tokenization: But , if I have any English skills , eventually it will be a good thing for me .\n",
            "Sentence before tokenization: When I signed the contract to buy the car , I was very happy and just looking forward to driving that new car .\n",
            "Sentence before tokenization: I put him next to Jack .\n",
            "Sentence before tokenization: I think I am still a beginner speaking English even though I have almost studied English for a year here in Toronto .\n",
            "Sentence before tokenization: I like also fashion .\n",
            "Sentence before tokenization: I will be a sophomore in high school ! ?\n",
            "Sentence before tokenization: I will start as quickly as possible , maybe about this July .\n",
            "Sentence before tokenization: Wow what a big difference !\n",
            "Sentence before tokenization: Ask for my advice , my friend .\n",
            "Sentence before tokenization: Am I right about these understandings ?\n",
            "Sentence before tokenization: It was so delicious ! !\n",
            "Sentence before tokenization: After many days .\n",
            "Sentence before tokenization: I have not visited it before , but I really would like to .\n",
            "Sentence before tokenization: Indian scholar\n",
            "Sentence before tokenization: Becoming a little fat .\n",
            "Sentence before tokenization: They have a great job and friends .\n",
            "Sentence before tokenization: For example The animation South park It is an animation of full of bad languages .\n",
            "Sentence before tokenization: In addition , I like Chet Baker is saxophone performance .\n",
            "Sentence before tokenization: But it was not tomato !\n",
            "Sentence before tokenization: this is in danger .\n",
            "Sentence before tokenization: I belong to a ballroom dancing club .\n",
            "Sentence before tokenization: I was very glad for her sudden call .\n",
            "Sentence before tokenization: At this lesson , I got a lot of homework and had to remember them .\n",
            "Sentence before tokenization: The Nurse was really helphul .\n",
            "Sentence before tokenization: Last weekend I found a great possibility to use them .\n",
            "Sentence before tokenization: But some foreigners are studying Japanese in cocone .\n",
            "Sentence before tokenization: They are a blues - rock band .\n",
            "Sentence before tokenization: It is in Russia .\n",
            "Sentence before tokenization: As I yearned to read any Japanese text , I took advantage of the Internet .\n",
            "Sentence before tokenization: I will go to Bankok in Thailand in March with my friends .\n",
            "Sentence before tokenization: I feel as if I have to take action now , or otherwise , it will be too late .\n",
            "Sentence before tokenization: I need more courage !\n",
            "Sentence before tokenization: Cultural Differences , again ?\n",
            "Sentence before tokenization: Today I missed the bus , so I was walking for minutes to go to the closest shop from my school .\n",
            "Sentence before tokenization: I wonder why many people are interested in watching movies .\n",
            "Sentence before tokenization: I just ca not get enough coffee .\n",
            "Sentence before tokenization: Today Chiba city area has heavy rain .\n",
            "Sentence before tokenization: This url below is about the article .\n",
            "Sentence before tokenization: He was very kind and always talked to me with a face full of smiles .\n",
            "Sentence before tokenization: If anyone have watched the anime , please leave a comment and discuss !\n",
            "Sentence before tokenization: Till next time .\n",
            "Sentence before tokenization: Word like diamond , love and paradise were considered happy .\n",
            "Sentence before tokenization: Do you like mathematics ?\n",
            "Sentence before tokenization: I drew two paintings every day .\n",
            "Sentence before tokenization: My plan is to take one more part time job .\n",
            "Sentence before tokenization: So Japan must learn it from the foreigners and should look up to them .\n",
            "Sentence before tokenization: I feel sad .\n",
            "Sentence before tokenization: I have a lot of free time on Sundays .\n",
            "Sentence before tokenization: I hope the weather clears up .\n",
            "Sentence before tokenization: I want to exchange the product due to damage .\n",
            "Sentence before tokenization: I live in Tokyo , Japan .\n",
            "Sentence before tokenization: I also have volume and of the series .\n",
            "Sentence before tokenization: Whatever your dream is - study abroad , work in another culture , communicate with friends from other countries - it will come true with your little but continuous effort .\n",
            "Sentence before tokenization: I like music like a Rock band .\n",
            "Sentence before tokenization: I have a LIGHT LAN which actual speed is mega for sec .\n",
            "Sentence before tokenization: More soft music , even songs from my parents ' years come often on my CD player - perhaps I am really getting old and being nostalgic \n",
            "Sentence before tokenization: True A makeshift .\n",
            "Sentence before tokenization: Moreover they speak very fast .\n",
            "Sentence before tokenization: my heart fluttered with excitement .\n",
            "Sentence before tokenization: Soup curry is the newest country dishes .\n",
            "Sentence before tokenization: It is the second last movie of HARRY POTTERs .\n",
            "Sentence before tokenization: I walk to work with an umbrella even if it rains heavily , \n",
            "Sentence before tokenization: My job is call center operator which is home electrical repair .\n",
            "Sentence before tokenization: I am lazy .\n",
            "Sentence before tokenization: The first one was the biggest .\n",
            "Sentence before tokenization: The mind of one is own was not bent .\n",
            "Sentence before tokenization: I need help .\n",
            "Sentence before tokenization: For five years , the children did everything themselves .\n",
            "Sentence before tokenization: The mother would take a piece of cake and a cup of tea or things like that to me .\n",
            "Sentence before tokenization: No one had a job as poet or author before pushkin .\n",
            "Sentence before tokenization: It is midnight in Japan now .\n",
            "Sentence before tokenization: I still use English - Japanese dictionaries instead of monolingual ones for most expertises in classes I am taking because what is important for those words is how clearly they are defined , not how they are used in context .\n",
            "Sentence before tokenization: i want to practice my oral english , can you help me ? and also , with great honor , i would love to practice chinese with you , i wish we could help each other and there will be a win - win result .\n",
            "Sentence before tokenization: You need to start from the point of departure , to make important decisions to go to the top of the career which you really look forward to .\n",
            "Sentence before tokenization: In Japan , more and more people are starting it .\n",
            "Sentence before tokenization: In school , I am not a good student and also I am not a bad student .\n",
            "Sentence before tokenization: Going through the United States to arrive at Narita Airport , please .\n",
            "Sentence before tokenization: president can nominate the Supreme Court justice .\n",
            "Sentence before tokenization: It is difficult to choice the dairy topic .\n",
            "Sentence before tokenization: Japan is national team won last night .\n",
            "Sentence before tokenization: In my country there are many Internet users and more mobile - phone subscribers .\n",
            "Sentence before tokenization: I have never done ' teaching ' in English , so I am not sure if I can pull it off so easily .\n",
            "Sentence before tokenization: When I am sleeping , wrapped up in my fluffy warm blanket , I feel as if I am in heaven .\n",
            "Sentence before tokenization: We can do nothing but to show our anger on the web in order to force the courts to punish the perpetrator .\n",
            "Sentence before tokenization: but they do not sell rabbit .\n",
            "Sentence before tokenization: I think this is the reason why I m keen on swimming .\n",
            "Sentence before tokenization: I am sorry about renew my dialy .\n",
            "Sentence before tokenization: Elephants and hippopotamus also had a tremendous impact .\n",
            "Sentence before tokenization: Stay tuned - perhaps I will try to translate something else\n",
            "Sentence before tokenization: I worry about the interviews I will take at a company because I do not have any experience that shows I have learned or succeeded in something .\n",
            "Sentence before tokenization: After a bath , she gives Popo a cup of tea . \n",
            "Sentence before tokenization: I helped her for the sake of my owing .\n",
            "Sentence before tokenization: During the dinner i chatted with my friends , my seniors and\n",
            "Sentence before tokenization: How should I say ?\n",
            "Sentence before tokenization: Oh my god .\n",
            "Sentence before tokenization: This article gives you a brief introduction to one of the sections in the JLPT test - the kanji and vocabulary section .\n",
            "Sentence before tokenization: so I love that store .\n",
            "Sentence before tokenization: In the European and American traditions , the husband always presents a precious ring to his wife on each wedding anniversary .\n",
            "Sentence before tokenization: My father bought a new TV .\n",
            "Sentence before tokenization: I can give you many good examples of our heroes in history .\n",
            "Sentence before tokenization: She allowed me to go to play a baseball with my freinds , though I could not play the piano well .\n",
            "Sentence before tokenization: And there are actually some rhythm patterns when I hit the keyboard .\n",
            "Sentence before tokenization: My former grammar school teacher wrote an e - mail to me .\n",
            "Sentence before tokenization: While we were chatting , I strongly felt that I need to study English more .\n",
            "Sentence before tokenization: So , this time I carried out the stage setting .\n",
            "Sentence before tokenization: For example , if you want to study about Japanese culture , you only need to use google search tool and type the keyword Japanese culture and then you can learn by yourself .\n",
            "Sentence before tokenization: The first time , it was easy ! ! !\n",
            "Sentence before tokenization: Jazz class\n",
            "Sentence before tokenization: I definitely think that they would have disadvantages .\n",
            "Sentence before tokenization: His birthday is November fifteenth .\n",
            "Sentence before tokenization: Though , I am not there with you guys .\n",
            "Sentence before tokenization: But five minutes later , I became very unhappy .\n",
            "Sentence before tokenization: I want to improve my English .\n",
            "Sentence before tokenization: I like to think about my clothoing .\n",
            "Sentence before tokenization: it make me a back pain .\n",
            "Sentence before tokenization: Anyway , It made me feel sorry for him .\n",
            "Sentence before tokenization: It is a coincidence that his family name is the same as mine .\n",
            "Sentence before tokenization: My - year - daughter said that she wanted to do ice skating , I knew that it was impossible for a three year old child , but I let her challenge .\n",
            "Sentence before tokenization: Am i selfish ?\n",
            "Sentence before tokenization: Which is more important , school learning or domestic learning ?\n",
            "Sentence before tokenization:  recession noun for economics , a period of an economic contraction\n",
            "Sentence before tokenization: Are you believed ?\n",
            "Sentence before tokenization: However I do nt know well about them .\n",
            "Sentence before tokenization: The problem with travel advisory is the credibility and freshness of the information .\n",
            "Sentence before tokenization: I tend to do my best even if my English is poor .\n",
            "Sentence before tokenization: It is rain today .\n",
            "Sentence before tokenization: But since the canned motor is rotor was covered by a can which directly connect to the pump is vacuum chamber , it is no need to seal the shaft , and it has high airtigtness .\n",
            "Sentence before tokenization: Although , I ate all of them which was just opened while drinking beer .\n",
            "Sentence before tokenization: However , the lesson is mainly to speak and to listen .\n",
            "Sentence before tokenization: And those who do become famous often find they want to wake up from lives that are less than dreamlike .\n",
            "Sentence before tokenization: Today I will also set up a group conversation for my best friend Zac .\n",
            "Sentence before tokenization: Now it is my favorite new toy .\n",
            "Sentence before tokenization: But before climbing I did not know the height of Mt .\n",
            "Sentence before tokenization: If there were someone out there , I would be very happy .\n",
            "Sentence before tokenization: So I looked up much about pimples on the internet .\n",
            "Sentence before tokenization: I am the new one in lang - .\n",
            "Sentence before tokenization: while they are still students .\n",
            "Sentence before tokenization: I know many English words , but I do not occur when I talk to\n",
            "Sentence before tokenization: I download how to make doughnut pillow , face mask , hair mask , and lot of handycratings .\n",
            "Sentence before tokenization: So now I have good sight .\n",
            "Sentence before tokenization: It is The family way , written by Tony Peasons .\n",
            "Sentence before tokenization: Bob hate shopping\n",
            "Sentence before tokenization: It is too expensive .\n",
            "Sentence before tokenization: Is that a way to show some kind of unconformity with the days we are living ?\n",
            "Sentence before tokenization: Done the TOEIC test\n",
            "Sentence before tokenization: My Dad felt sorry and took up feeding her .\n",
            "Sentence before tokenization: I do not know if the English language education in Japan is good , but it is not so easy to seek out the best way to teach English to Japanese children .\n",
            "Sentence before tokenization: Hold me tightly should be used ?\n",
            "Sentence before tokenization: But he could not ask the old man to give it back or steal it from the old man .\n",
            "Sentence before tokenization: Let is get started studying English again !\n",
            "Sentence before tokenization: I am not an easy - going girl since I have not known all of them .\n",
            "Sentence before tokenization: There was a trampoline .\n",
            "Sentence before tokenization: Afternoon , I read a comic and played with Miguel .\n",
            "Sentence before tokenization: I want to write about boyfriend today .\n",
            "Sentence before tokenization: What do you think ?\n",
            "Sentence before tokenization: How to\n",
            "Sentence before tokenization: Please connect with me ! !\n",
            "Sentence before tokenization: Contrary to their attempt to show their strong attitude , I notice they need to offend others to hold their self - esteem , thus they depend on external factors , as offending others is often seen as a sign of insecurity or low self - esteem .\n",
            "Sentence before tokenization: This article gives you a brief introduction of one of the sections in the JLPT test - the kanji and vocabulary section .\n",
            "Sentence before tokenization: The entomologist tried to run away from the place at first , but he was gradually getting accustomed to the oppressive situation .\n",
            "Sentence before tokenization: All I could do was to go to bed and sleep for the whole day .\n",
            "Sentence before tokenization: But I guess it was my daughter who gave the best present to my parents .\n",
            "Sentence before tokenization: Here is a new story for today .\n",
            "Sentence before tokenization: I just watch .\n",
            "Sentence before tokenization: I visited the hospital to see her .\n",
            "Sentence before tokenization: It always makes me confused that English people look like they do not like to use umbrellas .\n",
            "Sentence before tokenization: I hope friends can help me .\n",
            "Sentence before tokenization: There is no one that I want to be prime minister .\n",
            "Sentence before tokenization: I keep to write essays in English for improving my English skills since I came to the US .\n",
            "Sentence before tokenization: I heard about Canadian Veterans ' Day from my friend .\n",
            "Sentence before tokenization: But I got a boyfriend .\n",
            "Sentence before tokenization: One of the advantages is easy to wash and dry their hair , so they can easier keep clean their head than the people who has long hair .\n",
            "Sentence before tokenization: Have you ever thought that you would like to get married to a person who works as a model ?\n",
            "Sentence before tokenization: But education is interesting for me .\n",
            "Sentence before tokenization: Why this case occurred ?\n",
            "Sentence before tokenization: Kyoto is the place where I really recommend to visit ! !\n",
            "Sentence before tokenization: So it is my most unforgettable event in recent days .\n",
            "Sentence before tokenization: A mounting animal ?\n",
            "Sentence before tokenization: In the past , I saw this movie and read it in Japanese , but now it is paperback .\n",
            "Sentence before tokenization: After the class , I went to Tesco to buy some foods .\n",
            "Sentence before tokenization: Nice to meet you !\n",
            "Sentence before tokenization: This concert brought lots of surprise and marvel .\n",
            "Sentence before tokenization: Language Learning Websites Tools\n",
            "Sentence before tokenization: This shows the stationmaster at this station is a cat ! ! !\n",
            "Sentence before tokenization: I would like to go back again .\n",
            "Sentence before tokenization: Luck has nothing to do with success .\n",
            "Sentence before tokenization: It just makes me sick .\n",
            "Sentence before tokenization: Study abroad\n",
            "Sentence before tokenization: Once I told her I did not like the food in school .\n",
            "Sentence before tokenization: Today I went to childhood friend home .\n",
            "Sentence before tokenization: We play different piano pieces by turns .\n",
            "Sentence before tokenization: I want to do a lot of things .\n",
            "Sentence before tokenization: It is a tendency that Japan is economy has been shrinking .\n",
            "Sentence before tokenization: I am absolutely not sure about my English at all I would greatly appreciate it if you could tell me some major problems of your city from your point of view .\n",
            "Sentence before tokenization: CNN Japan Economy slips to third in world\n",
            "Sentence before tokenization: Stand beside I stood beside a special source in order to use it later .\n",
            "Sentence before tokenization: But I would like to just have a hope .\n",
            "Sentence before tokenization: She is my colleague , but she is a temporary employee .\n",
            "Sentence before tokenization: I am totally ashamed about your ugly face .\n",
            "Sentence before tokenization: Since James has to finish his term paper , FREE ca not find a colleague to act for her .\n",
            "Sentence before tokenization: I had sick for a half month\n",
            "Sentence before tokenization: So I think that they have a prejudice .\n",
            "Sentence before tokenization: I want to improve my english , beacuse it is not in a level that I want it to be .\n",
            "Sentence before tokenization: I went to the festival .\n",
            "Sentence before tokenization: Because other rhubarbs I have started were killed by terrible cold weather last winter .\n",
            "Sentence before tokenization: The a .\n",
            "Sentence before tokenization: Do you have an experience that when you read books or articles which are written in another language , you could not understand more than half ?\n",
            "Sentence before tokenization: A fellow in the suit\n",
            "Sentence before tokenization: Today I help my father to cook dinner , since I want him to find new hobby .\n",
            "Sentence before tokenization: I have only minutes !\n",
            "Sentence before tokenization: If the happyness and love is only saturation of the neurons phenyl - ethylamine .\n",
            "Sentence before tokenization: Thanks for reading\n",
            "Sentence before tokenization: I quit I go to buy bikini ! '\n",
            "Sentence before tokenization: I saw this drama on TV and read this novel when I was young .\n",
            "Sentence before tokenization: I did not study photography , even had no DC .\n",
            "Sentence before tokenization: Some women were having a chat and laughing .\n",
            "Sentence before tokenization: Especially this month is .\n",
            "Sentence before tokenization: Honda said that he would go to Tokyo or something .\n",
            "Sentence before tokenization: It is sad not to be able to speak English and Korean though a lot of foreign dramas are seen .\n",
            "Sentence before tokenization: It is funny true love story of my cat .\n",
            "Sentence before tokenization: He discovered Fibonacci number .\n",
            "Sentence before tokenization: Today I planned to have a date with her , but she canceled it .\n",
            "Sentence before tokenization: I already knew the rule that she he and it be used has , and added s after verb .\n",
            "Sentence before tokenization: But I am not good at English now .\n",
            "Sentence before tokenization: But I can buy nothing for all these money .\n",
            "Sentence before tokenization: I have a quick question and your help will be very much appreciated .\n",
            "Sentence before tokenization: I went to beach karaoke drive part time job shopping movie and so on .\n",
            "Sentence before tokenization: I guess I figured you would understand .\n",
            "Sentence before tokenization:  Japan , part Dreadful changing situations\n",
            "Sentence before tokenization: so I will go to work in hours later .\n",
            "Sentence before tokenization: Only Michael Jackson , in my opinion , would be able to face nowadays even most complex challenges .\n",
            "Sentence before tokenization: I realized I could take a significant step towards a bright future .\n",
            "Sentence before tokenization: Fetch my glasses from my room !\n",
            "Sentence before tokenization: I have not seen you .\n",
            "Sentence before tokenization: First of all , I will improve my\n",
            "Sentence before tokenization: Take it easy guys !\n",
            "Sentence before tokenization: That is to say it is the same smell between bellybutton and armpit .\n",
            "Sentence before tokenization: When I was a child videogames was one of my hobbies that I enjoyed the most .\n",
            "Sentence before tokenization: Today is the last day of my vacation .\n",
            "Sentence before tokenization: My concern is about whether I can response the question quickly\n",
            "Sentence before tokenization: It is made of wood got from thinning of a forest .\n",
            "Sentence before tokenization: I probably think the result will be No . or No . luckily .\n",
            "Sentence before tokenization: The most interesting store we visited today was the M M Shop ! !\n",
            "Sentence before tokenization: This song is used in the under movie about the Blue Impulse flight team .\n",
            "Sentence before tokenization: Is not that scary ?\n",
            "Sentence before tokenization: I love this cartoon !\n",
            "Sentence before tokenization: My courses which I have taken on Smart .\n",
            "Sentence before tokenization: The deeper we dive , the colder the water becomes .\n",
            "Sentence before tokenization: Which field of science is this ?\n",
            "Sentence before tokenization: I think it is cool\n",
            "Sentence before tokenization: Anyway , here in France , it is almost midnight , and I found myself extremely tired .\n",
            "Sentence before tokenization: World Heritage\n",
            "Sentence before tokenization: I think they taught me the most important thing for a teacher .\n",
            "Sentence before tokenization: I was glad to hear that .\n",
            "Sentence before tokenization: Now we give each other presents at the evening of th December .\n",
            "Sentence before tokenization: Do not you know a good pillow ?\n",
            "Sentence before tokenization: I made cookies . May .\n",
            "Sentence before tokenization: I would like to know your opinion !\n",
            "Sentence before tokenization: You sleep immediately after finishing eating food .\n",
            "Sentence before tokenization: Not only that , but she writes down the phrases lines ?\n",
            "Sentence before tokenization: I am from Japan .\n",
            "Sentence before tokenization: I am now setting the next goals , pertaining to the goal which I have already done today .\n",
            "Sentence before tokenization: The wind was warm and felt good .\n",
            "Sentence before tokenization: Especially in a cold north area , it is usually sticking on the ground at this time of the year .\n",
            "Sentence before tokenization: When will I finish it ?\n",
            "Sentence before tokenization: There is no use crying of split milk about drank too much last night .\n",
            "Sentence before tokenization: I will be a good English speaker even though I can not speak English .\n",
            "Sentence before tokenization: I imagined how fun I played these puppets with my daughter , although she is still two month old .\n",
            "Sentence before tokenization: I ca not imagine so many people will help me .\n",
            "Sentence before tokenization: I thought this rank was the best for the beginning of new year .\n",
            "Sentence before tokenization: Soak bread crumbs in milk .\n",
            "Sentence before tokenization: i cannt understand the word over\n",
            "Sentence before tokenization: When I asked students Do you have this paper ?\n",
            "Sentence before tokenization: Why I say this is that the people who are born in a temple have no choice to select faith because of the hereditary system .\n",
            "Sentence before tokenization: But these fine days wo not last much longer .\n",
            "Sentence before tokenization: I also like her writing style because it is very poetic .\n",
            "Sentence before tokenization: I think I will buy an iPhone G , since I am interested in developing iPhone apps .\n",
            "Sentence before tokenization: She says How can you treat me like this ? You never talk to me anymore .\n",
            "Sentence before tokenization: Also , you will be motivated by looking at how much you have completed so far .\n",
            "Sentence before tokenization: Hello !I am Miku .\n",
            "Sentence before tokenization: I am writing a report .\n",
            "Sentence before tokenization: And , I want to take communications with the person in various countries .\n",
            "Sentence before tokenization: And it can heal your disease soon . I heard that the patient often go better .\n",
            "Sentence before tokenization: And last song , singing with everybody who sang and danced for me for the last .\n",
            "Sentence before tokenization: It is the first time to sleep alone in the new house for her , and she said Can you stay in my room for a while during I am sleeping ? .\n",
            "Sentence before tokenization: I want to give a good impression to my new teachers .\n",
            "Sentence before tokenization: I am sorry for not reply to your message in year - end .\n",
            "Sentence before tokenization: She had to apologize courteously to all participants for being unable to give them return gifts in her letter .\n",
            "Sentence before tokenization: I read an interesting article about word order .\n",
            "Sentence before tokenization: There is no particular reason for that .\n",
            "Sentence before tokenization: To keep a diary is a good idea to use English .\n",
            "Sentence before tokenization: Too busy\n",
            "Sentence before tokenization: When she finished her job , I saw her off at the station .\n",
            "Sentence before tokenization: It is easy and really delicious .\n",
            "Sentence before tokenization: I saw a big rainbow when I came back my place .\n",
            "Sentence before tokenization: Some researches carried out investigations\n",
            "Sentence before tokenization: They do not have anything to do and blame it on where they live .\n",
            "Sentence before tokenization: WBC means World Baseball Classic .\n",
            "Sentence before tokenization: The Beatles ' songs are very easy English .\n",
            "Sentence before tokenization: But in actuality , she is childish AHAHAHAHA ! !\n",
            "Sentence before tokenization: Good luck my friend .\n",
            "Sentence before tokenization: Speak Talk\n",
            "Sentence before tokenization: because your hobbies are overlapping my hobbies .\n",
            "Sentence before tokenization: So many people say that .\n",
            "Sentence before tokenization: I think the best way I should take is to return to my family home .\n",
            "Sentence before tokenization: After the class , I will go to his favorite Japanese food restaurant .\n",
            "Sentence before tokenization: you know , . \n",
            "Sentence before tokenization: Many of them look similar to me .\n",
            "Sentence before tokenization: I love it . '\n",
            "Sentence before tokenization: I feel for her makes more sense .\n",
            "Sentence before tokenization: So it s very important that we , at least in an innate sense and even at an unconscious level , have some degree of altruism and we care what other people think about us , we care about the feelings of others , you know .\n",
            "Sentence before tokenization: I want to make sure these sentences are correct or not .\n",
            "Sentence before tokenization: I did not feel any pain when the dentist was pulling it out , because I was put under anesthesia .\n",
            "Sentence before tokenization: So many people say taht .\n",
            "Sentence before tokenization: For example , they have ' my mom is alien ' , ' shooting star ' and so on .\n",
            "Sentence before tokenization: I usually go to work on foot .\n",
            "Sentence before tokenization: They seemed soooooo happy .\n",
            "Sentence before tokenization: I fed one kangaroos . It was very good ! I am very happy to be from Australia !\n",
            "Sentence before tokenization: I will join next year , and do more exercise for a higher body is score ! !\n",
            "Sentence before tokenization: I was shocked .\n",
            "Sentence before tokenization: Were my eyes dry ?\n",
            "Sentence before tokenization: Today I saw a cool movie called Redhood .\n",
            "Sentence before tokenization: This model is design has not changed much .\n",
            "Sentence before tokenization: My mother bought a math workbook for me .\n",
            "Sentence before tokenization: This regulation is general for police officers , and working hours are not clearly fixed .\n",
            "Sentence before tokenization: Prices in Japan have recently become very cheap .\n",
            "Sentence before tokenization: You have to forget . , I would be able to understand .\n",
            "Sentence before tokenization: The teacher said your speaking skill is low so you should not change class .\n",
            "Sentence before tokenization: I was so impressed to hear that .\n",
            "Sentence before tokenization: Kind of English\n",
            "Sentence before tokenization: Although it was already four days ago , I still feel like writing it down loyally just like a child .\n",
            "Sentence before tokenization: We took shelter out of office .\n",
            "Sentence before tokenization: Hello everyone !My name is Lizzie and I speak in Chinese .\n",
            "Sentence before tokenization: That was great time\n",
            "Sentence before tokenization: While I regret shouting at him crazy , I have hurt him .\n",
            "Sentence before tokenization: Sometimes I just wonder .\n",
            "Sentence before tokenization: I was very happy like myself !I always cheer for him ! !\n",
            "Sentence before tokenization: I tried to eat kg curry in minutes .\n",
            "Sentence before tokenization: Then I continued to see the TV play Merlin , and it attracted me deeply .\n",
            "Sentence before tokenization: Actually , many economists are taking a fresh look at Japan is troubled experience in order to obtain something useful for today is economic depression .\n",
            "Sentence before tokenization: Ofcourse , in English .\n",
            "Sentence before tokenization: I recently harvest some tomatoes at last .\n",
            "Sentence before tokenization: We bought lots of stuff such as a latter , a fragrant , a basin and even Japanese noodles .\n",
            "Sentence before tokenization: How can I study well ?\n",
            "Sentence before tokenization: The girl sang instead of her dead boyfriend .\n",
            "Sentence before tokenization: She is very big and has a black coat .\n",
            "Sentence before tokenization: The answer is no .\n",
            "Sentence before tokenization: In the urban areas , we can usually find them within minutes ' walk from our home .\n",
            "Sentence before tokenization: My mother told me that Santa is gone .\n",
            "Sentence before tokenization: As for travel , I visited Hawaii , Boston and Saipan .\n",
            "Sentence before tokenization: We live in an absurd world with an illogical system of values .\n",
            "Sentence before tokenization: All the conversations we have is in English and sometimes Italiano .\n",
            "Sentence before tokenization: This logo design is very simple , but deep meaning is hidden behind it .\n",
            "Sentence before tokenization: I ca not keep doing something because I lose interest in it .\n",
            "Sentence before tokenization: I am a two year now .\n",
            "Sentence before tokenization: As a result , we all have the possibility of either success or failure .\n",
            "Sentence before tokenization: We bought lots of stuff , such as a latter , a fragrance , a basin and even Japanese noodles .\n",
            "Sentence before tokenization: There were over people in the audience .\n",
            "Sentence before tokenization: PC , mobile phone , lights and so on were out of order by the lack of powers .\n",
            "Sentence before tokenization: It is only years old , but there are very talented actors and actresses .\n",
            "Sentence before tokenization: I have a dream for them .\n",
            "Sentence before tokenization: I have to recommend everybody\n",
            "Sentence before tokenization: I am proud of that .\n",
            "Sentence before tokenization: However I do nothing but do homework .\n",
            "Sentence before tokenization: I love drawing pictures .\n",
            "Sentence before tokenization: Four families and two dogs stay in my house .\n",
            "Sentence before tokenization: It is a miracle that I got an .\n",
            "Sentence before tokenization: Just smile .\n",
            "Sentence before tokenization: By the way , my father transfered today .\n",
            "Sentence before tokenization: Thelanguage of the character is very organic and it is as vivid as the character herself .\n",
            "Sentence before tokenization: My company never take a bonus holiday .\n",
            "Sentence before tokenization: Sincerely hope I can do a great job at this new work and everything will be smooth and successful .\n",
            "Sentence before tokenization: Are there any grammatical mistakes ?\n",
            "Sentence before tokenization: We had a nice little chat while eating foods .\n",
            "Sentence before tokenization: Becase it is hard to express with words .\n",
            "Sentence before tokenization: More than a hundred thousands of people are supporting sufferer .\n",
            "Sentence before tokenization: It remain hours .\n",
            "Sentence before tokenization: I would like you to teach me .\n",
            "Sentence before tokenization: But what is this ?\n",
            "Sentence before tokenization: It took three hours to Tokyo .\n",
            "Sentence before tokenization: Because this situation is break the Japanese tradition .\n",
            "Sentence before tokenization: There are so many personalities , the same as the number of people .\n",
            "Sentence before tokenization: The First Time\n",
            "Sentence before tokenization: I am the one who are the same person at some degrees .\n",
            "Sentence before tokenization: and feel sad too !\n",
            "Sentence before tokenization: Do you like movies ?\n",
            "Sentence before tokenization: Now , I am looking for a job .\n",
            "Sentence before tokenization: But I am too hard\n",
            "Sentence before tokenization: Many famous players belong to there .\n",
            "Sentence before tokenization: Then Y - kun repeated the same question again and again .\n",
            "Sentence before tokenization:  Dad , I just told you , it is a bird ! the son replied impatiently .\n",
            "Sentence before tokenization: It is a promise you made for love , \n",
            "Sentence before tokenization: Thank you for reading !\n",
            "Sentence before tokenization: He made a mistake in the exam\n",
            "Sentence before tokenization: Visitors can enjoy , fireworks .\n",
            "Sentence before tokenization: Yesterday , I made sweets at a cooking school .\n",
            "Sentence before tokenization: After that I had recovered , and felt good until the day before yesterday .\n",
            "Sentence before tokenization: So magical , so cold but simultaneously so warm I cherished it as much as I was able to , mostly because something finally made me feel complete .\n",
            "Sentence before tokenization: SO I want to know about that in Japanese today .\n",
            "Sentence before tokenization: Now , i am in this store .\n",
            "Sentence before tokenization: I am really happy to see he is excited .\n",
            "Sentence before tokenization: Today I got a new word of Facebook Depression .\n",
            "Sentence before tokenization: My heart fluttered with excitement .\n",
            "Sentence before tokenization: Then , I remained songs which I willingly listened to when I was a high school student .\n",
            "Sentence before tokenization: Despite our thinking , we finally got a wonderful victory , and the morale of the team members was very high .\n",
            "Sentence before tokenization: I have never watched musicals , but it was so nice .\n",
            "Sentence before tokenization: Life Begins At Forty !\n",
            "Sentence before tokenization: It can meet my requirements .\n",
            "Sentence before tokenization: I hope to go to see cherry blossom this Sunday , \n",
            "Sentence before tokenization: My first diary in LANG -\n",
            "Sentence before tokenization: But I am not enjoying it .\n",
            "Sentence before tokenization: By taking Japanese language courses at a Japanese university , I hope to acquire new approaches to improving my Japanese language skills .\n",
            "Sentence before tokenization: I always need someone to correct my english writings whether that is right or not .\n",
            "Sentence before tokenization: When I got to the store , I suddenly had a bad stomachache .\n",
            "Sentence before tokenization: Luisa\n",
            "Sentence before tokenization: But it was not a tomato !\n",
            "Sentence before tokenization: It was to fail , the thing is I love to be alone from the beginning .\n",
            "Sentence before tokenization: Between the devil and the deep sea !\n",
            "Sentence before tokenization: I m glad you have nt brought me back an in - law form Alberta\n",
            "Sentence before tokenization: I told my roommate about it .\n",
            "Sentence before tokenization: I felt the sence of accompulishment then .\n",
            "Sentence before tokenization: And I think that it helps me to improve my skills\n",
            "Sentence before tokenization: Today is .\n",
            "Sentence before tokenization: The Great Wall is the first choice to visit in Beijing .\n",
            "Sentence before tokenization: Small number of young girls visit solarium .\n",
            "Sentence before tokenization: I am interested in the space .\n",
            "Sentence before tokenization: The growth of her skill is slow , but sure .\n",
            "Sentence before tokenization: There are a lot of advantages to using a computer and it is necessary to use it in our life .\n",
            "Sentence before tokenization: But there were a lot of words which I did nt know , so I was discouraged to read it .\n",
            "Sentence before tokenization: I wonder What s the matter ?\n",
            "Sentence before tokenization: While working as a salesman , I will work hard to hold a broad konwledge of this vacation and weave a net of personal connection in - years .\n",
            "Sentence before tokenization: It is said that the Simpsons has been broadcasted for more than years .\n",
            "Sentence before tokenization: Are all false statements lies ?\n",
            "Sentence before tokenization: To tell the truth , our looked Kay tasted beer with great relish with watching TV when mom went to toilet , and laughted loudy about it .\n",
            "Sentence before tokenization: And he is .\n",
            "Sentence before tokenization: Nice to meet you !\n",
            "Sentence before tokenization: Keio Corp .\n",
            "Sentence before tokenization: I m strong .\n",
            "Sentence before tokenization: A single lifetime will pass soon\n",
            "Sentence before tokenization: The ratio including graduates from college and academy is also supposed to be lower than last year .\n",
            "Sentence before tokenization: For three days I can keep my schedule , but after three days I ca not do that .\n",
            "Sentence before tokenization: I disagree to Tim Ferris in part .\n",
            "Sentence before tokenization: The most big type is formed by a king , a queen , three lady is maids , a band of five men , two officers and foods .\n",
            "Sentence before tokenization: It is the reason our culture has originality .\n",
            "Sentence before tokenization: It made a deep impression on me .\n",
            "Sentence before tokenization: I am doing very well because I received a very nice message today .\n",
            "Sentence before tokenization: Second , smoking helps free the body of tension .\n",
            "Sentence before tokenization: Please try it .\n",
            "Sentence before tokenization: Crab Syndrome\n",
            "Sentence before tokenization: He must be a genius .\n",
            "Sentence before tokenization: I bought a danish type bread filled with sausage and cheese , a curry bread , and a chocolate doughnut .\n",
            "Sentence before tokenization: I hurried up to go pick her up , and I apologized to her that I was late .\n",
            "Sentence before tokenization: I bought a new smart - phone weeks ago .\n",
            "Sentence before tokenization: Oh , Geez , I feel stupid XD\n",
            "Sentence before tokenization: I passed ! !\n",
            "Sentence before tokenization: But when I was writing a message , she showed up .\n",
            "Sentence before tokenization: What experience skills do you have in this field ?\n",
            "Sentence before tokenization: It is very gorgeous .\n",
            "Sentence before tokenization: All of them are taller than the mountain .\n",
            "Sentence before tokenization: The number of friends has been increasing gradually .\n",
            "Sentence before tokenization: We got to a large park by the station .\n",
            "Sentence before tokenization: As soon as I sat down in the seat , I ordered pancakes with bananas without a hesitation .\n",
            "Sentence before tokenization: By the way , do I also need to renew myself this spring ?\n",
            "Sentence before tokenization: Honda , the forward player , won the goal at last .\n",
            "Sentence before tokenization: but i had to work at my desk , eagerly .\n",
            "Sentence before tokenization: Sorry to bother you , but I am not sure whether my application files are complete or not .\n",
            "Sentence before tokenization: summer vacation\n",
            "Sentence before tokenization: I like learning new things and taking challenges .\n",
            "Sentence before tokenization: It means Come in ! in English .\n",
            "Sentence before tokenization: There are so many parties in March .\n",
            "Sentence before tokenization: Actually compare to other persons , it is not a long time but when I look back , a plenty of good or bad things which happened on me .\n",
            "Sentence before tokenization: I enrolled in a cram school for bereancracy entrance examination one week ago .\n",
            "Sentence before tokenization: At this point , the passenger got angry and shouted Who the devil do you think you are ? \n",
            "Sentence before tokenization: I have a leg joint problem .\n",
            "Sentence before tokenization: And restaurants served eel dishes are very busy this day .\n",
            "Sentence before tokenization: Which place would you prefer to live in ?\n",
            "Sentence before tokenization: Christmas illuminations\n",
            "Sentence before tokenization: Do you know ?\n",
            "Sentence before tokenization: I did not skip out on learning English .\n",
            "Sentence before tokenization: It starts every Sunday at .\n",
            "Sentence before tokenization: It means our words on Twitter have the possibility to change the world .\n",
            "Sentence before tokenization: Some friends keep studying hard so I thought I should brace myself again .\n",
            "Sentence before tokenization: should you keep stuff gifts from your ex - lovers or not ?\n",
            "Sentence before tokenization: I an going to go sightseeing to Korea with cousin .\n",
            "Sentence before tokenization: However it is very inconvenient for shopping .\n",
            "Sentence before tokenization: A new start !\n",
            "Sentence before tokenization: The Life !\n",
            "Sentence before tokenization: Please give advice .\n",
            "Sentence before tokenization: I have severe headaches .\n",
            "Sentence before tokenization: My Dream\n",
            "Sentence before tokenization: We can help each other by correcting each other is writing through this site .\n",
            "Sentence before tokenization: And I did so , I sent them a whisky and told them I wo not give them money , when I am married , do not give me the money either .\n",
            "Sentence before tokenization: inevitable It is inevitable that the world will run out of oil in the future .\n",
            "Sentence before tokenization: Many of them said , I study Japanese .\n",
            "Sentence before tokenization: As matter of fact , I did not know there is sandwich restraunt in Japan in the recent days .\n",
            "Sentence before tokenization: Of course it was Japanese edition .\n",
            "Sentence before tokenization: Snack CM\n",
            "Sentence before tokenization: Today was the second day of the JOCV meeting .\n",
            "Sentence before tokenization: Because I have been having dizzy these days .\n",
            "Sentence before tokenization: Tommorow I will have breakfast with the kids of my classroom .\n",
            "Sentence before tokenization: Today , I decided to go to the dermatologist , just in case , though the pain was almost eased when I woke up in this morning .\n",
            "Sentence before tokenization: Time flies .\n",
            "Sentence before tokenization: Northern Japan\n",
            "Sentence before tokenization: i m korean , male\n",
            "Sentence before tokenization: Therefore , it will be safe and convenient .\n",
            "Sentence before tokenization: I just ca not get enough of coffees .\n",
            "Sentence before tokenization: However , after I saw my book in the book store , I thought many things about my illustration work .\n",
            "Sentence before tokenization: Anyway , it is just the peace before the storm .\n",
            "Sentence before tokenization: They are older than me who just like my uncle , aunt and grandmother .\n",
            "Sentence before tokenization: Multiculturalism in Canada\n",
            "Sentence before tokenization: They were delicious and very cheap , so we were happy .\n",
            "Sentence before tokenization: Two and three is five .\n",
            "Sentence before tokenization: When the observer was saying that half the time has passed , I was in the second question and the whole exam consisted of questions .\n",
            "Sentence before tokenization: taxi is soooooooooooo cool !\n",
            "Sentence before tokenization: I wondered why would I ignore my friends suggestion and do nt believe such a thing is totally possible ? Perhaps it was because I was too lazy to consider it and would like to enjoy a comfortable life without getting sunburn during the summer vacation .\n",
            "Sentence before tokenization: I am looking forward to see the new Harry Potter is movie .\n",
            "Sentence before tokenization: It is\n",
            "Sentence before tokenization: some expressions\n",
            "Sentence before tokenization: It was awesome . He never let me down .\n",
            "Sentence before tokenization: in the gym\n",
            "Sentence before tokenization: This time I use the Google translate service , \n",
            "Sentence before tokenization: So , these weeks I have slept many times .\n",
            "Sentence before tokenization: I was happy , I drank it a lot and I discovered a very good bar near my house .\n",
            "Sentence before tokenization: and its business model is the same that customers pay for convenience with higher prices on most goods .\n",
            "Sentence before tokenization: Let is try again !\n",
            "Sentence before tokenization: It had started all of a sudden and kept on with no sign of stopping .\n",
            "Sentence before tokenization: Where can you go ?\n",
            "Sentence before tokenization: so i will give him many chocolate !\n",
            "Sentence before tokenization: There are many shops so I had spent a lot of many !\n",
            "Sentence before tokenization: I suppose that pupils would rather have a year for find a job and gain experience or travel to widen their insight than enter straight to university after finishing at high school\n",
            "Sentence before tokenization: The ordinary general meeting shall be held within six months of the end of each financial year .\n",
            "Sentence before tokenization: .\n",
            "Sentence before tokenization: yeah I know you had enough\n",
            "Sentence before tokenization: First , SF is relatively compact and there are a lot of slopes .\n",
            "Sentence before tokenization: The two are very fun for me .\n",
            "Sentence before tokenization: We just put out new products on the market .\n",
            "Sentence before tokenization: An exhausting day\n",
            "Sentence before tokenization: Today I watched an amusing TV drama .\n",
            "Sentence before tokenization: I want to be a good teacher for my children , so I will study everything for teaching children very hard ! !\n",
            "Sentence before tokenization: There are a lot of murals of several stories and graffiti , which were remained by visitors Japanese .\n",
            "Sentence before tokenization: The swimming instruction lessons start at the end of September .\n",
            "Sentence before tokenization: I have a good time on the bus because I talk with a lot of people that I never talk with , so I can find out things about them .\n",
            "Sentence before tokenization: Getting up early is a key issue in my self - management .\n",
            "Sentence before tokenization: My favourite word\n",
            "Sentence before tokenization: My diary -\n",
            "Sentence before tokenization: I felt so sad and shocked when I heard even elementary school kids pass the exam sometimes .\n",
            "Sentence before tokenization: Freakonomics\n",
            "Sentence before tokenization: The people who fail to pass the exam study another year to prepare for next entrance exam .\n",
            "Sentence before tokenization: One piece of one - dollar bill , two pieces of dimes , \n",
            "Sentence before tokenization: It was a real shock .\n",
            "Sentence before tokenization: About the purpose\n",
            "Sentence before tokenization: Take care !\n",
            "Sentence before tokenization: Today , I want to tell you about one of the Internet slang expressions in Japan again .\n",
            "Sentence before tokenization: Anyway , the scenery of Marien Plaza with fireworks was wonderful .\n",
            "Sentence before tokenization: Spoken language is very difficult .\n",
            "Sentence before tokenization: Today , I am going to take TOEIC .\n",
            "Sentence before tokenization: A Korean blogger wrote about this with his confusions .\n",
            "Sentence before tokenization: I did not have enough time to answer all the questions this time .\n",
            "Sentence before tokenization: He met her mother who had two sister , Helen s sister Julia and Helen .\n",
            "Sentence before tokenization: I did not take them .\n",
            "Sentence before tokenization: My entries were always corrected for spelling mistakes .\n",
            "Sentence before tokenization: When a man shows interest in a woman is feelings and heartfelt concern for her well - being , she feels loved and cared for .\n",
            "Sentence before tokenization: My worry this summer\n",
            "Sentence before tokenization: If you have problems understanding the meaning of some words , \n",
            "Sentence before tokenization: In addition , since I have worked for a company for a long time , I have not been able to have enough time to enjoy studying .\n",
            "Sentence before tokenization: Please check this out first .\n",
            "Sentence before tokenization: Americans dislike having silence in conversations .\n",
            "Sentence before tokenization: Today , my hobby and Iwant to write about overseas travel .\n",
            "Sentence before tokenization: This is a warning label on a lighter I found in my bag yesterday .\n",
            "Sentence before tokenization: My name is .\n",
            "Sentence before tokenization: I hope everything will be alright !\n",
            "Sentence before tokenization: If this is too much .\n",
            "Sentence before tokenization: I am very happy .\n",
            "Sentence before tokenization: It is hard to convey all my ideas in only pages , so I will write my thesis as a detailed version of the article .\n",
            "Sentence before tokenization: Tomorrow Never Comes\n",
            "Sentence before tokenization: Generally speaking , it appears that it is easier to enter into other countries by passing across the border .\n",
            "Sentence before tokenization: How enjoy the citizen , is not it ?\n",
            "Sentence before tokenization: And th , th , I have a second one .\n",
            "Sentence before tokenization: I have no confidence actually .\n",
            "Sentence before tokenization: Today I did oversleeping after a long time .\n",
            "Sentence before tokenization: But it is too cold to swim .\n",
            "Sentence before tokenization: I am happy to know this site !\n",
            "Sentence before tokenization: And I bought a USB in order to watch DVDs .\n",
            "Sentence before tokenization: It was written in and became one of Agatha Christie s most popular and successful stories .\n",
            "Sentence before tokenization: It was a gangster is car but I did not realise it at all .\n",
            "Sentence before tokenization: In the reaction , where Nitrogen gas reacts with Hydrogen gas to form Ammonia gas , if the temperature is increasing , the reaction will progress rapidly while the yield of product will be decreasing .\n",
            "Sentence before tokenization: I used to go for a lonely walk , wear a dress , get my big red bag and .\n",
            "Sentence before tokenization: Hi !\n",
            "Sentence before tokenization: She had recovered a lot .\n",
            "Sentence before tokenization: I really felt amazed .\n",
            "Sentence before tokenization: Do you want to try Melatonin when you go to overseas travel ?\n",
            "Sentence before tokenization: In the run - up to the election , the opposition party was cracked down on .\n",
            "Sentence before tokenization: She also lies today .\n",
            "Sentence before tokenization: I am not sure that the man could understand or not .\n",
            "Sentence before tokenization: Very simple and small watercolour pictures .\n",
            "Sentence before tokenization: It was a very religious day in a meaning .\n",
            "Sentence before tokenization: Shrimps , fishes , and vegetables are especially good .\n",
            "Sentence before tokenization: I knew this page today !\n",
            "Sentence before tokenization: Very delicious ! !\n",
            "Sentence before tokenization: It has been cold and rainy these days .\n",
            "Sentence before tokenization: So my point is that our listening comprehension remains sluggish unless we can read and understand at a glance .\n",
            "Sentence before tokenization: I think The best coffee has good memories than good meterials .\n",
            "Sentence before tokenization: Hellow my name is Marcela and I want to talk about London cause I d love to go there .\n",
            "Sentence before tokenization: He can speak Japanese a little .\n",
            "Sentence before tokenization: She touched the base of the sound with the branch , and as a result , balconies with potted flower plants suddenly appeared .\n",
            "Sentence before tokenization: I am struggling with my new lifestyle because I changed my job .\n",
            "Sentence before tokenization: I just nod to him , and he too .\n",
            "Sentence before tokenization: I need something to excite me .\n",
            "Sentence before tokenization: Sometimes I want to make sure if the story is true .\n",
            "Sentence before tokenization: Have a nice evening !\n",
            "Sentence before tokenization: I am very glad .\n",
            "Sentence before tokenization: But I sometimes like to take a boat and go on a lake and enjoy the calm and fresh air on the water .\n",
            "Sentence before tokenization: I would like to describe its flavour as similar to milk and soda .\n",
            "Sentence before tokenization: Do over - to renovate or redecorate .\n",
            "Sentence before tokenization: Recently , however , I have heard or seen troubles between women on women - only cars .\n",
            "Sentence before tokenization: Writing card is a little burden but it is importaint for me to get in touch with my old friends .\n",
            "Sentence before tokenization: In this Bora blows with a medium speed of ovee km h over kts , and the highest gust reached km h .\n",
            "Sentence before tokenization: Techno , House , \n",
            "Sentence before tokenization: I believe he will have a pleasant time on this trip .\n",
            "Sentence before tokenization: Hello , everyone , my name is lily .\n",
            "Sentence before tokenization: I have come home just now .\n",
            "Sentence before tokenization: I understand what he wrote but I do not think\n",
            "Sentence before tokenization: I know , I know .\n",
            "Sentence before tokenization: It was really excited !And then I made a song by ad - lib .\n",
            "Sentence before tokenization: I came home .\n",
            "Sentence before tokenization: They have released pieces of CDs and three pieces of CD albums so far .\n",
            "Sentence before tokenization: nice to meet you .\n",
            "Sentence before tokenization: But I gradually realize that everything in this world is short acturally , including our life .\n",
            "Sentence before tokenization: Shapur told everything about what had happened to Shirin from A to Z .\n",
            "Sentence before tokenization: In addition , long - distance coaches have become more popular since more people try to pinch a penny .\n",
            "Sentence before tokenization: He asked a few more questions such as What it looks like ? to make sure the pass is mine .\n",
            "Sentence before tokenization: Nobody complains , anyway .\n",
            "Sentence before tokenization: Oh , I miss him so much ! !\n",
            "Sentence before tokenization: Once finished , this argument is passed to write up proposals that would improve and implement the exit strategy after the Olympics because this can really enjoy the positive mechanisms initiated by public investment .\n",
            "Sentence before tokenization: For this sake , the young people in many families feel frustrated in persuading their parents , nevertheless , what has to be done must be done .\n",
            "Sentence before tokenization: But I try .\n",
            "Sentence before tokenization: The ability , such as activity , I am very easily to accept fresh things when I get into new environment .\n",
            "Sentence before tokenization: I am really worried about him .\n",
            "Sentence before tokenization: On the other hand , I was not able to say directly what was on my mind .\n",
            "Sentence before tokenization: Guess what !\n",
            "Sentence before tokenization: It is makes their wedding party going perfect .\n",
            "Sentence before tokenization: Is raining\n",
            "Sentence before tokenization: Clare This is just between You and Me\n",
            "Sentence before tokenization: Oct th\n",
            "Sentence before tokenization: The theme was racial discrimination in the s .\n",
            "Sentence before tokenization: I have changed my work time again .\n",
            "Sentence before tokenization: consider those opinions carefully , I would like to support the idea that studying at a small university is better for\n",
            "Sentence before tokenization: Me It is difficult to use up all of foods I got .\n",
            "Sentence before tokenization: Thank you for your help .\n",
            "Sentence before tokenization: Learning foreign languages is so fun . So after graduation , I want to learn many languages .\n",
            "Sentence before tokenization: Seeing my parents carrying those big baggages to the six floor .\n",
            "Sentence before tokenization: Besides , you know , the building\n",
            "Sentence before tokenization: Today , I would like to introduce two recommendations .\n",
            "Sentence before tokenization: Here is a massage for an ebay seller .\n",
            "Sentence before tokenization: My email is xzlhdzsw gmail .\n",
            "Sentence before tokenization: From the ground\n",
            "Sentence before tokenization: And I signed the contract without even noticing what was going to come . I had to fulfill the contract made between me and the company . It would have been a breach if I had failed to do so .\n",
            "Sentence before tokenization: Out of work again !\n",
            "Sentence before tokenization: Some say Japanese projects are more difficult than those of other countries .\n",
            "Sentence before tokenization: Because I am a little tired , I will take a break .\n",
            "Sentence before tokenization: because I watched no korean caption\n",
            "Sentence before tokenization: The animation has been popular since then .\n",
            "Sentence before tokenization: He kindly made me an appointment for four p .m . and straightened my neck and back .\n",
            "Sentence before tokenization: I hope one day I could feel how great MLB is in person .\n",
            "Sentence before tokenization: and MP on DX format .\n",
            "Sentence before tokenization: When I was kid , it could not be imagined .\n",
            "Sentence before tokenization: Remembering what I did yesterday , I read a book with lying down in the midnight .\n",
            "Sentence before tokenization: How I wish I was taller\n",
            "Sentence before tokenization: I want you to see it when you have some free time .\n",
            "Sentence before tokenization: Because this helps me to break the\n",
            "Sentence before tokenization: New Year cards\n",
            "Sentence before tokenization: is ' did you nod ?\n",
            "Sentence before tokenization: It was the same thing .\n",
            "Sentence before tokenization: His new apartment is eight - minute walk from Yokohama station .\n",
            "Sentence before tokenization: There is a bus stop and subway station near my house .\n",
            "Sentence before tokenization: The most obvious one is promoting international trade .\n",
            "Sentence before tokenization: but anyway .\n",
            "Sentence before tokenization: Every Friday , I always consider that choosing the college near my home is right .\n",
            "Sentence before tokenization: And they sang a song , talking to each other .\n",
            "Sentence before tokenization: This is my first journal in Lang - .\n",
            "Sentence before tokenization: It is very beautiful ! !\n",
            "Sentence before tokenization: Lane was so silly ! ! ! Lane was so crazy .\n",
            "Sentence before tokenization: There is a masterpoece movie named Bicycle Thief in Italy .\n",
            "Sentence before tokenization: I was very glad that they had a good time with Japanese culture .\n",
            "Sentence before tokenization: In contrast , the lecture is main idea is that beforehand expectation deeply affects the decision making process .\n",
            "Sentence before tokenization: Foreign company or domestic company\n",
            "Sentence before tokenization: Where and what will you who will read this letter do ?\n",
            "Sentence before tokenization: My father said that he can put some more foods in the pot - ramyeons , but he ca not put anything in the cup - ramyeons .\n",
            "Sentence before tokenization: My friends picked me up on Friday afternoon , and we played some video games , monopoly and poker at that night .\n",
            "Sentence before tokenization: If I go business trip alone , I can not go restaurant , \n",
            "Sentence before tokenization: I wo not forget it ever and ever .\n",
            "Sentence before tokenization: And a time when you can choose , \n",
            "Sentence before tokenization: This year was th anniversary , so number of roses were five .\n",
            "Sentence before tokenization: The team won in the Japanese Series .\n",
            "Sentence before tokenization: At first , I will go back to Japan for six month .\n",
            "Sentence before tokenization: I am now setting the next goals pertaing the goal which I have already done today .\n",
            "Sentence before tokenization: Before I knew it , three hours had passed when we were immersed in watching the exhibits .\n",
            "Sentence before tokenization: It is just like a dream .\n",
            "Sentence before tokenization: Thank you everyone .\n",
            "Sentence before tokenization: What do you think ?\n",
            "Sentence before tokenization: But how come the Starbucks stores I go to here , always have a lot of customers .\n",
            "Sentence before tokenization: This is my first writing to you .\n",
            "Sentence before tokenization: The professor of New Zealander drinks like a fish .\n",
            "Sentence before tokenization: What ways can both my Russian and English in the same time .\n",
            "Sentence before tokenization: I guess , I will re - watch that drama .\n",
            "Sentence before tokenization: I want to go to the sea , mountains and outside in summer .\n",
            "Sentence before tokenization: The other day I went to the library , and borrowed a book written about saliva .\n",
            "Sentence before tokenization: Because There are many shops .\n",
            "Sentence before tokenization: and even I watched korean casting ! !\n",
            "Sentence before tokenization: Do you know the word IKUMEN ?\n",
            "Sentence before tokenization: If you were him , would you cancel ?\n",
            "Sentence before tokenization: In my opinion .\n",
            "Sentence before tokenization:  Togo is players not only people , two soldiers were \n",
            "Sentence before tokenization: vary from red to green , \n",
            "Sentence before tokenization: Lecturers explained very quickly without taking a rest , \n",
            "Sentence before tokenization: Ice wine of Canada was very sweet and tasty .\n",
            "Sentence before tokenization: I practised the making of Zonbi also today .\n",
            "Sentence before tokenization: BUT I must do the English level Test .\n",
            "Sentence before tokenization: Recently I often listen to this song on TV .\n",
            "Sentence before tokenization: They could not even fix it .\n",
            "Sentence before tokenization: But I ca not speak English .\n",
            "Sentence before tokenization: The make - up is almost finished at the bride is home .\n",
            "Sentence before tokenization: I need change in this new year , so I will work hard ! In order to make progress , I will write journals when I surf the Internet .\n",
            "Sentence before tokenization: So if you move to an area from another area in Japan , you will have some trouble .\n",
            "Sentence before tokenization: But I want to improve my speaking skill .\n",
            "Sentence before tokenization: Although today was a part time job , in the meantime , Japan was hit by a typhoon .\n",
            "Sentence before tokenization: When I was in junior high school , I was confident of fiscal abilities , that I had by nature .\n",
            "Sentence before tokenization: I invited my friend .\n",
            "Sentence before tokenization: And I am going to go movietheater to see Night and day with friends tommorrow .\n",
            "Sentence before tokenization: i am the new one in lang - .\n",
            "Sentence before tokenization: I want to write on this site about a problem of Japan and a solution of that , but my poor English disturbs me .\n",
            "Sentence before tokenization: Recently , I was busy with a project .\n",
            "Sentence before tokenization: In addition , I wo nt friend in foreign country who will be my first international friend .\n",
            "Sentence before tokenization: In the morning , on a TV program , I watched an interview VTR that questioned foreigners who speak Japanese well .\n",
            "Sentence before tokenization: Old and young , everybody look at their fighting .\n",
            "Sentence before tokenization: thx reading ! !\n",
            "Sentence before tokenization: Here they are\n",
            "Sentence before tokenization: zall about English - Evie they will not stick with me if they do not like my attitude\n",
            "Sentence before tokenization: But I ate it , I thought very delicious .\n",
            "Sentence before tokenization: I do not know why but his speech continued to remain in my ears . I wanted to know what he said .\n",
            "Sentence before tokenization: I am sure you will become good at English .\n",
            "Sentence before tokenization: This year the silver week has five holidays .\n",
            "Sentence before tokenization: Most of those things may not be seen as the condition at this time , but that fact could nt stop us imagining them .\n",
            "Sentence before tokenization: The yellow means you can close , you can not close .\n",
            "Sentence before tokenization: And someday the pets are going to die .\n",
            "Sentence before tokenization: Home Bakery\n",
            "Sentence before tokenization: Maybe I think I was too relaxed .\n",
            "Sentence before tokenization: Be ready to pay up .\n",
            "Sentence before tokenization: Because it was soooo grotesque and cruel .\n",
            "Sentence before tokenization: The natural disasters do nt wait for poor people .\n",
            "Sentence before tokenization: Once again we appreciate your support and cooperation a lot for our humanitarian activities .\n",
            "Sentence before tokenization: I like those things .\n",
            "Sentence before tokenization: Use specific reasons and examples to support your opinion .\n",
            "Sentence before tokenization: I felt happeer than useal .\n",
            "Sentence before tokenization: The interview was very difficult for me .\n",
            "Sentence before tokenization: My friend is mom invited me to her church .\n",
            "Sentence before tokenization: I hope my college life will be wonderful !\n",
            "Sentence before tokenization: Half from the defense .\n",
            "Sentence before tokenization: David Lachapelle\n",
            "Sentence before tokenization: Internet game\n",
            "Sentence before tokenization: I think it show his folk character .\n",
            "Sentence before tokenization: But I will be able to restart studying English from today .\n",
            "Sentence before tokenization: But how about b and ?\n",
            "Sentence before tokenization: Maybe , at last I will know that our baby s gender at that time .\n",
            "Sentence before tokenization: I am studying dynamics for the examination which is going to be carried out about two weeks later .\n",
            "Sentence before tokenization: The game was over with a victory for Paraguay .\n",
            "Sentence before tokenization: I went shopping with my husband to our favorite store BARNEYS NEW YORK in Shinjyuku .\n",
            "Sentence before tokenization: TO OUR VESSEL SUDDENLY , AND PROBE TRIVIAL THING\n",
            "Sentence before tokenization: Once upon a time , there was a young girl called Mariah .\n",
            "Sentence before tokenization: Although our journey ended with seriously sickness , many of us got fever or problems with stomach .\n",
            "Sentence before tokenization: Would you leave any comment about pronunciation or script ?\n",
            "Sentence before tokenization: This is a ride .\n",
            "Sentence before tokenization: What do you think is the reason why I went to Kalaoke today ?\n",
            "Sentence before tokenization: Yesterday I cooked food by myself . This was my first time cooking .\n",
            "Sentence before tokenization: I easily have a blocked nose with hay fever .\n",
            "Sentence before tokenization: Then , an earthquake happened .\n",
            "Sentence before tokenization: This morning , I woke up at , because I had a class at .\n",
            "Sentence before tokenization: Thanks for birth of her ! ! !\n",
            "Sentence before tokenization: The world would never be the same , black became pink , sadness became happiness and loneliness became love .\n",
            "Sentence before tokenization: Locked Out !\n",
            "Sentence before tokenization: Have to go to bed right now .\n",
            "Sentence before tokenization: My pet\n",
            "Sentence before tokenization: I look like the marshmallowman .\n",
            "Sentence before tokenization: With best wishes .\n",
            "Sentence before tokenization: When I started studying abroad , I could not speak or listen to any English even though I had studied it for years , as I said before .\n",
            "Sentence before tokenization: I do not have a child .\n",
            "Sentence before tokenization: My tooth had chipped by biting bread , indeed !\n",
            "Sentence before tokenization: I love to drive a car with my friend or my wife .\n",
            "Sentence before tokenization: I have recently developed interest in studying japanese and Spanish , so I hope that I will be able to write some entires in these languages soon !\n",
            "Sentence before tokenization: Morning , something\n",
            "Sentence before tokenization: By the time my grandpa died , most of them had not actually been practiced so often .\n",
            "Sentence before tokenization: Wars and complains may arise in this way .\n",
            "Sentence before tokenization: Japan is the most excellent about service , security and sanitary .\n",
            "Sentence before tokenization: This main character is a - year - old girl , and she does not know things well because she is young .\n",
            "Sentence before tokenization: I hope we have a nice training session .\n",
            "Sentence before tokenization: I think you will be able to do it .\n",
            "Sentence before tokenization: I was very proud of these applications because it help people and the world .\n",
            "Sentence before tokenization: Although my mom said Japanese was easy to learn for Chinese people , I still found it difficult .\n",
            "Sentence before tokenization: But she has heavy morning sickness .\n",
            "Sentence before tokenization: The above price is for three courses !\n",
            "Sentence before tokenization: They are too graphic for the generally ungraphic English emoticons to be used suitably in combination .\n",
            "Sentence before tokenization: After one minute , a tram .\n",
            "Sentence before tokenization: If it sounds like that , that is just because my sense of English is not that good .\n",
            "Sentence before tokenization: It could be named as a electric - pickpocket ?\n",
            "Sentence before tokenization: Save the enjoyment for a while .\n",
            "Sentence before tokenization: change my hairstyle , \n",
            "Sentence before tokenization: In , when I traveled in the U .\n",
            "Sentence before tokenization: Old and young , everybody looks at their fighting .\n",
            "Sentence before tokenization: I will try to make a few sentences using this idiom .\n",
            "Sentence before tokenization: But every early morning I was forced to get up by the noise and shaking of the first train .\n",
            "Sentence before tokenization: I hate my computer .\n",
            "Sentence before tokenization: The issue of how to deal with the money has been wildly discussed .\n",
            "Sentence before tokenization: I understand why they say this , but do they understand It will make sufferers of earthquakes face an even harder situation .\n",
            "Sentence before tokenization: I was moved by their skillfulness when they cut a piece of timber and made some tools .\n",
            "Sentence before tokenization: When we communicate about relationships using problematic facts , we exchange nothing but anger .\n",
            "Sentence before tokenization: I could not feel it from him anymore .\n",
            "Sentence before tokenization: My vegetable basket was filled with potatoes .\n",
            "Sentence before tokenization: watch is uncounable .\n",
            "Sentence before tokenization: This is one of my favorites !\n",
            "Sentence before tokenization: Oh , they are not wishes but statements !\n",
            "Sentence before tokenization: I Caught a Cold .\n",
            "Sentence before tokenization: The guitarist Slash is good at that .\n",
            "Sentence before tokenization: The body is built of Japanese cypresses .\n",
            "Sentence before tokenization: I spent a month there years ago .\n",
            "Sentence before tokenization: I am writing an essay\n",
            "Sentence before tokenization: Okay then , I guess I should face this problem for starters .\n",
            "Sentence before tokenization: It was my nd experience but I was so excited .\n",
            "Sentence before tokenization: I have to work and do not have a holiday .\n",
            "Sentence before tokenization: Their play excited me .\n",
            "Sentence before tokenization: Although I do not know when and how it began , I guess that the confectionery industry successfully commercialized the day by taking advantage of a traditional idea .\n",
            "Sentence before tokenization: Also , customers who brought the promoted products usually had good experience and impression about the products .\n",
            "Sentence before tokenization: Thank you\n",
            "Sentence before tokenization: I love his every play , especially the blues because it is break bounds apparently .\n",
            "Sentence before tokenization: He hitted the drum with full of smiles .\n",
            "Sentence before tokenization: Mobile and music\n",
            "Sentence before tokenization: I can study English and write this diary on this time .\n",
            "Sentence before tokenization: In addition , the player can play a part of a MP file and\n",
            "Sentence before tokenization: A I have been to Tokyo .\n",
            "Sentence before tokenization: Thank you very much for your last letter .\n",
            "Sentence before tokenization: But I am University student .\n",
            "Sentence before tokenization: The temperature rose c .\n",
            "Sentence before tokenization: I did not know why she could not find the answer .\n",
            "Sentence before tokenization: I thought we should go to another restaurant but my mam said Today , we definitely eat here ! !\n",
            "Sentence before tokenization: Second , ' Summer ' .\n",
            "Sentence before tokenization: I must make a detailed plan later .\n",
            "Sentence before tokenization: I wish my friends never get to this website at least !\n",
            "Sentence before tokenization: On the other hand , in some other areas , where people have the adequate water supply , the phenomenon of wasting water is quite common .\n",
            "Sentence before tokenization: It is really good news for me .\n",
            "Sentence before tokenization: There was no place to be seen but this street as a main street .\n",
            "Sentence before tokenization: I heard the people ware too cold to sleep the previous day .\n",
            "Sentence before tokenization: Finally , the Austrian network operator explained what they did .\n",
            "Sentence before tokenization: Fortunately , it looks like a Chinese or Hong Kong name , so it should be OK with them .\n",
            "Sentence before tokenization: They keep them at the temperature of minus degrees centigrade .\n",
            "Sentence before tokenization: Trick Art\n",
            "Sentence before tokenization: german shephard with a secret past .\n",
            "Sentence before tokenization: Well , nice thing is that you can hear audiance is laughter in the drama , so you will know when you are supposed to laugh .\n",
            "Sentence before tokenization: There are so many things to do .\n",
            "Sentence before tokenization: You can easily imagine what will happen next !\n",
            "Sentence before tokenization: - First is Anchoring .\n",
            "Sentence before tokenization: Thank you for reading my diary .\n",
            "Sentence before tokenization: The principal character of this movie is a girl of fish .\n",
            "Sentence before tokenization: The exam is today at . pm .\n",
            "Sentence before tokenization: They were well - educated , polite enough and yet friendly .\n",
            "Sentence before tokenization: And I will take the speaking test here at CNE on Thursday .\n",
            "Sentence before tokenization: I feel uneasy about the future of the earth .\n",
            "Sentence before tokenization: But it is difficult for me to try to write it in a journal .\n",
            "Sentence before tokenization: He was as abrupt with me as he could ever be , keeping that utter impassivity of his the whole time .\n",
            "Sentence before tokenization: Are men boring ?\n",
            "Sentence before tokenization: At the beginning of this year , we were told by the vet that Big Steve might not be able to make it , but he did ! !\n",
            "Sentence before tokenization:  Of course , it is free .\n",
            "Sentence before tokenization: It was very cold due to the wind .\n",
            "Sentence before tokenization: It s too difficult .\n",
            "Sentence before tokenization: Do Americans have a fire drill ? ?\n",
            "Sentence before tokenization: Simon That is a big town ?\n",
            "Sentence before tokenization: His song is pretty good .\n",
            "Sentence before tokenization: I wondered what I ate tonight .\n",
            "Sentence before tokenization: Oh my god !\n",
            "Sentence before tokenization: We found that our seats were placed in front of fireworks .\n",
            "Sentence before tokenization: Brushing of teeth\n",
            "Sentence before tokenization: This has been go on ever since when I was an upper grade of elementary school .\n",
            "Sentence before tokenization: Lang is growing up and improving step by step !\n",
            "Sentence before tokenization: I was away from my housework for about days .\n",
            "Sentence before tokenization: The conflict is so serious .\n",
            "Sentence before tokenization: An apple is a round fruit with smooth and colorful skin , red , green and sometimes gold .\n",
            "Sentence before tokenization: He is years old and he can barely speak .\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def check_grammar_errors(input_file_path, output_file_path):\n",
        "    # Load the input CSV file\n",
        "    input_df = pd.read_csv(input_file_path)\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "\n",
        "    # Iterate over each row in the input DataFrame\n",
        "    for index, row in input_df.iterrows():\n",
        "        # Skip NaN values\n",
        "        if pd.isna(row['input']):\n",
        "            continue\n",
        "\n",
        "        # Print the sentence before tokenization for debugging\n",
        "        print(\"Sentence before tokenization:\", row['input'])\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        sentence = row['input']\n",
        "        tokens = word_tokenize(sentence)\n",
        "\n",
        "        # Perform part-of-speech tagging\n",
        "        pos_tags = pos_tag(tokens)\n",
        "\n",
        "        # Initialize a list to store errors for the current sentence\n",
        "        errors = []\n",
        "\n",
        "        # Iterate over each token and check for grammar errors\n",
        "        for i in range(len(pos_tags) - 1):\n",
        "            # Check for subject-verb agreement error\n",
        "            if pos_tags[i][1].startswith('N') and pos_tags[i+1][1].startswith('VB'):\n",
        "                errors.append(\"Subject-Verb Agreement Error: '{}' should be '{}'\".format(pos_tags[i+1][0], pos_tags[i+1][0]))\n",
        "\n",
        "            # Check for article usage errors (e.g., a/an)\n",
        "            if pos_tags[i][1] == 'DT' and pos_tags[i][0].lower() in ['a', 'an'] and pos_tags[i+1][1].startswith(('N', 'JJ')):\n",
        "                errors.append(\"Article Usage Error: '{}' should be '{}'\".format(pos_tags[i][0], 'an' if pos_tags[i+1][0].lower()[0] in 'aeiou' else 'a'))\n",
        "\n",
        "            # Check for pluralization errors\n",
        "            if pos_tags[i][1].startswith('NN') and pos_tags[i+1][0] == \"'s\":\n",
        "                errors.append(\"Pluralization Error: Possessive form used for plural noun ('{}' should be '{}')\".format(pos_tags[i][0], pos_tags[i][0]+'s'))\n",
        "\n",
        "            # Check for past tense agreement error\n",
        "            if pos_tags[i][1].startswith('V') and 'VBD' not in pos_tags[i][1] and 'VBN' not in pos_tags[i][1]:\n",
        "                errors.append(\"Past Tense Agreement Error: '{}' should be in past tense\".format(pos_tags[i][0]))\n",
        "\n",
        "            # Check for present tense agreement error\n",
        "            if pos_tags[i][1].startswith('VB') and 'VBG' not in pos_tags[i][1]:\n",
        "                errors.append(\"Present Tense Agreement Error: '{}' should be in present tense\".format(pos_tags[i][0]))\n",
        "\n",
        "            # Rule 1: Subject-Verb Agreement\n",
        "            if pos_tags[i][1].startswith('N') and pos_tags[i+1][1].startswith('VB'):\n",
        "                errors.append(\"Subject-Verb Agreement Error: '{}' should be '{}'\".format(pos_tags[i+1][0], pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 2: Present Simple Tense\n",
        "            if pos_tags[i][1] == 'VBP' and pos_tags[i][0].endswith('s'):\n",
        "                errors.append(\"Present Simple Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], pos_tags[i][0][:-1]))\n",
        "\n",
        "            # Rule 3: Present Continuous Tense\n",
        "            if pos_tags[i][1] == 'VBG' and pos_tags[i][0] != 'am':\n",
        "                errors.append(\"Present Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"am \" + pos_tags[i][0]))\n",
        "\n",
        "            # Rule 4: Present Perfect Tense\n",
        "            if pos_tags[i][1] == 'VBN' and pos_tags[i][0] != 'been':\n",
        "                errors.append(\"Present Perfect Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"have \" + pos_tags[i][0]))\n",
        "\n",
        "            # Rule 5: Present Perfect Continuous Tense\n",
        "            if pos_tags[i][1] == 'VBG' and pos_tags[i][0] == 'been':\n",
        "                errors.append(\"Present Perfect Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"been \" + pos_tags[i][0]))\n",
        "\n",
        "            # Rule 6: Past Simple Tense\n",
        "            if pos_tags[i][1] == 'VBD' and not pos_tags[i][0].endswith('ed'):\n",
        "                errors.append(\"Past Simple Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], pos_tags[i][0] + 'ed'))\n",
        "\n",
        "            # Rule 7: Past Continuous Tense\n",
        "            if pos_tags[i][1] == 'VBD' and pos_tags[i][0] == 'were':\n",
        "                errors.append(\"Past Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"were \" + pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 8: Past Perfect Tense\n",
        "            if pos_tags[i][1] == 'VBN' and pos_tags[i][0] != 'had':\n",
        "                errors.append(\"Past Perfect Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"had \" + pos_tags[i][0]))\n",
        "\n",
        "            # Rule 9: Past Perfect Continuous Tense\n",
        "            if pos_tags[i][1] == 'VBN' and pos_tags[i][0] == 'had':\n",
        "                errors.append(\"Past Perfect Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"had been \" + pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 10: Future Simple Tense\n",
        "            if pos_tags[i][1] == 'MD' and pos_tags[i][0] not in ['will', 'shall']:\n",
        "                errors.append(\"Future Simple Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], \"will \" + pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 11: Future Continuous Tense\n",
        "            if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n",
        "                errors.append(\"Future Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], pos_tags[i][0] + \" be \" + pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 12: Future Perfect Tense\n",
        "            if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n",
        "                errors.append(\"Future Perfect Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], pos_tags[i][0] + \" have \" + pos_tags[i+1][0]))\n",
        "\n",
        "            # Rule 13: Future Perfect Continuous Tense\n",
        "            if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n",
        "                errors.append(\"Future Perfect Continuous Tense Error: '{}' should be '{}'\".format(pos_tags[i][0], pos_tags[i][0] + \" have been \" + pos_tags[i+1][0]))\n",
        "\n",
        "\n",
        "        # Add the results to the list\n",
        "        if row['predicted_label'] == 0:\n",
        "            if len(errors) > 0:\n",
        "                results.append((sentence, 0, errors))\n",
        "            else:\n",
        "                results.append((sentence, 0, \"No Error\"))\n",
        "        else:\n",
        "            results.append((sentence, 1, \"No Error\"))\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    output_df = pd.DataFrame(results, columns=['input', 'label', 'error_type'])\n",
        "\n",
        "    # Save the DataFrame to the output CSV file\n",
        "    output_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Example usage:\n",
        "check_grammar_errors(\"output_labelled.csv\", \"final_predictions_with_errortype.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xarmVUL6wN_p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMMn0i3YggDHsjOysu1D3BL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a31976743784e91a157161b0e6ca0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fc18421db624525812de1ebb85bf30c",
              "IPY_MODEL_a009d3cb9ef74afaabfe98c5c48b6704",
              "IPY_MODEL_ba5317e7c24b4de0bcdf9adfb08031eb"
            ],
            "layout": "IPY_MODEL_69d5e623fe67430689d69af592c28783"
          }
        },
        "0fc18421db624525812de1ebb85bf30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ce9dc7d025a4d8b8d6b249225664e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa63531df31c478fac038e100f983061",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a009d3cb9ef74afaabfe98c5c48b6704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9caa6bdead1e4e95befc12a689f1932c",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4792744d5b1a4f40ad62e0d2cc2b643e",
            "value": 48
          }
        },
        "ba5317e7c24b4de0bcdf9adfb08031eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9566017f51e43c7b43c612897dc2c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_4936e69475eb419e8572abec8d64349b",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.29kB/s]"
          }
        },
        "69d5e623fe67430689d69af592c28783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce9dc7d025a4d8b8d6b249225664e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa63531df31c478fac038e100f983061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9caa6bdead1e4e95befc12a689f1932c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4792744d5b1a4f40ad62e0d2cc2b643e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9566017f51e43c7b43c612897dc2c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4936e69475eb419e8572abec8d64349b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "776b6fd669924a2fa4aed78157e9b396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe24f8ce12684c6b9097ecd300bd52b3",
              "IPY_MODEL_da8a6e57dd4c47f99b5ed5f438c37583",
              "IPY_MODEL_e5e1709b7399411f9c8881c73a1fbffb"
            ],
            "layout": "IPY_MODEL_84c9a4106f8a46998c83d441a5e0f18b"
          }
        },
        "fe24f8ce12684c6b9097ecd300bd52b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5206ee3bc4634ca0a7dc1811b11ae9d2",
            "placeholder": "​",
            "style": "IPY_MODEL_d975e3440ec047bb9262980268e23feb",
            "value": "vocab.txt: 100%"
          }
        },
        "da8a6e57dd4c47f99b5ed5f438c37583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab308c38f8e4e049eb34da19aed6f98",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c2964075ef848909996ac5b22fc7147",
            "value": 231508
          }
        },
        "e5e1709b7399411f9c8881c73a1fbffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4b0789bed84d5eba79eaf4a73c5981",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d7d6b3674048eb957dbd4258612f3d",
            "value": " 232k/232k [00:00&lt;00:00, 6.31MB/s]"
          }
        },
        "84c9a4106f8a46998c83d441a5e0f18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5206ee3bc4634ca0a7dc1811b11ae9d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d975e3440ec047bb9262980268e23feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab308c38f8e4e049eb34da19aed6f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2964075ef848909996ac5b22fc7147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c4b0789bed84d5eba79eaf4a73c5981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d7d6b3674048eb957dbd4258612f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a66ec5f49654dad9a1d5e18a439797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ce6709a33d043f5a81ae7ce9e6496df",
              "IPY_MODEL_b0adc857f0bd44c1a8a56d6a47179738",
              "IPY_MODEL_7d62992909d7437ba35fdd6bf9f288f0"
            ],
            "layout": "IPY_MODEL_45c119b77b6241ba8837fd440c5b9b21"
          }
        },
        "1ce6709a33d043f5a81ae7ce9e6496df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9329c29485740938c65ee6543921de3",
            "placeholder": "​",
            "style": "IPY_MODEL_6e3bb9c3d9194b0c94627d636a70b023",
            "value": "tokenizer.json: 100%"
          }
        },
        "b0adc857f0bd44c1a8a56d6a47179738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_140f277b970e4636af76ad8fbed3e5d2",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e69205ef534c67b639ffe8a74fe9db",
            "value": 466062
          }
        },
        "7d62992909d7437ba35fdd6bf9f288f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d2ac72a6ca44c72a55cac0f154c58cf",
            "placeholder": "​",
            "style": "IPY_MODEL_59534e7e9eb5427dbbd14e3fbe009fcf",
            "value": " 466k/466k [00:00&lt;00:00, 19.8MB/s]"
          }
        },
        "45c119b77b6241ba8837fd440c5b9b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9329c29485740938c65ee6543921de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3bb9c3d9194b0c94627d636a70b023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140f277b970e4636af76ad8fbed3e5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e69205ef534c67b639ffe8a74fe9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d2ac72a6ca44c72a55cac0f154c58cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59534e7e9eb5427dbbd14e3fbe009fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c78736266d47308bcf06c8159b2d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4d6495a5e9b40b8b0f04bcb0475aebd",
              "IPY_MODEL_65d7f964690142288da78518cbb57bb3",
              "IPY_MODEL_d7493a468e8843018d8c5734bbe87f5c"
            ],
            "layout": "IPY_MODEL_e57257e2a10143dd84514f047ac097b5"
          }
        },
        "c4d6495a5e9b40b8b0f04bcb0475aebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f2f22096a54907977085d18a03c829",
            "placeholder": "​",
            "style": "IPY_MODEL_deeb2099514548f8baff66d1ea59942b",
            "value": "config.json: 100%"
          }
        },
        "65d7f964690142288da78518cbb57bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ee6a629fd249928359e29a27331c93",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b55c08db22024ac8a891fdc3c6bc3d09",
            "value": 570
          }
        },
        "d7493a468e8843018d8c5734bbe87f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641554f14f35437b8e7ba494a99dd7de",
            "placeholder": "​",
            "style": "IPY_MODEL_77d04ee4b8714703bdc1dca1460d1019",
            "value": " 570/570 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "e57257e2a10143dd84514f047ac097b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f2f22096a54907977085d18a03c829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deeb2099514548f8baff66d1ea59942b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9ee6a629fd249928359e29a27331c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55c08db22024ac8a891fdc3c6bc3d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "641554f14f35437b8e7ba494a99dd7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d04ee4b8714703bdc1dca1460d1019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c5313066814b6ea8b47adb25c11e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9451c885cfe04e3bab32be4f9cd056ea",
              "IPY_MODEL_406bc8a4a132469d8de98d19bd722258",
              "IPY_MODEL_835ffeacc46140e5a034175a40e86104"
            ],
            "layout": "IPY_MODEL_af302ebf5fcf4d1b8a7c4ce84813c298"
          }
        },
        "9451c885cfe04e3bab32be4f9cd056ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c71bcd8031d4d97a437a33b5660abd9",
            "placeholder": "​",
            "style": "IPY_MODEL_4e002e3efb3b44f2ac3005b7e7c97aa8",
            "value": "model.safetensors: 100%"
          }
        },
        "406bc8a4a132469d8de98d19bd722258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ceca28a7c546819e1a876c1ecc88c3",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ab0981a2f564f60b118a3f9ef581e89",
            "value": 440449768
          }
        },
        "835ffeacc46140e5a034175a40e86104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9979964b79411a9969a8e862c1df1c",
            "placeholder": "​",
            "style": "IPY_MODEL_e804fba96ca04c568073d88d61980f3f",
            "value": " 440M/440M [00:01&lt;00:00, 233MB/s]"
          }
        },
        "af302ebf5fcf4d1b8a7c4ce84813c298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c71bcd8031d4d97a437a33b5660abd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e002e3efb3b44f2ac3005b7e7c97aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93ceca28a7c546819e1a876c1ecc88c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab0981a2f564f60b118a3f9ef581e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9979964b79411a9969a8e862c1df1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e804fba96ca04c568073d88d61980f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}